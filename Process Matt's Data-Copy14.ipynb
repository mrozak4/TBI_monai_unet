{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7be0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nipype.interfaces import niftyreg\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ants\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation, binary_closing\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import tifffile as tif\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import cc3d\n",
    "from scipy.io import loadmat, savemat\n",
    "import skan\n",
    "import sknw\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f724d",
   "metadata": {},
   "source": [
    "# Define connected componnet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9888d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_comps_3d(image, thresh = 500):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : binary np array with uint8 elements\n",
    "        3d numpy matrix, connected components will be removed form this image\n",
    "    thresh : int64\n",
    "        smallest connected components to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array with uint8 elements, binary\n",
    "        binary image with connected components below the threshold removed.\n",
    "\n",
    "    \"\"\"\n",
    "    img_lab, N = cc3d.connected_components(image,return_N=True)\n",
    "    unique, counts = np.unique(img_lab, return_counts=True)\n",
    "    unique_keep = unique[counts>thresh]\n",
    "    unique_keep = np.delete(unique_keep,[0])\n",
    "    img_filt = np.zeros(img_lab.shape).astype('int8')\n",
    "    img_filt[np.isin(img_lab,unique_keep)] = 1\n",
    "    return img_filt.astype('uint8')   \n",
    "\n",
    "def fill_holes(img,thresh=100):\n",
    "    #res = np.zeros(img.shape)\n",
    "    for i in np.unique(img)[::-1]:\n",
    "        _tmp = (img==i)*1.0\n",
    "        _tmp = _tmp.astype('int8')\n",
    "        _tmp = remove_small_comps_3d(_tmp,thresh=thresh)\n",
    "        img[_tmp==1] = i\n",
    "    res = img.astype('int8')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7b76",
   "metadata": {},
   "source": [
    "# Get mean predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b09644",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if 'vbm' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5c3c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8db528",
   "metadata": {},
   "source": [
    "# High bias low varience segmentation\n",
    "\n",
    "With removal of connected components under 500 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b4b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [38:39<00:00,  3.02s/it]  \n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files[::-1]):\n",
    "    if (time.time() - os.path.getmtime(re.sub('mean','seg',file)))/3600>48:\n",
    "    #if not os.path.exists(re.sub('mean','seg',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==1)*1\n",
    "        seg = fill_holes(seg)\n",
    "        np.save(re.sub('mean','seg',file),seg)\n",
    "        #savemat(re.sub('mean.npy','seg.mat',file),{'FinalImage':fill_holes(binary_dilation(binary_dilation(seg)))})\n",
    "        #tif.imwrite(re.sub('mean.npy','seg.tif',file),seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3743f6-0c58-47e5-a874-d1960fa54645",
   "metadata": {},
   "source": [
    "# Get distance transform of neuron segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b6c5ef-34e0-40fd-9513-493f5302d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if 'vbm' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bddcafd-b682-4000-bd3d-56b82e12da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [00:00<00:00, 1912.07it/s]\n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files[::-1]):\n",
    "    if (time.time() - os.path.getmtime(re.sub('mean','seg_nrn_dst',file)))/3600>48:\n",
    "    #if not os.path.exists(re.sub('mean','seg_nrn_dst',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==2)*1\n",
    "        np.save(re.sub('mean','seg_nrn',file),seg)\n",
    "        np.save(re.sub('mean','seg_nrn_dst',file),distance_transform_edt(1-seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e5259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matt_preds/06162021_45-XYZres288_0001_seg_nrn_dst.npy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('mean','seg_nrn_dst',file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca6732",
   "metadata": {},
   "source": [
    "# ANTs registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9228eb",
   "metadata": {},
   "source": [
    "## Upsample raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b86439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = Path('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI')\n",
    "images = list(image_path.glob('*?[0-9]/*res*?[0-9].tif'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8959038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [00:44<00:00, 17.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(images))[:]):\n",
    "    if not os.path.exists('matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i]))):\n",
    "        image = io.imread(images[i])\n",
    "        if image.shape[0] == 96:\n",
    "            image = np.swapaxes(image,0,1)\n",
    "            image = np.swapaxes(image,1,3)\n",
    "            image = resize(image,(2,507,507,252),preserve_range=True, order=3)\n",
    "            zeros = np.zeros((1,507,507,252)).astype('uint16')\n",
    "            image = np.append(image,zeros,axis = 0)\n",
    "            image = image.astype('float16')\n",
    "            io.imsave('matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i])),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53558e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matt_preds/vbm11 Apr 04 2020-XYZres052_0001.tif'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f08281",
   "metadata": {},
   "source": [
    "## reshape numpy seg files and resave as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600a9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "files_seg  = list(directory_seg.glob('*_seg.npy'))\n",
    "files_seg = sorted([x.as_posix() for x in files_seg])\n",
    "#files_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad13dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1157/1157 [00:26<00:00, 44.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(files_seg))):\n",
    "    if not os.path.exists(re.sub('.npy','.tif',files_seg[i])):\n",
    "        tmp = np.load(files_seg[i])\n",
    "        tmp = np.reshape(tmp,(1,507,507,252))\n",
    "        io.imsave(re.sub('.npy','.tif',files_seg[i]),tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf7115",
   "metadata": {},
   "source": [
    "## Register images and transform masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dfc93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "matt_preds/06162021_45-XYZres288_0001.tif\n"
     ]
    }
   ],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001.tif'))\n",
    "images = sorted([x.as_posix() for x in images])#[0:2]\n",
    "print(len(images))\n",
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade09ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:10<00:00, 36.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(images))):\n",
    "    if os.path.exists(re.sub('.tif','_seg.tif',images[i])):\n",
    "        if not os.path.exists(re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',images[i]))):\n",
    "            fix = ants.image_read(re.sub('_0001','',images[i]))\n",
    "            mov = ants.image_read(images[i])\n",
    "            fix_mask = ants.image_read(re.sub('.tif','_seg.tif',re.sub('_0001','',images[i])))\n",
    "            mov_mask = ants.image_read(re.sub('.tif','_seg.tif',images[i]))\n",
    "            mytx = ants.registration(fixed = fix,\n",
    "                                    moving = mov,\n",
    "                                    type_of_transform = 'Rigid'\n",
    "                                    )\n",
    "            warpedmask = ants.apply_transforms(fixed = fix_mask,\n",
    "                                               moving = mov_mask,\n",
    "                                               transformlist = mytx['fwdtransforms'],\n",
    "                                               interpolator = 'nearestNeighbor'\n",
    "                                              )\n",
    "            io.imsave(re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',images[i])),warpedmask.numpy())\n",
    "            io.imsave(re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',re.sub('_0001','',images[i]))),fix_mask.numpy())\n",
    "            #print(2 * np.sum(warpedmask.numpy()*fix_mask.numpy())/(np.sum(warpedmask.numpy())+np.sum(fix_mask.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a8329",
   "metadata": {},
   "source": [
    "## Save Matlab .mat file of registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af813286",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001_seg_warped.tif'))\n",
    "images = sorted([x.as_posix() for x in images])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d576f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [00:15<00:00, 36.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(images):\n",
    "    if not os.path.exists(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image))):\n",
    "        img_0001 = io.imread(image)\n",
    "        img = io.imread(re.sub('_0001','',image))\n",
    "        seg = img*img_0001\n",
    "        seg = (seg==1)*1\n",
    "        seg = seg.astype('int8')\n",
    "        seg = fill_holes(seg)\n",
    "        savemat(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image)),{'FinalImage':fill_holes(binary_dilation(seg))})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ce09b0-d23d-4b99-abb1-c18431ad1bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matt_preds/06162021_45-XYZres288_0001_seg_warped.tif\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5818c18",
   "metadata": {},
   "source": [
    "# Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd876acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('matt_preds')\n",
    "files_seg_0001 = directory.glob('*_0001_seg_warped.tif')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "len(files_seg_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6810a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [00:00<00:00, 9893.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_0001 in tqdm(files_seg_0001):\n",
    "    if not os.path.exists(re.sub('_0001_seg_warped.tif','_warped.pickle',file)):\n",
    "        file = file_0001\n",
    "        skel_file = re.sub('_0001_seg_warped.tif','_skel_warped_single.mat',file)\n",
    "        #seg = io.imread(file)\n",
    "        skel = loadmat(skel_file)['FilteredImage']\n",
    "        #skel = skeletonize_3d(skel)\n",
    "        io.imsave(re.sub('_seg_warped.tif','_single_skel.tif',file),skel)\n",
    "        #dst_tsfm = distance_transform_edt(seg)\n",
    "        #dst_tsfm[dst_tsfm==0]=0.00001\n",
    "        #skel_dst = skel*dst_tsfm\n",
    "    #\n",
    "        #\n",
    "        #np.save(re.sub('seg','dst_skel',file),skel_dst)\n",
    "        #io.imsave(re.sub('_seg_warped.tif','_dst_skel_warped.tif',file),skel_dst)\n",
    "        graph = sknw.build_sknw(skel, multi=False)\n",
    "        print(len(graph.edges))\n",
    "        #graph, c0  = skan.csr.skeleton_to_csgraph(skel)\n",
    "        #print(len(graph.edges))\n",
    "        \n",
    "        #print(len(graph_0001.edges))\n",
    "        #pickle.dump(graph, open(str(re.sub('_seg.npy','.pickle',file)), 'w'))\n",
    "        #nx.write_pajek(graph,re.sub('_seg.npy','.pajek',file))\n",
    "        \n",
    "        nx.write_gpickle(graph,re.sub('_0001_seg_warped.tif','_warped.pickle',file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba7bff",
   "metadata": {},
   "source": [
    "# write vessel measurments to graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65f52c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "matt_preds/06162021_45-XYZres288_warped.pickle\n"
     ]
    }
   ],
   "source": [
    "directory = Path('matt_preds')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if '-' in x]\n",
    "print(len(files))\n",
    "print(files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba9d4364-488f-407b-a9ae-e3878dad3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37e13ca7-1348-43fa-b7dc-cff0cbfe1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('matt_preds/','',re.sub('_warped.pickle','',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21d716ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]/tmp/ipykernel_1975335/87323968.py:76: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "100%|██████████| 380/380 [1:50:33<00:00, 17.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    #if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file))):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        if len(graph.edges) < 1500:\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1] in df[sheet_name].values:\n",
    "                    subj = sheet_name\n",
    "                    if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1] in sheet_name:\n",
    "                        if subj in [\"TBI07_3D\",\n",
    "                                    \"TBI11_3D\",\n",
    "                                    \"TBI22_3D\",\n",
    "                                    \"TBI31_3D\",\n",
    "                                    \"TBI38_3D\",\n",
    "                                    \"SHAM09_3D\",\n",
    "                                    \"SHAM12_3D\",\n",
    "                                    \"SHAM23_3D\",\n",
    "                                    \"SHAM32_3D\",\n",
    "                                    'TBI38_3D',\n",
    "                                    'TBI6_3D',\n",
    "                                    'SHAM7_3D',\n",
    "                                    'TBI43_3D',\n",
    "                                    'TBI45_3D',\n",
    "                                    'SHAM53_3D',\n",
    "                                    'SHAM56_3D',\n",
    "                                    'SHAM55_3D']:\n",
    "                            gender = 'male'\n",
    "                        else:\n",
    "                            gender = 'female'\n",
    "                        treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                        _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1]]\n",
    "                        if _tmp['Unnamed: 12'].iloc[0] == 'raster':\n",
    "                            seg_file = re.sub('_warped.pickle','_seg_warped.tif',file)\n",
    "                            seg_0001_file = re.sub('_warped.pickle','_0001_seg_warped.tif',file)\n",
    "                            seg = io.imread(seg_file)\n",
    "                            seg_0001 = io.imread(seg_0001_file)\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "                            nrn_dst = np.load(re.sub('_warped.pickle','_seg_nrn_dst.npy',file))\n",
    "                            nrn_dst = np.swapaxes(nrn_dst,0,2)\n",
    "                            wavelength = _tmp['Unnamed: 11'].iloc[0]\n",
    "                            power_per = _tmp['Unnamed: 10'].iloc[0]\n",
    "                            start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                            age = _tmp['Unnamed: 14'].iloc[0]\n",
    "                            days_post_injury = _tmp['Unnamed: 15'].iloc[0]\n",
    "                            for i in range(len(graph.edges)):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _vals = seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                _vals_0001 = seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                _nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['wavelength'] = wavelength\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['power'] = power_per\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            nx.write_gpickle(graph, re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file)))\n",
    "                            i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec064eab-4b32-4f15-ad94-5faf33de3eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 507, 507)\n",
      "(252, 507, 507)\n"
     ]
    }
   ],
   "source": [
    "print(nrn_dst.shape)\n",
    "print(seg_dst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3ec65da-36a4-48ca-8994-f5153e5cf748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "graphs = [file for file in files if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file)))]\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83abb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 23/119 [00:23<05:30,  3.45s/it]/tmp/ipykernel_1975335/2211074957.py:74: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "100%|██████████| 119/119 [17:22<00:00,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(graphs):\n",
    "    #if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file))):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        if len(graph.edges) < 1500:\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1] in df[sheet_name].values:\n",
    "                    subj = sheet_name\n",
    "                    if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1] in sheet_name:\n",
    "                        if subj in [\"TBI07_3D\",\n",
    "                                    \"TBI11_3D\",\n",
    "                                    \"TBI22_3D\",\n",
    "                                    \"TBI31_3D\",\n",
    "                                    \"TBI38_3D\",\n",
    "                                    \"SHAM09_3D\",\n",
    "                                    \"SHAM12_3D\",\n",
    "                                    \"SHAM23_3D\",\n",
    "                                    \"SHAM32_3D\",\n",
    "                                    'TBI38_3D',\n",
    "                                    'TBI6_3D',\n",
    "                                    'SHAM7_3D',\n",
    "                                    'TBI43_3D',\n",
    "                                    'TBI45_3D',\n",
    "                                    'SHAM53_3D',\n",
    "                                    'SHAM56_3D',\n",
    "                                    'SHAM55_3D']:\n",
    "                            gender = 'male'\n",
    "                        else:\n",
    "                            gender = 'female'\n",
    "                        treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                        _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1]]\n",
    "                        if _tmp['Unnamed: 10'].iloc[0] == 2:\n",
    "                            seg_file = re.sub('_warped.pickle','_seg_warped.tif',file)\n",
    "                            seg_0001_file = re.sub('_warped.pickle','_0001_seg_warped.tif',file)\n",
    "                            seg = io.imread(seg_file)\n",
    "                            seg_0001 = io.imread(seg_0001_file)\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "                            nrn_dst = np.load(re.sub('_warped.pickle','_seg_nrn_dst.npy',file))\n",
    "                            nrn_dst = np.swapaxes(nrn_dst,0,2)\n",
    "                            start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                            age = _tmp['Unnamed: 8'].iloc[0]\n",
    "                            days_post_injury = _tmp['Unnamed: 9'].iloc[0]\n",
    "                            for i in range(len(graph.edges)):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _vals = seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                _vals_0001 = seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                _nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            nx.write_gpickle(graph, re.sub('preds','preds_graphs',re.sub('.pickle','_radii_shock.pickle',file)))\n",
    "                            i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e257eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "['matt_preds/06162021_45-xyzres296_warped.pickle', 'matt_preds/20200109_6-XYZres69_warped.pickle', 'matt_preds/20200109_6-XYZres70_warped.pickle', 'matt_preds/20200109_6-XYZres71_warped.pickle', 'matt_preds/20200109_6-XYZres72_warped.pickle', 'matt_preds/20200109_6-XYZres73_warped.pickle', 'matt_preds/20200109_6-XYZres74_warped.pickle', 'matt_preds/20200109_6-XYZres75_warped.pickle', 'matt_preds/20200109_6-XYZres76_warped.pickle', 'matt_preds/20200109_6-XYZres77_warped.pickle', 'matt_preds/20200109_6-XYZres78_warped.pickle', 'matt_preds/20200109_6-XYZres79_warped.pickle', 'matt_preds/20200109_6-XYZres80_warped.pickle', 'matt_preds/20200217_11-XYZres91_warped.pickle', 'matt_preds/20200217_11-XYZres92_warped.pickle', 'matt_preds/20200217_11-XYZres93_warped.pickle', 'matt_preds/20200217_11-XYZres94_warped.pickle', 'matt_preds/20200217_11-XYZres96_warped.pickle', 'matt_preds/20200217_12-XYZres81_warped.pickle', 'matt_preds/20200217_12-XYZres82_warped.pickle', 'matt_preds/20200217_12-XYZres83_warped.pickle', 'matt_preds/20200217_12-XYZres84_warped.pickle', 'matt_preds/20200217_7-XYZres61_warped.pickle', 'matt_preds/20200217_7-XYZres62_warped.pickle', 'matt_preds/20200217_7-XYZres63_warped.pickle', 'matt_preds/20200217_7-XYZres64_warped.pickle', 'matt_preds/20200217_7-XYZres65_warped.pickle', 'matt_preds/20200217_7-XYZres66_warped.pickle', 'matt_preds/20200217_7-XYZres67_warped.pickle', 'matt_preds/20200217_7-XYZres68_warped.pickle', 'matt_preds/vbm03 Feb 26 2020-XYZres006_warped.pickle', 'matt_preds/vbm03 Feb 26 2020-XYZres007_warped.pickle', 'matt_preds/vbm03 Feb 26 2020-XYZres008_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres009_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres010_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres011_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres012_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres013_warped.pickle', 'matt_preds/vbm04 Feb 27 2020-XYZres014_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres015_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres016_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres017_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres018_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres019_warped.pickle', 'matt_preds/vbm05 Feb 28 2020-XYZres020_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres021_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres022_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres023_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres024_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres025_warped.pickle', 'matt_preds/vbm07 Mar 24 2020-XYZres026_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres027_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres028_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres029_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres030_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres031_warped.pickle', 'matt_preds/vbm08 Mar 27 2020-XYZres032_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres033_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres034_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres035_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres036_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres037_warped.pickle', 'matt_preds/vbm09 Mar 28 2020-XYZres038_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres039_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres040_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres041_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres042_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres043_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres044_warped.pickle', 'matt_preds/vbm10 Apr 03 2020-XYZres045_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres046_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres047_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres048_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres049_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres050_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres051_warped.pickle', 'matt_preds/vbm11 Apr 04 2020-XYZres052_warped.pickle']\n"
     ]
    }
   ],
   "source": [
    "_graphs = [file for file in graphs if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii_shock.pickle',file)))]\n",
    "print(len(_graphs))\n",
    "print(_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5be2",
   "metadata": {},
   "source": [
    "# convert graphs to excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14ad0961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'matt_preds_graphs/06162021_45-XYZres288_warped_radii.pickle'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('matt_preds_graphs')\n",
    "files = directory.glob('*_warped_radii.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b60f19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 402/402 [03:32<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    edge_df.to_excel(re.sub('.pickle','.xlsx',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46893c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'matt_preds_graphs/20200217_14-XYZres113_warped_radii_shock.pickle'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('matt_preds_graphs')\n",
    "files = directory.glob('*_warped_radii_shock.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e900d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:19<00:00,  2.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    edge_df.to_excel(re.sub('.pickle','.xlsx',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb2639-ecdf-4cfd-9175-562423a5fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
