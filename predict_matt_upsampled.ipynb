{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beab03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import (\n",
    "    first, \n",
    "    set_determinism, \n",
    "    ensure_tuple\n",
    ")\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAffined,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    RandFlipd,\n",
    "    RandGaussianNoised,\n",
    "    RandAdjustContrastd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    AddChanneld,\n",
    "    RandGaussianSharpend,\n",
    "    RandGaussianSmoothd,\n",
    "    RandHistogramShiftd,\n",
    "    OneOf,\n",
    "    Rand3DElasticd,\n",
    "    Rand3DElastic,\n",
    "    RandGridDistortiond,\n",
    "    RandSpatialCropSamplesd,\n",
    "    FillHoles,\n",
    "    LabelFilter,\n",
    "    LabelToContour\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import (\n",
    "    DiceMetric, \n",
    "    HausdorffDistanceMetric\n",
    ")\n",
    "from monai.losses import (\n",
    "    DiceLoss, \n",
    "    DiceCELoss, \n",
    "    DiceFocalLoss\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import (\n",
    "    CacheDataset, \n",
    "    DataLoader, \n",
    "    Dataset, \n",
    "    decollate_batch, \n",
    "    ImageReader\n",
    ")\n",
    "from monai.data.image_reader import WSIReader\n",
    "from monai.config import (\n",
    "    print_config, \n",
    "    KeysCollection, \n",
    "    PathLike\n",
    ")\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "from torchio.transforms import (\n",
    "    RandomAffine\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from numpy import random\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage import io\n",
    "from typing import (\n",
    "    Optional, \n",
    "    Union, \n",
    "    Sequence, \n",
    "    Callable, \n",
    "    Dict, \n",
    "    List\n",
    ")\n",
    "from monai.data.utils import is_supported_format\n",
    "from monai. data.image_reader import (\n",
    "    _copy_compatible_dict, \n",
    "    _stack_images\n",
    ")\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from mlflow import log_metric, log_param, log_artifacts, set_experiment, start_run, end_run\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "#import torch as torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "class TIFFReader(ImageReader):\n",
    "    \n",
    "    def __init__(self, npz_keys: Optional[KeysCollection] = None, channel_dim: Optional[int] = None, **kwargs):\n",
    "        super().__init__()\n",
    "        if npz_keys is not None:\n",
    "            npz_keys = ensure_tuple(npz_keys)\n",
    "        self.npz_keys = npz_keys\n",
    "        self.channel_dim = channel_dim\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def verify_suffix(self, filename: Union[Sequence[PathLike], PathLike]) -> bool:\n",
    "        \"\"\"\n",
    "        Verify whether the specified file or files format is supported by Numpy reader.\n",
    "\n",
    "        Args:\n",
    "            filename: file name or a list of file names to read.\n",
    "                if a list of files, verify all the suffixes.\n",
    "        \"\"\"\n",
    "        suffixes: Sequence[str] = [\"tif\", \"tiff\"]\n",
    "        return is_supported_format(filename, suffixes)\n",
    "\n",
    "    def read(self, data: Union[Sequence[PathLike], PathLike], **kwargs):\n",
    "        \"\"\"\n",
    "        Read image data from specified file or files, it can read a list of `no-channel` data files\n",
    "        and stack them together as multi-channels data in `get_data()`.\n",
    "        Note that the returned object is Numpy array or list of Numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            data: file name or a list of file names to read.\n",
    "            kwargs: additional args for `numpy.load` API except `allow_pickle`, will override `self.kwargs` for existing keys.\n",
    "                More details about available args:\n",
    "                https://numpy.org/doc/stable/reference/generated/numpy.load.html\n",
    "\n",
    "        \"\"\"\n",
    "        img_: List[Nifti1Image] = []\n",
    "\n",
    "        filenames: Sequence[PathLike] = ensure_tuple(data)\n",
    "        kwargs_ = self.kwargs.copy()\n",
    "        kwargs_.update(kwargs)\n",
    "        for name in filenames:\n",
    "            img = io.imread(name, **kwargs_)\n",
    "            #print(name)\n",
    "            img = img.astype('float32')\n",
    "            if len(img.shape)==4:\n",
    "                img = np.swapaxes(img,0,1)\n",
    "                img = np.swapaxes(img,1,3)\n",
    "            img_.append(img)\n",
    "        return img_ if len(img_) > 1 else img_[0]\n",
    "    \n",
    "    def get_data(self, img):\n",
    "        \"\"\"\n",
    "        Extract data array and meta data from loaded image and return them.\n",
    "        This function returns two objects, first is numpy array of image data, second is dict of meta data.\n",
    "        It constructs `affine`, `original_affine`, and `spatial_shape` and stores them in meta dict.\n",
    "        When loading a list of files, they are stacked together at a new dimension as the first dimension,\n",
    "        and the meta data of the first image is used to represent the output meta data.\n",
    "\n",
    "        Args:\n",
    "            img: a Numpy array loaded from a file or a list of Numpy arrays.\n",
    "\n",
    "        \"\"\"\n",
    "        img_array: List[np.ndarray] = []\n",
    "        compatible_meta: Dict = {}\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = (img,)\n",
    "\n",
    "        for i in ensure_tuple(img):\n",
    "            header = {\"affine\":np.eye(5),\n",
    "                     \"labels\": {\"0\": \"background\",\n",
    "                                \"1\": \"vessels\",\n",
    "                                \"2\": \"neurons\",}\n",
    "                     }\n",
    "            if isinstance(i, np.ndarray):\n",
    "                # if `channel_dim` is None, can not detect the channel dim, use all the dims as spatial_shape\n",
    "                spatial_shape = np.asarray(i.shape)\n",
    "                if isinstance(self.channel_dim, int):\n",
    "                    spatial_shape = np.delete(spatial_shape, self.channel_dim)\n",
    "                header[\"spatial_shape\"] = spatial_shape\n",
    "            img_array.append(i)\n",
    "            header[\"original_channel_dim\"] = self.channel_dim if isinstance(self.channel_dim, int) else \"no_channel\"\n",
    "            _copy_compatible_dict(header, compatible_meta)\n",
    "\n",
    "        return _stack_images(img_array, compatible_meta), compatible_meta\n",
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.module = module # that I actually define.\n",
    "    def forward(self, x):\n",
    "        return self.module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db66c37",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1323694/3634729990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#model = model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m model.load_state_dict(torch.load(\n\u001b[0m\u001b[1;32m     42\u001b[0m     os.path.join(directory, \"best_metric_model_rerun.pth\")))\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#ddp_model = DDP(model, device_ids=[device_id])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "parameter_file = 'hyperparameter_pickle_files/parameters436.pickle'\n",
    "\n",
    "experiment = re.sub('.pickle',\n",
    "                    '',\n",
    "                    re.sub('hyperparameter_pickle_files/parameters',\n",
    "                           '',\n",
    "                           parameter_file\n",
    "                          )\n",
    "                   )\n",
    "\n",
    "with open(parameter_file, 'rb') as handle:\n",
    "    params = pickle.load(handle)\n",
    "\n",
    "directory = re.sub('.pickle',\n",
    "                   '',\n",
    "                   re.sub('hyperparameter_pickle_files/parameters',\n",
    "                          'training_models/',\n",
    "                           parameter_file\n",
    "                         )\n",
    "                  )\n",
    "\n",
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "model = UNETR(\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    img_size = (128,128,128),\n",
    "    feature_size = 16,\n",
    "    hidden_size = 768,\n",
    "    mlp_dim = 3072,\n",
    "    pos_embed = \"perceptron\",\n",
    "    res_block=True,\n",
    "    norm_name=\"instance\",\n",
    "    dropout_rate=params[\"dropout\"]\n",
    ")\n",
    "model = torch.nn.DataParallel(model)\n",
    "#model = model.to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(directory, \"best_metric_model_rerun.pth\")))\n",
    "#ddp_model = DDP(model, device_ids=[device_id])\n",
    "model = model.to(device)\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "#model.to(device)\n",
    "#model = WrappedModel(model)\n",
    "#state_dict = torch.load(os.path.join(directory, \"best_metric_model_rerun.pth\"), map_location='cpu')\n",
    "#model.load_state_dict(state_dict)\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e878a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b30ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13163219",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_path = Path('matt_raw_warped')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*res*.tif'))#grab folder names/mouse ids\n",
    "mouse_ids = sorted([x.as_posix() for x in mouse_ids])\n",
    "np.random.shuffle(mouse_ids)\n",
    "data_dicts = [\n",
    "    {\"image\":image_name}\n",
    "    for image_name in mouse_ids if not os.path.exists(re.sub('.tif','_pred.npy',re.sub('matt_raw_warped','/home/rozakmat/scratch/rrg-bojana/rozakmat/matt_raw_warped_upsampled',image_name)))\n",
    "]\n",
    "\n",
    "pred_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"],reader = TIFFReader(channel_dim = 0)),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(\n",
    "            1, 1, 0.375), mode=(\"bilinear\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1024,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pred_ds = Dataset(data=data_dicts, transform=pred_transforms)\n",
    "pred_loader = DataLoader(pred_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f584c8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d92a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:19, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "CPU times: user 18.7 s, sys: 3.72 s, total: 22.4 s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_evals = 5\n",
    "#post_pred = Compose([EnsureType(), AsDiscrete(argmax=True,to_onehot=3)])\n",
    "#softmax = torch.nn.Softmax(dim=1)\n",
    "#model.eval()\n",
    "#for m in model.modules():\n",
    "#    if m.__class__.__name__.startswith('Dropout'):\n",
    "#        m.train()\n",
    "with torch.no_grad():\n",
    "    print('no')\n",
    "    for i, pred_data in tqdm(enumerate(pred_loader)):\n",
    "        print('yes')\n",
    "        #print(pred_data[\"image\"].shape)\n",
    "        if not os.path.exists(re.sub('scratch/rrg-bojana/rozakmat','projects/rrg-bojana/rozakmat/TBI_monai_UNET',re.sub('.tif','_mean.npy',re.sub('matt_raw_warped','/home/rozakmat/scratch/rrg-bojana/rozakmat/matt_raw_warped_upsampled',data_dicts[i][\"image\"])))):\n",
    "            #pred_array = np.empty((num_evals,3,1023,1023,508),dtype=np.float16)\n",
    "            pred_data[\"image\"] = pred_data[\"image\"]\n",
    "            break\n",
    "            print(pred_data[\"image\"].requires_grad)\n",
    "            for j in tqdm(range(num_evals)):\n",
    "                roi_size = (128, 128, 128)\n",
    "                sw_batch_size = 64\n",
    "                pred_outputs = sliding_window_inference(\n",
    "                    pred_data[\"image\"],\n",
    "                    roi_size, \n",
    "                    sw_batch_size, \n",
    "                    model,\n",
    "                    sw_device=device,\n",
    "                    device='cpu'\n",
    "                )\n",
    "                pred_outputs = softmax(pred_outputs)\n",
    "                pred_outputs = np.float16(pred_outputs.cpu().detach().numpy())\n",
    "                pred_array[j] = pred_outputs[:]\n",
    "                del pred_outputs\n",
    "            mean = np.float16(pred_array.mean(axis=0))\n",
    "            new_file_name = re.sub('matt_raw_warped','/home/rozakmat/scratch/rrg-bojana/rozakmat/matt_raw_warped_upsampled',data_dicts[i][\"image\"])\n",
    "            np.save(re.sub('scratch/rrg-bojana/rozakmat','projects/rrg-bojana/rozakmat/TBI_monai_UNET',re.sub('.tif','_mean.npy',new_file_name)),mean)\n",
    "            np.save(re.sub('.tif','_pred.npy',new_file_name),pred_array)\n",
    "            print(re.sub('.tif','_mean.npy',new_file_name))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4c2bf6-628c-43d4-bcbf-e1a6304e9117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512, 512, 254])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50810cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "new_file_name = re.sub('matt_raw_warped','/home/rozakmat/scratch/rrg-bojana/rozakmat/matt_raw_warped_upsampled',data_dicts[i][\"image\"])\n",
    "re.sub('scratch/rrg-bojana/rozakmat','projects/rrg-bojana/rozakmat/TBI_monai_',re.sub('.tif','_mean.npy',new_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean = pred_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ff851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae071dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def parallel_apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but takes advantage of multiple\n",
    "    cores.\n",
    "    \"\"\"        \n",
    "    # Effective axis where apply_along_axis() will be applied by each\n",
    "    # worker (any non-zero axis number would work, so as to allow the use\n",
    "    # of `np.array_split()`, which is only done on axis 0):\n",
    "    effective_axis = 1 if axis == 0 else axis\n",
    "    if effective_axis != axis:\n",
    "        arr = arr.swapaxes(axis, effective_axis)\n",
    "\n",
    "    # Chunks for the mapping (only a few chunks):\n",
    "    chunks = [(func1d, effective_axis, sub_arr, args, kwargs)\n",
    "              for sub_arr in np.array_split(arr, multiprocessing.cpu_count())]\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "    individual_results = pool.map(unpacking_apply_along_axis, chunks)\n",
    "    # Freeing the workers:\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return np.concatenate(individual_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "std = pred_array.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit,jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eced27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#@njit\n",
    "#def mean_numba(arr, axis=None):\n",
    "#    \"\"\"\n",
    "#    Computes the unbiased standard deviation of a large numpy array along a given axis,\n",
    "#    using Numba for optimization.\n",
    "#    \"\"\"\n",
    "#    mean = np.mean(arr, axis=axis, keepdims=False)\n",
    "#    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean = pred_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def unbiased_std(arr, axis=None, ddof=1):\n",
    "    \"\"\"\n",
    "    Computes the unbiased standard deviation of a large numpy array along a given axis.\n",
    "    \"\"\"\n",
    "    mean = np.mean(arr, axis=axis, keepdims=True)\n",
    "    variance = np.mean((arr - mean)**2, axis=axis, keepdims=True)\n",
    "    return np.sqrt(variance) * np.sqrt(1 / (arr.shape[axis] - ddof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b45410",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred_array[0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fba08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "std = unbiased_std(pred_array, axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_file_name = re.sub('matt_raw_warped','matt_raw_warped_upsampled',data_dicts[i][\"image\"])\n",
    "np.save(re.sub('.tif','_mean.npy',new_file_name),mean)\n",
    "#np.save(re.sub('.tif','_std.npy',new_file_name),std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105d3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
