{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a247ea0",
   "metadata": {},
   "source": [
    "# Setup Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea02dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import (\n",
    "    first, \n",
    "    set_determinism, \n",
    "    ensure_tuple\n",
    ")\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAffined,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    RandFlipd,\n",
    "    RandGaussianNoised,\n",
    "    RandAdjustContrastd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    AddChanneld,\n",
    "    RandGaussianSharpend,\n",
    "    RandGaussianSmoothd,\n",
    "    RandHistogramShiftd,\n",
    "    OneOf,\n",
    "    Rand3DElasticd,\n",
    "    Rand3DElastic,\n",
    "    RandGridDistortiond,\n",
    "    RandSpatialCropSamplesd,\n",
    "    FillHoles,\n",
    "    LabelFilter,\n",
    "    LabelToContour,\n",
    "    RandCoarseDropoutd\n",
    "    \n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import (\n",
    "    DiceMetric, \n",
    "    HausdorffDistanceMetric\n",
    ")\n",
    "from monai.losses import (\n",
    "    DiceLoss, \n",
    "    DiceCELoss, \n",
    "    DiceFocalLoss\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import (\n",
    "    CacheDataset, \n",
    "    DataLoader, \n",
    "    Dataset, \n",
    "    decollate_batch, \n",
    "    ImageReader\n",
    ")\n",
    "from monai.data.image_reader import WSIReader\n",
    "from monai.config import (\n",
    "    print_config, \n",
    "    KeysCollection, \n",
    "    PathLike\n",
    ")\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "from torchio.transforms import (\n",
    "    RandomAffine\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from numpy import random\n",
    "from pathlib import Path\n",
    "import re\n",
    "from skimage import io\n",
    "from typing import (\n",
    "    Optional, \n",
    "    Union, \n",
    "    Sequence, \n",
    "    Callable, \n",
    "    Dict, \n",
    "    List\n",
    ")\n",
    "#from monai.data.utils import is_supported_format\n",
    "#from monai. data.image_reader import (\n",
    "#    _copy_compatible_dict, \n",
    "#    _stack_images\n",
    "#)\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "#from mlflow import log_metric, log_param, log_artifacts, set_experiment, start_run, end_run\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd325977-7187-4466-b97d-a361e5cb9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7709d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.23.0\n",
      "Pytorch version: 1.10.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.7.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.10.0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.0\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.15.0\n",
      "mlflow version: 1.28.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a98315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TIFFReader(ImageReader):\n",
    "    \n",
    "    def __init__(self, npz_keys: Optional[KeysCollection] = None, channel_dim: Optional[int] = None, **kwargs):\n",
    "        super().__init__()\n",
    "        if npz_keys is not None:\n",
    "            npz_keys = ensure_tuple(npz_keys)\n",
    "        self.npz_keys = npz_keys\n",
    "        self.channel_dim = channel_dim\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def verify_suffix(self, filename: Union[Sequence[PathLike], PathLike]) -> bool:\n",
    "        \"\"\"\n",
    "        Verify whether the specified file or files format is supported by Numpy reader.\n",
    "\n",
    "        Args:\n",
    "            filename: file name or a list of file names to read.\n",
    "                if a list of files, verify all the suffixes.\n",
    "        \"\"\"\n",
    "        suffixes: Sequence[str] = [\"tif\", \"tiff\"]\n",
    "        return is_supported_format(filename, suffixes)\n",
    "\n",
    "    def read(self, data: Union[Sequence[PathLike], PathLike], **kwargs):\n",
    "        \"\"\"\n",
    "        Read image data from specified file or files, it can read a list of `no-channel` data files\n",
    "        and stack them together as multi-channels data in `get_data()`.\n",
    "        Note that the returned object is Numpy array or list of Numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            data: file name or a list of file names to read.\n",
    "            kwargs: additional args for `numpy.load` API except `allow_pickle`, will override `self.kwargs` for existing keys.\n",
    "                More details about available args:\n",
    "                https://numpy.org/doc/stable/reference/generated/numpy.load.html\n",
    "\n",
    "        \"\"\"\n",
    "        img_: List[Nifti1Image] = []\n",
    "\n",
    "        filenames: Sequence[PathLike] = ensure_tuple(data)\n",
    "        kwargs_ = self.kwargs.copy()\n",
    "        kwargs_.update(kwargs)\n",
    "        for name in filenames:\n",
    "            img = io.imread(name, **kwargs_)\n",
    "            img = img.astype('float32')\n",
    "            if len(img.shape)==4:\n",
    "                img = np.swapaxes(img,0,1)\n",
    "                img = np.swapaxes(img,1,3)\n",
    "            img_.append(img)\n",
    "        return img_ if len(img_) > 1 else img_[0]\n",
    "    \n",
    "    def get_data(self, img):\n",
    "        \"\"\"\n",
    "        Extract data array and meta data from loaded image and return them.\n",
    "        This function returns two objects, first is numpy array of image data, second is dict of meta data.\n",
    "        It constructs `affine`, `original_affine`, and `spatial_shape` and stores them in meta dict.\n",
    "        When loading a list of files, they are stacked together at a new dimension as the first dimension,\n",
    "        and the meta data of the first image is used to represent the output meta data.\n",
    "\n",
    "        Args:\n",
    "            img: a Numpy array loaded from a file or a list of Numpy arrays.\n",
    "\n",
    "        \"\"\"\n",
    "        img_array: List[np.ndarray] = []\n",
    "        compatible_meta: Dict = {}\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = (img,)\n",
    "\n",
    "        for i in ensure_tuple(img):\n",
    "            header = {\"affine\":np.eye(5),\n",
    "                     \"labels\": {\"0\": \"background\",\n",
    "                                \"1\": \"vessels\",\n",
    "                                \"2\": \"neurons\",}\n",
    "                     }\n",
    "            if isinstance(i, np.ndarray):\n",
    "                # if `channel_dim` is None, can not detect the channel dim, use all the dims as spatial_shape\n",
    "                spatial_shape = np.asarray(i.shape)\n",
    "                if isinstance(self.channel_dim, int):\n",
    "                    spatial_shape = np.delete(spatial_shape, self.channel_dim)\n",
    "                header[\"spatial_shape\"] = spatial_shape\n",
    "            img_array.append(i)\n",
    "            header[\"original_channel_dim\"] = self.channel_dim if isinstance(self.channel_dim, int) else \"no_channel\"\n",
    "            _copy_compatible_dict(header, compatible_meta)\n",
    "\n",
    "        return _stack_images(img_array, compatible_meta), compatible_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db1586",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd15ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = 'hyperparameter_pickle_files/parameters436.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9edd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = re.sub('.pickle',\n",
    "                    '',\n",
    "                    re.sub('hyperparameter_pickle_files/parameters',\n",
    "                           '',\n",
    "                           parameter_file\n",
    "                          )\n",
    "                   )\n",
    "#set_experiment(\"TBI_UNet_adam_optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a34ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parameter_file, 'rb') as handle:\n",
    "    params = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f94a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crop_size': (128, 128, 128),\n",
       " 'N_crops': 8,\n",
       " 'optimizer': torch.optim.adam.Adam,\n",
       " 'batch_size': 1,\n",
       " 'max_epochs': 1000,\n",
       " 'intensity_transform_probability': 0.5,\n",
       " 'gaussian_transform_probability': 0.5,\n",
       " 'rotation_flip_transforms_probability': 0.5,\n",
       " 'deformation_transforms_prob': 0.5,\n",
       " 'Rand3DElasticd_sigma_range': (1, 3),\n",
       " 'Rand3DElasticd_magnitude_range': (3, 15),\n",
       " 'RandGridDistortiond_num_cells': 8,\n",
       " 'RandGridDistortiond_distort_limit': (-0.3, 0.3),\n",
       " 'RandShiftIntensityd_offsets': 0.4,\n",
       " 'RandAdjustContrastd_gamma': (0.5, 5.5),\n",
       " 'RandHistogramShiftd_num_control_points': 4,\n",
       " 'RandGaussianNoised_mean': 0,\n",
       " 'RandGaussianNoised_std': 0.2,\n",
       " 'RandomAffine_probability': 0.5,\n",
       " 'RandomAffine_degrees': (20, 20, 20),\n",
       " 'RandomAffine_scales': (0.1, 0.1, 0.1),\n",
       " 'RandomAffine_translation': (0.1, 0.1, 0.1),\n",
       " 'norm': 'INSTANCE',\n",
       " 'dropout': 0.1,\n",
       " 'learning_rate': 1e-05,\n",
       " 'num_res_units': 2,\n",
       " 'loss_function': DiceCELoss(\n",
       "   (dice): DiceLoss()\n",
       "   (cross_entropy): CrossEntropyLoss()\n",
       " )}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85ed99",
   "metadata": {},
   "source": [
    "# setup directory to save enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae47144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'training_models/436'\n",
      "training_models/436\n"
     ]
    }
   ],
   "source": [
    "directory = re.sub('.pickle',\n",
    "                   '',\n",
    "                   re.sub('hyperparameter_pickle_files/parameters',\n",
    "                          'training_models/',\n",
    "                           parameter_file\n",
    "                         )\n",
    "                  )\n",
    "try:\n",
    "    os.mkdir(directory)\n",
    "except OSError as error:\n",
    "    print(error) \n",
    "#log_artifacts(directory)\n",
    "print(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d8fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_models/436'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529c608",
   "metadata": {},
   "source": [
    "# get train and validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b589c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of data dictionaries\n",
    "train_images_path = Path('../TBI/GT_filtered+raw/') #raw path images\n",
    "train_images_paths = list(train_images_path.glob('*.tif'))#get images\n",
    "train_images = sorted([x.as_posix() for x in train_images_paths])#sort\n",
    "train_labels_path = Path('../TBI/GT_filtered+raw/')#labels path\n",
    "train_labels = list(train_labels_path.glob('*sub1.tiff'))#get label images\n",
    "train_labels = sorted([x.as_posix() for x in train_labels])#sort\n",
    "#combine images and labels into monai dictionary format\n",
    "data_dicts = [\n",
    "    {\"image\":image_name, \"label\":label_name}\n",
    "    for image_name, label_name in zip(train_images,train_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6881b680-edde-43de-bbf3-41f616993bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../TBI/GT_filtered+raw/Result_of_XYZres114_0001.tif'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36bd9090-f3ca-4d85-b9a6-b410193cd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dicts))\n",
    "print(len(mouse_ids_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33dd23b6-d248-4976-be26-3f081b06185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200217_11',\n",
       " '20200217_12',\n",
       " '20200217_14',\n",
       " '20200217_17',\n",
       " '20200217_7',\n",
       " '20200217_9',\n",
       " '20200227_18',\n",
       " '20200227_20',\n",
       " '20200227_22',\n",
       " '20200227_23',\n",
       " '20200411_26',\n",
       " '20200411_28',\n",
       " '20200525_32',\n",
       " '20201201_33',\n",
       " '20201201_35',\n",
       " '20201221_38',\n",
       " '20202112_40',\n",
       " 'vbm03 Feb 26 2020',\n",
       " 'vbm04 Feb 27 2020',\n",
       " 'vbm05 Feb 28 2020',\n",
       " 'vbm07 Mar 24 2020',\n",
       " 'vbm08 Mar 27 2020',\n",
       " 'vbm09 Mar 28 2020',\n",
       " 'vbm10 Apr 03 2020',\n",
       " 'vbm11 Apr 04 2020']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mouse_ids_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b89e662-6121-40f4-817f-7baff792861d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TBI_mice = [\"_7\",\"_11\",\"_14\",\"_18\",\"_22\",\"_26\",\"_28\",\"_33\"]\n",
    "len([x for x in mouse_ids_with_raw_tiff_flat if any(y in x for y in TBI_mice)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73d78c47-ea3a-41bb-8a62-cc845986a383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in mouse_ids_with_raw_tiff_flat if 'vbm' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ffd42eb-5831-4589-9c07-79fb5135115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_with_raw_tiff_flat = [x.as_posix() for x in mouse_ids_with_raw_tiff_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "467b7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_path = Path('../TBI/raw')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*'))#grab molder names/mouse ids\n",
    "images = sorted([y.name for y in train_images_paths])#sort\n",
    "#get mouse id corresponding to each image i have labels for\n",
    "mouse_ids_with_raw_tiff = []\n",
    "for i in mouse_ids:\n",
    "    for j in images:\n",
    "        if len(list(i.glob(j))) !=0:\n",
    "            mouse_ids_with_raw_tiff.append(list(i.glob(j)))\n",
    "#flatten the list and sort\n",
    "mouse_ids_with_raw_tiff_flat = [item for sublist in mouse_ids_with_raw_tiff for item in sublist]\n",
    "mouse_ids_with_raw_tiff_flat = sorted(mouse_ids_with_raw_tiff_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf680925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle mouse ids for a 15/4/6 split train/val/test by mouse id\n",
    "mouse_ids_present = [i.parent.name for i in mouse_ids_with_raw_tiff_flat]\n",
    "mouse_ids_present = sorted(list(np.unique(mouse_ids_present)))\n",
    "np.random.seed(643)\n",
    "np.random.shuffle(mouse_ids_present)\n",
    "mouse_ids_present\n",
    "train = sorted(mouse_ids_present[:15])\n",
    "#log_param('train_set',' '.join(train))\n",
    "val = mouse_ids_present[15:-6]\n",
    "#log_param('val_set',' '.join(val))\n",
    "test = mouse_ids_present[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36479b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "for i in train:\n",
    "    for j in mouse_ids_with_raw_tiff_flat:\n",
    "        if i in j.as_posix():\n",
    "            for k in data_dicts:\n",
    "                if j.name in k[\"image\"]:\n",
    "                    train_files.append(k)\n",
    "for i in val:\n",
    "    for j in mouse_ids_with_raw_tiff_flat:\n",
    "        if i in j.as_posix():\n",
    "            for k in data_dicts:\n",
    "                if j.name in k[\"image\"]:\n",
    "                    val_files.append(k)\n",
    "for i in test:\n",
    "    for j in mouse_ids_with_raw_tiff_flat:\n",
    "        if i in j.as_posix():\n",
    "            for k in data_dicts:\n",
    "                if j.name in k[\"image\"]:\n",
    "                    test_files.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74068ff1-ae80-482b-bfaa-80bc8ba07943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200217_12',\n",
       " '20200217_17',\n",
       " '20200217_7',\n",
       " '20200217_9',\n",
       " '20200227_18',\n",
       " '20200227_20',\n",
       " '20200227_23',\n",
       " '20200411_26',\n",
       " '20201201_33',\n",
       " '20201201_35',\n",
       " '20201221_38',\n",
       " '20202112_40',\n",
       " 'vbm08 Mar 27 2020',\n",
       " 'vbm09 Mar 28 2020',\n",
       " 'vbm10 Apr 03 2020']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f46bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x['label'] for x in val_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0ce915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': '../TBI/GT_filtered+raw/XYZres008.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres008_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres92.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres92_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres95_0001.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres95_0001_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres025.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres025_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres018_0001.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres018_0001_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres110.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres110_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres114_0001.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres114_0001_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres201.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres201_Simple Segmentation_sub1.tiff'},\n",
       " {'image': '../TBI/GT_filtered+raw/XYZres204_0001.tif',\n",
       "  'label': '../TBI/GT_filtered+raw/XYZres204_0001_Simple Segmentation_sub1.tiff'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57ca85",
   "metadata": {},
   "source": [
    "# Set deterministic training for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d67cb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e78a1",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation\n",
    "\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. `LoadImaged` loads the spleen CT images and labels from NIfTI format files.\n",
    "1. `AddChanneld` as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "1. `Spacingd` adjusts the spacing by `pixdim=(1.5, 1.5, 2.)` based on the affine matrix.\n",
    "1. `Orientationd` unifies the data orientation based on the affine matrix.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "1. `RandAffined` efficiently performs `rotate`, `scale`, `shear`, `translate`, etc. together based on PyTorch affine transform.\n",
    "1. `EnsureTyped` converts the numpy array to PyTorch Tensor for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "826a3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"], reader = TIFFReader(channel_dim = 0)),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1.01, 1.01, 0.3787), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1024,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"label\",\n",
    "                   rounding='torchrounding',\n",
    "                   to_onehot=True),\n",
    "        #random cropping\n",
    "        RandSpatialCropSamplesd(\n",
    "            keys=['image','label'],\n",
    "            num_samples = 6,#params['N_crops'],\n",
    "            roi_size = params['crop_size'],\n",
    "            random_size = False\n",
    "        ),\n",
    "        #Deformation_transforms\n",
    "        OneOf(transforms=[Rand3DElasticd(keys = [\"image\",\"label\"],\n",
    "                                        sigma_range = params['Rand3DElasticd_sigma_range'],\n",
    "                                        magnitude_range = params['Rand3DElasticd_magnitude_range'],\n",
    "                                        prob = params[\"deformation_transforms_prob\"],\n",
    "                                        mode = [\"bilinear\",\"nearest\"]),\n",
    "                          RandGridDistortiond(keys = [\"image\",\"label\"],\n",
    "                                             num_cells = params['RandGridDistortiond_num_cells'],\n",
    "                                             prob = params[\"deformation_transforms_prob\"],\n",
    "                                             distort_limit = params['RandGridDistortiond_distort_limit'],\n",
    "                                             mode = [\"bilinear\",\"nearest\"]\n",
    "                                             )\n",
    "                         ]\n",
    "             ),\n",
    "        #Intensity_Transforms\n",
    "        OneOf(transforms = [RandShiftIntensityd(keys = [\"image\"],\n",
    "                                                offsets = params['RandShiftIntensityd_offsets'],\n",
    "                                                prob = params[\"intensity_transform_probability\"]),\n",
    "                            RandAdjustContrastd(keys = [\"image\"],\n",
    "                                                prob = params[\"intensity_transform_probability\"],\n",
    "                                                gamma = params['RandAdjustContrastd_gamma']),\n",
    "                            RandHistogramShiftd(keys = [\"image\"],\n",
    "                                                prob = params[\"intensity_transform_probability\"],\n",
    "                                                num_control_points = params['RandHistogramShiftd_num_control_points'])\n",
    "                           ]\n",
    "             ),\n",
    "        #Gaussian_Transforms\n",
    "        OneOf(transforms = [RandGaussianSharpend(keys = [\"image\"],\n",
    "                                                 prob = params[\"gaussian_transform_probability\"]),\n",
    "                            RandGaussianSmoothd(keys = [\"image\"],\n",
    "                                                prob = params[\"gaussian_transform_probability\"]),\n",
    "                            RandGaussianNoised(keys = [\"image\"],\n",
    "                                               prob = params[\"gaussian_transform_probability\"],\n",
    "                                               mean = params['RandGaussianNoised_mean'],\n",
    "                                               std = params['RandGaussianNoised_std'])\n",
    "                           ]\n",
    "             ),\n",
    "        RandCoarseDropoutd(keys = [\"image\"],\n",
    "                           prob=0.75,\n",
    "                           holes = 50,\n",
    "                           spatial_size=2,\n",
    "                           max_holes = 1000,\n",
    "                           max_spatial_size=6,\n",
    "                           fill_value = (0.0001,0.1)\n",
    "        ),\n",
    "        #rottion+flip_transforms\n",
    "        RandRotate90d(\n",
    "            keys = [\"image\", \"label\"],\n",
    "            prob = params['rotation_flip_transforms_probability'],\n",
    "            max_k = 3,\n",
    "            spatial_axes=(0,1)\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys = [\"image\", \"label\"],\n",
    "            spatial_axis = [0],\n",
    "            prob = params['rotation_flip_transforms_probability'],\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys = [\"image\", \"label\"],\n",
    "            spatial_axis = [1],\n",
    "            prob = params['rotation_flip_transforms_probability'],\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys = [\"image\", \"label\"],\n",
    "            spatial_axis = [2],\n",
    "            prob = params['rotation_flip_transforms_probability'],\n",
    "        ),\n",
    "        #random affine\n",
    "        RandomAffine(\n",
    "            include=[\"image\", \"label\"], \n",
    "            p=params[\"RandomAffine_probability\"], \n",
    "            degrees=params[\"RandomAffine_degrees\"], \n",
    "            scales=params[\"RandomAffine_scales\"],\n",
    "            translation=params[\"RandomAffine_translation\"],\n",
    "            center='image'\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"],reader = TIFFReader(channel_dim = 0)),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1.01, 1.01, 0.3787), mode=(\"bilinear\", \"nearest\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1024,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"label\",\n",
    "                   rounding='torchrounding',\n",
    "                   to_onehot=True),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#val_transforms_deform = Compose(\n",
    "#    [\n",
    "#        LoadImaged(keys=[\"image\", \"label\"],reader = TIFFReader(channel_dim = 0)),\n",
    "#        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "#        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "#            1.01, 1.01, 0.3787), mode=(\"bilinear\", \"nearest\")),\n",
    "#        ScaleIntensityRanged(\n",
    "#            keys=[\"image\"], a_min=0, a_max=1024,\n",
    "#            b_min=0.0, b_max=1.0, clip=True,\n",
    "#        ),\n",
    "#        AsDiscreted(keys=\"label\",\n",
    "#                   rounding='torchrounding',\n",
    "#                   to_onehot=True),\n",
    "#        Rand3DElasticd(keys = [\"image\",\"label\"],\n",
    "#                              sigma_range = (1,2),\n",
    "#                              magnitude_range = (3,4),\n",
    "#                              prob = 1,\n",
    "#                              mode = [\"bilinear\",\"nearest\"]\n",
    "#                      ),\n",
    "#        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104ebdd",
   "metadata": {},
   "source": [
    "# Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cae63422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres050.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres050_Simple Segmentation_sub1.tiff\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.compose.Compose object at 0x146ceb788970>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/io/dictionary.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key_postfix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_key_postfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/io/array.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, filename, reader)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3890830/2019029274.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_channel_dim\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_dim\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"no_channel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0m_copy_compatible_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatible_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_copy_compatible_dict' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_transform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0m_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"applying transform {transform}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x146ceb788460>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3890830/2880789755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheck_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheck_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheck_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"image shape: {image.shape}, label shape: {label.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/utils/misc.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(iterable, default)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeaningful\u001b[0m \u001b[0mmostly\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m'for'\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0mdata_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0m_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"applying transform {transform}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.compose.Compose object at 0x146ceb788970>"
     ]
    }
   ],
   "source": [
    "check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0], check_data[\"label\"][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [ :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "img2 = torch.transpose(image[:,:, :, 80],0,2)\n",
    "img2 = img2.cpu().detach().numpy()\n",
    "img2 = np.append(img2,np.zeros((507,507,1)), axis=2)/np.max(img2)\n",
    "plt.imshow(img2, cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "img3 = torch.transpose(label[:,:, :, 80],0,2)\n",
    "img3 = img3.cpu().detach().numpy()\n",
    "plt.imshow(img3)\n",
    "plt.show()\n",
    "\n",
    "#check_ds = Dataset(data=val_files, transform=val_transforms_deform)\n",
    "#check_loader = DataLoader(check_ds, batch_size=1)\n",
    "#check_data = first(check_loader)\n",
    "#image2, label2 = (check_data[\"image\"][0], check_data[\"label\"][0])\n",
    "#print(f\"image shape: {image2.shape}, label shape: {label2.shape}\")\n",
    "## plot the slice [ :, 80]\n",
    "#plt.figure(\"check\", (12, 6))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.title(\"image\")\n",
    "#img2 = torch.swapaxes(image2[:,:, :, 80],0,2)\n",
    "#img2 = img2.cpu().detach().numpy()\n",
    "#img2 = np.append(img2,np.zeros((507,507,1)), axis=2)/np.max(img2)\n",
    "#plt.imshow(img2, cmap=\"gray\")\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.title(\"label\")\n",
    "#img3 = torch.swapaxes(label2[:,:, :, 80],0,2)\n",
    "#img3 = img3.cpu().detach().numpy()\n",
    "#plt.imshow(img3)\n",
    "#plt.show()\n",
    "#\n",
    "#post_label = Compose([EnsureType(), AsDiscrete(to_onehot=3)])\n",
    "#\n",
    "#label = post_label(label)\n",
    "#label2 = post_label(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_filter = Compose([EnsureType(), LabelFilter(applied_labels=(1))])\n",
    "#\n",
    "#dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "#label = label_filter(label)\n",
    "#label2 = label_filter(label2)\n",
    "#contour = LabelToContour()(label_filter(label))\n",
    "##print(contour.shape)\n",
    "#contour2 = LabelToContour()(label_filter(label2))\n",
    "#dice_metric(y_pred=contour, y=contour2)\n",
    "#metric = dice_metric.aggregate().item()\n",
    "#dice_metric.reset()\n",
    "#print(metric)\n",
    "#print(\"boundary difference\",torch.sum(contour2.ne(contour).long()))\n",
    "#print(\"total boundary size\",torch.sum(contour2.ne(contour).long())/torch.sum(contour)*100)\n",
    "#label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bed12",
   "metadata": {},
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d151d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct  9 12:35:35 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7afc0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ps aux | grep python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77c7a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill 248521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1f9b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250.tif\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250_Simple Segmentation_sub1.tiff\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres250_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres76_0001_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres71_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres245_0001_Simple Segmentation_sub1.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x146ceb7093d0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/io/dictionary.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key_postfix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_key_postfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/io/array.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, filename, reader)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3890830/2019029274.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_channel_dim\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_dim\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"no_channel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0m_copy_compatible_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatible_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_copy_compatible_dict' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3890830/245829726.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ds = CacheDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcache_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, transform, cache_num, cache_rate, num_workers, progress, copy_cache)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_fill_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 return list(\n\u001b[0m\u001b[1;32m    629\u001b[0m                     tqdm(\n\u001b[1;32m    630\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_cache_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_load_cache_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0m_xform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThreadUnsafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_xform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0m_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"applying transform {transform}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x146ceb7093d0>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres128_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres042_0001_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres032_Simple Segmentation_sub1.tiff\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001.tif\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: ../TBI/GT_filtered+raw/XYZres131_0001_Simple Segmentation_sub1.tiff\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data = train_files, \n",
    "    transform = train_transforms,\n",
    "    cache_rate = 1.0, \n",
    "    num_workers = 4\n",
    ")\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=2,#params[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data = val_files, \n",
    "    transform = val_transforms, \n",
    "    cache_rate = 1.0, \n",
    "    num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size = 1, \n",
    "    num_workers = 4\n",
    ")\n",
    "\n",
    "#val_ds_deform = CacheDataset(\n",
    "#    data=val_files, transform=val_transforms_deform, cache_rate=1.0, num_workers=4)\n",
    "#val_loader_deform = DataLoader(val_ds_deform, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594f58c",
   "metadata": {},
   "source": [
    "# Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8d8b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNETR(\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    img_size = (128,128,128),\n",
    "    feature_size = 16,\n",
    "    hidden_size = 768,\n",
    "    mlp_dim = 3072,\n",
    "    pos_embed = \"perceptron\",\n",
    "    res_block=True,\n",
    "    norm_name=\"instance\",\n",
    "    dropout_rate=params[\"dropout\"]\n",
    ")\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load(\n",
    "#    os.path.join(directory, \"best_metric_model.pth\")))\n",
    "loss_function = DiceFocalLoss(to_onehot_y=True, softmax=True, include_background=True, focal_weight=[0.025,0.95,0.025], squared_pred=True, jaccard=False)#params['loss_function']\n",
    "optimizer = params['optimizer'](params = model.parameters(), \n",
    "                                lr = 1e-4)#params['learning_rate'])\n",
    "dice_metric = DiceMetric(\n",
    "    include_background=False,\n",
    "    reduction=\"mean\"\n",
    ")\n",
    "#hausdorf_distance_metric = HausdorffDistanceMetric(include_background=False,\n",
    "#                                                   distance_metric='euclidean')\n",
    "dice_metric_deform = DiceMetric(\n",
    "    include_background = False,\n",
    "    reduction = \"mean\"\n",
    ")\n",
    "dice_metric_deform_boundary_difference = DiceMetric(\n",
    "    include_background = False,\n",
    "    reduction = \"mean\"\n",
    ")\n",
    "dice_metric_predicted_deform_boundary_difference = DiceMetric(\n",
    "    include_background = False,\n",
    "    reduction = \"mean\"\n",
    ")\n",
    "dice_metric_boundary_difference_detection = DiceMetric(\n",
    "    include_background = False,\n",
    "    reduction = \"mean\"\n",
    ")\n",
    "label_filter = Compose(\n",
    "    [EnsureType(),\n",
    "     LabelFilter(applied_labels = (1))\n",
    "    ]\n",
    ")\n",
    "deform = Rand3DElastic(\n",
    "    sigma_range = (1,2),\n",
    "    magnitude_range = (3,4),\n",
    "    prob = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9592511",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3287279/4187007541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee82911",
   "metadata": {},
   "source": [
    "# Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d838c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12)\n",
    "max_epochs = params[\"max_epochs\"]\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "#hausdorf_distance_values = []\n",
    "metric_values_deform = []\n",
    "metric_values_deform_boundary_difference = []\n",
    "metric_values_predicted_deform_boundary_difference = []\n",
    "metric_values_boundary_difference_detection = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True,to_onehot=3)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=3)])\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    log_metric('epoch_loss',epoch_loss, step = epoch)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                seed = random.randint(0,10000000)\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                #val_inputs_deform, val_labels_deform = (\n",
    "                #    val_data_deform[\"image\"].to(device),\n",
    "                #    val_data_deform[\"label\"].to(device),\n",
    "                #)\n",
    "                roi_size = (128, 128, 128)\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_inputs, \n",
    "                    roi_size, \n",
    "                    sw_batch_size, \n",
    "                    model\n",
    "                )\n",
    "                #get prediciton output\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                filled  = [FillHoles(connectivity=2)(i) for i in val_outputs]\n",
    "                #deform raw image\n",
    "                deform.set_random_state(seed = seed)\n",
    "                deform_val_inputs = torch.unsqueeze(deform(torch.squeeze(val_inputs),mode='bilinear'),axis=0)\n",
    "                #deform validation output\n",
    "                deform.set_random_state(seed = seed)\n",
    "                deform_val_outputs_gt = deform(filled[0],mode='nearest')\n",
    "                #predict on deformed raw image\n",
    "                deform_val_outputs =sliding_window_inference(\n",
    "                    deform_val_inputs, \n",
    "                    roi_size, \n",
    "                    sw_batch_size, \n",
    "                    model\n",
    "                )   \n",
    "                # get predicted outputs\n",
    "                val_outputs_deform = [post_pred(i) for i in decollate_batch(deform_val_outputs)]\n",
    "                #fill holes in prediction\n",
    "                filled_deform  = [FillHoles(connectivity=2)(i) for i in val_outputs_deform]\n",
    "                #generated boundaries from predictions\n",
    "                filled_vessels_boundary = [LabelToContour()(label_filter(i)) for i in filled]\n",
    "                filled_vessels_boundary_deform = [LabelToContour()(label_filter(i)) for i in filled_deform]\n",
    "                #get labelled data\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                #print(val_labels.shape)\n",
    "                val_labels_deform = [deform_val_outputs_gt]\n",
    "                #get validation boundaries\n",
    "                val_labels_boundary = [LabelToContour()(i) for i in val_labels]\n",
    "                val_outputs_boundary_deform = [LabelToContour()(i) for i in val_labels_deform]\n",
    "                # compute metric for current iteration\n",
    "                #dice metric for ground truth and prediction\n",
    "                dice_metric(\n",
    "                    y_pred = filled,\n",
    "                    y = val_labels\n",
    "                )\n",
    "                #hausdorf_distance_metric(y_pred=filled, \n",
    "                #                         y=val_labels)\n",
    "                #dice metric for deformed output, and prediction on deformed raw image\n",
    "                dice_metric_deform(\n",
    "                    y_pred = filled_deform,\n",
    "                    y = val_outputs_deform\n",
    "                )\n",
    "                #dice metric for boundary of ground truth and deformed ground truth\n",
    "                #measures how much the boundary was deformed\n",
    "                dice_metric_deform_boundary_difference(\n",
    "                    y_pred = val_outputs_boundary_deform,\n",
    "                    y = filled_vessels_boundary\n",
    "                )\n",
    "                \n",
    "                dice_metric_predicted_deform_boundary_difference(\n",
    "                    y_pred=val_outputs_boundary_deform[0],\n",
    "                    y=filled_vessels_boundary_deform[0]\n",
    "                )\n",
    "                #dice metric for boundary difference detection\n",
    "                dice_metric_boundary_difference_detection(\n",
    "                    y_pred = filled_vessels_boundary_deform[0].ne(filled_vessels_boundary[0]).int()[1],\n",
    "                    y = val_outputs_boundary_deform[0].ne(filled_vessels_boundary[0]).int()[1]\n",
    "                )\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice',\n",
    "                metric,\n",
    "                step = epoch\n",
    "            )\n",
    "            #hausdorf_distance = hausdorf_distance_metric.aggregate().item()\n",
    "            #aggregate the dice score for the prediction fo the deformed raw image againsed the deformed prediction\n",
    "            metric_deform = dice_metric_deform.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice_deformed_validation',\n",
    "                metric_deform,\n",
    "                step = epoch\n",
    "            )\n",
    "            metric_deform_boundary_difference = dice_metric_deform_boundary_difference.aggregate().item()\n",
    "            log_metric(\n",
    "                'ground_truths_boundary_dice',\n",
    "                metric_deform_boundary_difference,\n",
    "                step = epoch\n",
    "            )\n",
    "            metric_predicted_deform_boundary_difference = dice_metric_predicted_deform_boundary_difference.aggregate().item()\n",
    "            log_metric(\n",
    "                'predicted_boundary_dice',\n",
    "                metric_predicted_deform_boundary_difference,\n",
    "                step = epoch\n",
    "            )\n",
    "            metric_boundary_difference_detection = dice_metric_boundary_difference_detection.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice_deformed_boundary_ground_truth_to_prediction',\n",
    "                metric_boundary_difference_detection,\n",
    "                step = epoch\n",
    "            )\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            #hausdorf_distance_metric.reset()\n",
    "            dice_metric_deform.reset()\n",
    "            dice_metric_deform_boundary_difference.reset()\n",
    "            #dice_metric_predicted_deform_boundary_difference.reset()\n",
    "            dice_metric_boundary_difference_detection.reset()\n",
    "\n",
    "            metric_values.append(\n",
    "                metric\n",
    "            )\n",
    "            #hausdorf_distance_values.append(\n",
    "            #    hausdorf_distance\n",
    "            #)\n",
    "            metric_values_deform.append(\n",
    "                metric_deform\n",
    "            )\n",
    "            metric_values_deform_boundary_difference.append(\n",
    "                metric_deform_boundary_difference\n",
    "            )\n",
    "            metric_values_predicted_deform_boundary_difference.append(\n",
    "                metric_predicted_deform_boundary_difference\n",
    "            )\n",
    "            metric_values_boundary_difference_detection.append(\n",
    "                metric_boundary_difference_detection\n",
    "            )\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    directory, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                #f\"\\ncurrent mean hausdorf distance: {hausdorf_distance:.4f}\"\n",
    "                f\"\\ncurrent mean dice of deformed mask to predicted deformed image: {metric_deform:.4f}\"\n",
    "                f\"\\ncurrent mean dice of boundary of ground truth, and  boundary of deformed ground truth: {metric_deform_boundary_difference:.5f}\"\n",
    "                #f\"\\ncurrent mean dice of preficted boundary, and predicted deformed boundary: {metric_predicted_deform_boundary_difference:.5f}\"\n",
    "                f\"\\ncurrent mean dice of the boundary difference due to deformation: {metric_boundary_difference_detection:.5f}\"\n",
    "                #f\"\\nratio of dice of boundary deformation to ground truth on prediction and ground truth:{metric_predicted_deform_boundary_difference/metric_deform_boundary_difference}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "img2 = torch.transpose(val_outputs_boundary_deform[0][:,:, :, 80],0,2)\n",
    "img2 = img2.cpu().detach().numpy()\n",
    "#img2 = np.append(img2,np.zeros((507,507,1)), axis=2)/np.max(img2)\n",
    "plt.imshow(img2[:,:,1], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "img3 = torch.transpose(val_labels_boundary[0][:,:, :, 80],0,2)\n",
    "img3 = img3.cpu().detach().numpy()\n",
    "plt.imshow(img3[:,:,1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bab334",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "img2 = torch.transpose(filled_vessels_boundary_deform[0][:,:, :, 80],0,2)\n",
    "img2 = img2.cpu().detach().numpy()\n",
    "#img2 = np.append(img2,np.zeros((507,507,1)), axis=2)/np.max(img2)\n",
    "plt.imshow(img2[:,:,1], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "img3 = torch.transpose(filled_vessels_boundary[0][:,:, :, 80],0,2)\n",
    "img3 = img3.cpu().detach().numpy()\n",
    "plt.imshow(img3[:,:,1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = filled_vessels_boundary_deform[0].ne(filled_vessels_boundary[0]).int()[1]\n",
    "y = val_outputs_boundary_deform[0].ne(filled_vessels_boundary[0]).int()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8554bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = filled_vessels_boundary_deform[0].ne(val_labels_boundary[0]).int()[1]\n",
    "#y = val_outputs_boundary_deform[0].ne(filled_vessels_boundary[0]).int()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\"\n",
    ")\n",
    "#record_metric(\"best_epoch\",best_metric_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63629867",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "img2 = y_pred[:,:, 80]\n",
    "img2 = img2.cpu().detach().numpy()\n",
    "#img2 = np.append(img2,np.zeros((507,507,1)), axis=2)/np.max(img2)\n",
    "plt.imshow(img2[:,:], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "img3 = y[:, :, 80]\n",
    "img3 = img3.cpu().detach().numpy()\n",
    "plt.imshow(img3[:,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a4342",
   "metadata": {},
   "source": [
    "# Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf847a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Epoch_Average_Loss'] = epoch_loss_values\n",
    "df.to_csv(directory + '/metrics_loss.csv')\n",
    "df = pd.DataFrame()\n",
    "df['Val_Mean_Dice'] = metric_values\n",
    "df['boundary_detection_dice'] = metric_values_boundary_difference_detection\n",
    "df['boundary_difference_dice'] = metric_values_deform_boundary_difference\n",
    "#df.to_csv(directory + '/metrics_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca73c3e",
   "metadata": {},
   "source": [
    "# Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.savefig(directory +'ipynb_trial_Val_Loss+Dice.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47279946",
   "metadata": {},
   "source": [
    "# Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(directory, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "        )\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.argmax(\n",
    "            val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
    "        plt.show()\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1a1da",
   "metadata": {},
   "source": [
    "# Evaluation on original image spacings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36985eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(\n",
    "            1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_org_ds = Dataset(\n",
    "    data=val_files, transform=val_org_transforms)\n",
    "val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "    EnsureTyped(keys=\"pred\"),\n",
    "    Invertd(\n",
    "        keys=\"pred\",\n",
    "        transform=val_org_transforms,\n",
    "        orig_keys=\"image\",\n",
    "        meta_keys=\"pred_meta_dict\",\n",
    "        orig_meta_keys=\"image_meta_dict\",\n",
    "        meta_key_postfix=\"meta_dict\",\n",
    "        nearest_interp=False,\n",
    "        to_tensor=True,\n",
    "    ),\n",
    "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
    "    AsDiscreted(keys=\"label\", to_onehot=2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(directory, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_data in val_org_loader:\n",
    "        val_inputs = val_data[\"image\"].to(device)\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        val_data[\"pred\"] = sliding_window_inference(\n",
    "            val_inputs, roi_size, sw_batch_size, model)\n",
    "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
    "        val_outputs, val_labels = from_engine([\"pred\", \"label\"])(val_data)\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "    # aggregate the final mean dice result\n",
    "    metric_org = dice_metric.aggregate().item()\n",
    "    # reset the status for next validation round\n",
    "    dice_metric.reset()\n",
    "\n",
    "print(\"Metric on original image spacing: \", metric_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f0e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabfb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12)\n",
    "max_epochs = params[\"max_epochs\"]\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "#hausdorf_distance_values = []\n",
    "metric_values_deform = []\n",
    "metric_values_deform_boundary_difference = []\n",
    "metric_values_predicted_deform_boundary_difference = []\n",
    "metric_values_boundary_difference_detection = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True,to_onehot=3)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=3)])\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    log_metric('epoch_loss',epoch_loss, step = epoch)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                seed = random.randint(0,10000000)\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (128, 128, 128)\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_inputs, \n",
    "                    roi_size, \n",
    "                    sw_batch_size, \n",
    "                    model\n",
    "                )\n",
    "                #get prediciton output\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                #deform raw image\n",
    "                deform.set_random_state(seed = seed)\n",
    "                deform_val_inputs = torch.unsqueeze(deform(torch.squeeze(val_inputs),mode='bilinear'),axis=0)\n",
    "                #deform validation output\n",
    "                deform.set_random_state(seed = seed)\n",
    "                deform_val_outputs_gt = deform(val_outputs[0],mode='nearest')\n",
    "                #predict on deformed raw image\n",
    "                deform_val_outputs =sliding_window_inference(\n",
    "                    deform_val_inputs, \n",
    "                    roi_size, \n",
    "                    sw_batch_size, \n",
    "                    model\n",
    "                )   \n",
    "                # get predicted outputs\n",
    "                val_outputs_deform = [post_pred(i) for i in decollate_batch(deform_val_outputs)]\n",
    "                #fill holes in prediction\n",
    "                filled  = [FillHoles(applied_labels=[1],connectivity=2)(i) for i in val_outputs]\n",
    "                filled_deform  = [FillHoles(applied_labels=[1],connectivity=2)(i) for i in val_outputs_deform]\n",
    "                #generated boundaries from predictions\n",
    "                filled_vessels_boundary = [LabelToContour()(label_filter(i)) for i in filled]\n",
    "                filled_vessels_boundary_deform = [LabelToContour()(label_filter(i)) for i in filled_deform]\n",
    "                #get labelled data\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                #print(val_labels.shape)\n",
    "                val_labels_deform = [deform_val_outputs_gt]\n",
    "                #get validation boundaries\n",
    "                val_labels_boundary = [LabelToContour()(i) for i in val_labels]\n",
    "                val_outputs_boundary_deform = [LabelToContour()(i) for i in val_labels_deform]\n",
    "                # compute metric for current iteration\n",
    "                #dice metric for ground truth and prediction\n",
    "                dice_metric(\n",
    "                    y_pred = filled,\n",
    "                    y = val_labels\n",
    "                )\n",
    "                #hausdorf_distance_metric(y_pred=filled, \n",
    "                #                         y=val_labels)\n",
    "                #dice metric for deformed output, and prediction on deformed raw image\n",
    "                dice_metric_deform(\n",
    "                    y_pred = filled_deform,\n",
    "                    y = val_outputs_deform\n",
    "                )\n",
    "                #dice metric for boundary of ground truth and deformed ground truth\n",
    "                #measures how much the boundary was deformed\n",
    "                dice_metric_deform_boundary_difference(\n",
    "                    y_pred = val_outputs_boundary_deform,\n",
    "                    y = filled_vessels_boundary\n",
    "                )\n",
    "                #dice metric for boundary difference detection\n",
    "                dice_metric_boundary_difference_detection(\n",
    "                    y_pred=val_outputs_boundary_deform[0],\n",
    "                    y=filled_vessels_boundary_deform[0]\n",
    "                )\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice',\n",
    "                metric,\n",
    "                step = epoch\n",
    "            )\n",
    "            #hausdorf_distance = hausdorf_distance_metric.aggregate().item()\n",
    "            #aggregate the dice score for the prediction fo the deformed raw image againsed the deformed prediction\n",
    "            metric_deform = dice_metric_deform.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice_deformed_validation',\n",
    "                metric_deform,\n",
    "                step = epoch\n",
    "            )\n",
    "            metric_deform_boundary_difference = dice_metric_deform_boundary_difference.aggregate().item()\n",
    "            log_metric(\n",
    "                'ground_truths_boundary_dice',\n",
    "                metric_deform_boundary_difference,\n",
    "                step = epoch\n",
    "            )\n",
    "            metric_boundary_difference_detection = dice_metric_boundary_difference_detection.aggregate().item()\n",
    "            log_metric(\n",
    "                'dice_deformed_boundary_ground_truth_to_prediction',\n",
    "                metric_boundary_difference_detection,\n",
    "                step = epoch\n",
    "            )\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            dice_metric_deform.reset()\n",
    "            dice_metric_deform_boundary_difference.reset()\n",
    "            dice_metric_boundary_difference_detection.reset()\n",
    "\n",
    "            metric_values.append(\n",
    "                metric\n",
    "            )\n",
    "            #hausdorf_distance_values.append(\n",
    "            #    hausdorf_distance\n",
    "            #)\n",
    "            metric_values_deform.append(\n",
    "                metric_deform\n",
    "            )\n",
    "            metric_values_deform_boundary_difference.append(\n",
    "                metric_deform_boundary_difference\n",
    "            )\n",
    "            metric_values_boundary_difference_detection.append(\n",
    "                metric_boundary_difference_detection\n",
    "            )\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    directory, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\ncurrent mean dice of deformed mask to predicted deformed image: {metric_deform:.4f}\"\n",
    "                f\"\\ncurrent mean dice of boundary of ground truth, and  boundary of deformed ground truth: {metric_deform_boundary_difference:.5f}\"\n",
    "                f\"\\ncurrent mean dice of the boundary difference due to deformation: {metric_boundary_difference_detection:.5f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
