{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178ba64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ants\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import skeletonize_3d, binary_closing\n",
    "from scipy.ndimage import distance_transform_edt, binary_dilation\n",
    "import tifffile as tif\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import cc3d\n",
    "from scipy.io import loadmat, savemat\n",
    "import sknw\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy as sp\n",
    "import vg\n",
    "from pytransform3d.rotations import matrix_from_axis_angle\n",
    "import multiprocessing\n",
    "from scipy.ndimage import convolve as conv\n",
    "from scipy.stats import multivariate_normal\n",
    "from skimage import color, data, restoration\n",
    "from RedLionfishDeconv import doRLDeconvolutionFromNpArrays\n",
    "from matplotlib.patches import Circle\n",
    "from skimage.feature import peak_local_max\n",
    "from statistics import mode\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from PIL.TiffTags import TAGS\n",
    "from tifffile import TiffFile\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "plt.rcParams['figure.figsize'] = [15, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d156882-af49-401d-8ce9-8113463f9c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3db4fa0-5e02-4479-993a-a5806123b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ants_affine_to_distance(affine):\n",
    "\n",
    "    dx, dy, dz = affine[9:]\n",
    "\n",
    "    rot_x = np.arcsin(affine[6])\n",
    "    cos_rot_x = np.cos(rot_x)\n",
    "    rot_y = np.arctan2(affine[7] / cos_rot_x, affine[8] / cos_rot_x)\n",
    "    rot_z = np.arctan2(affine[3] / cos_rot_x, affine[0] / cos_rot_x)\n",
    "\n",
    "    deg = np.degrees\n",
    "\n",
    "    return dx, dy, dz, deg(rot_x), deg(rot_y), deg(rot_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf31284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../TH1-CHR2_Small_Volumes/Female1/128_cap_1.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_2_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_2.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_2.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_2_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/XYZ1.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_3_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_3.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/304_arteriole_2.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/304_arteriole_2_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_3.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/128_cap_1_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_3_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/128_cap_2_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/304_arteriole_1_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/304_arteriole_1.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_1_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/57_art_1.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_1_0001.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/128_cap_2.tif'),\n",
       " PosixPath('../TH1-CHR2_Small_Volumes/Female1/276_cap_1.tif')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = Path('../TH1-CHR2_Small_Volumes/Female1')\n",
    "files  = list(folder.glob('*.tif'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3885c43e-f758-4ba5-8b8f-a4078e430089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../TH1-CHR2_Small_Volumes/Female1/128_cap_1.tif'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_ids_path = Path('../TH1-CHR2_Small_Volumes/Female1')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*.tif'))#grab folder names/mouse ids\n",
    "mouse_ids = sorted([x.as_posix() for x in mouse_ids])\n",
    "data_dicts = [\n",
    "    {\"image\":image_name}\n",
    "    for image_name in mouse_ids\n",
    "]\n",
    "\n",
    "#data_dicts = [data_dicts[_i]]\n",
    "re.sub('matt_raw_warped_upsampled','matt_preds_registered',data_dicts[0][\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47574f10",
   "metadata": {},
   "source": [
    "# Define connected componnet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8879e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_comps_3d(image, thresh = 500):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : binary np array with uint8 elements\n",
    "        3d numpy matrix, connected components will be removed form this image\n",
    "    thresh : int64\n",
    "        smallest connected components to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array with uint8 elements, binary\n",
    "        binary image with connected components below the threshold removed.\n",
    "\n",
    "    \"\"\"\n",
    "    img_lab, N = cc3d.connected_components(image,return_N=True)\n",
    "    unique, counts = np.unique(img_lab, return_counts=True)\n",
    "    unique_keep = unique[counts>thresh]\n",
    "    unique_keep = np.delete(unique_keep,[0])\n",
    "    img_filt = np.zeros(img_lab.shape).astype('int8')\n",
    "    img_filt[np.isin(img_lab,unique_keep)] = 1\n",
    "    return img_filt.astype('uint8')   \n",
    "\n",
    "def fill_holes(img,thresh=1000):\n",
    "    #res = np.zeros(img.shape)\n",
    "    for i in np.unique(img)[::-1]:\n",
    "        _tmp = (img==i)*1.0\n",
    "        _tmp = _tmp.astype('int8')\n",
    "        _tmp = remove_small_comps_3d(_tmp,thresh=thresh)\n",
    "        img[_tmp==1] = i\n",
    "    res = img.astype('int8')\n",
    "    return res\n",
    "\n",
    "def _rotmat(vector, points):\n",
    "    \"\"\"\n",
    "    Rotates a 3xn array of 3D coordinates from the +z normal to an\n",
    "    arbitrary new normal vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    vector = vg.normalize(vector)\n",
    "    axis = vg.perpendicular(vg.basis.z, vector)\n",
    "    angle = vg.angle(vg.basis.z, vector, units='rad')\n",
    "    \n",
    "    a = np.hstack((axis, (angle,)))\n",
    "    R = matrix_from_axis_angle(a)\n",
    "    \n",
    "    r = sp.spatial.transform.Rotation.from_matrix(R)\n",
    "    rotmat = r.apply(points)\n",
    "    \n",
    "    return rotmat\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    nodes = np.asarray(nodes)\n",
    "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "    if np.min(dist_2)>10:\n",
    "        return node\n",
    "    else:\n",
    "        return nodes[np.argmin(dist_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b7e27",
   "metadata": {},
   "source": [
    "# register raw iamges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95349708-d49a-4ef1-a543-24a17095f0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1/128_cap_1.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/128_cap_1_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/128_cap_2.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/128_cap_2_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_1.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_1_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_2.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_2_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_3.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/276_cap_3_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/304_arteriole_1.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/304_arteriole_1_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/304_arteriole_2.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/304_arteriole_2_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_1.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_1_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_2.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_2_0001.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_3.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1/57_art_3_0001.tif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = Path('../TH1-CHR2_Small_Volumes/Female1')\n",
    "files  = sorted(list(folder.glob('*.tif')))[0:-1]\n",
    "files = [x.as_posix() for x in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8e6e0f-fdec-4a57-ab8a-8f341dc406fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "  5%|▌         | 1/20 [00:06<02:10,  6.89s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 10%|█         | 2/20 [00:13<02:00,  6.67s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 15%|█▌        | 3/20 [00:19<01:48,  6.40s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 20%|██        | 4/20 [00:25<01:42,  6.43s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 25%|██▌       | 5/20 [00:33<01:41,  6.75s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 30%|███       | 6/20 [00:39<01:32,  6.62s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 35%|███▌      | 7/20 [00:46<01:28,  6.82s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 40%|████      | 8/20 [00:53<01:21,  6.79s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 45%|████▌     | 9/20 [01:00<01:14,  6.77s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 50%|█████     | 10/20 [01:06<01:06,  6.67s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 55%|█████▌    | 11/20 [01:14<01:02,  6.95s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 60%|██████    | 12/20 [01:21<00:55,  6.97s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 65%|██████▌   | 13/20 [01:29<00:51,  7.38s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 70%|███████   | 14/20 [01:37<00:44,  7.37s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 75%|███████▌  | 15/20 [01:45<00:37,  7.55s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 80%|████████  | 16/20 [01:52<00:30,  7.67s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 85%|████████▌ | 17/20 [02:01<00:23,  7.92s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 90%|█████████ | 18/20 [02:10<00:16,  8.12s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " 95%|█████████▌| 19/20 [02:18<00:08,  8.09s/it]<tifffile.TiffPage 0 @8> imagej_metadata failed with ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.31s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    img = io.imread(file)\n",
    "    for i in range(img.shape[0]):\n",
    "        io.imsave(re.sub('Female1','Female1_slices',re.sub('.tif','_'+str(i)+'.tif',file)), img[i], check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d1284d-537e-41d1-af08-c23f262de314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_1.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_10.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_100.tif']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = sorted(list(folder.glob('*.tif')))[0:-1]\n",
    "files = [x.as_posix() for x in files]\n",
    "files = [x for x in files if 'warped' not in x]\n",
    "print(len(files))\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0695656c-2681-4958-a061-1520ec5c2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['128_cap',\n",
    "        '276_cap',\n",
    "        '304_arteriole',\n",
    "        '57_art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "630a9802-5297-423f-848c-3df54c40af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for key in keys:\n",
    "        slices = [x for x in files if key in x]\n",
    "        dic[slices[0]] = slices[1:]\n",
    "        #scans = [x for x in scans if 'res' in str(x)]\n",
    "        #bottoms_1 = df[key][df[key][df[key].columns[3]] == 500]\n",
    "        #bottoms_2 = df[key][df[key][df[key].columns[2]] == 500]\n",
    "        #bottoms = pd.concat((bottoms_1,bottoms_2))\n",
    "        #bottoms = np.array(bottoms[bottoms.columns[1]])\n",
    "        #bottoms = [addition + '/' + x for x in bottoms]\n",
    "        #bottoms = [x for x in bottoms if 'res' in x]\n",
    "        #tops_1 = df[key][df[key][df[key].columns[3]] == 0]\n",
    "        #tops_2 = df[key][df[key][df[key].columns[2]] == 0]\n",
    "        #tops = pd.concat((tops_1,tops_2))\n",
    "        #tops = np.array(tops[tops.columns[1]])\n",
    "        #tops = [addition + '/' + x for x in tops]\n",
    "        #tops = [x for x in tops if 'res' in x]\n",
    "        #if len(tops) > 1:\n",
    "        #    dic[tops[0]] = list(tops[1:])\n",
    "        #elif len(tops) == 1:\n",
    "        #    dic[tops[0]] = tops\n",
    "        #if len(bottoms) > 1:\n",
    "        #    dic[bottoms[0]] = list(bottoms[1:])\n",
    "        #elif len(bottoms) == 1:\n",
    "        #    dic[bottoms[0]] = bottoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "914d070b-a868-4f7d-bf1c-efca8bb91834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0.tif', '../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0.tif', '../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0.tif', '../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0.tif'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8066d9d8-8d25-4a92-ad60-66f1cf894d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4010be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mouse_ids_path = Path('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI')#each mouse has its own folder with raw data in it\n",
    "#mouse_ids = list(mouse_ids_path.glob('*?[0-9]/*res*?[0-9].tif'))#grab folder names/mouse ids\n",
    "#images = sorted([x.as_posix() for x in mouse_ids if '_0001' in x.as_posix()])\n",
    "##images = [x for x in images if 'vbm' in x]\n",
    "#images = [x for x in images if  any(y in x for y in list(dic.keys()))]\n",
    "##images = [x for x in images if any(y in x for y in ['14/','49/','56/','68/','65/','61/'])]\n",
    "#unused_keys = [x for x in list(dic.keys()) if not  any(x in y for y in images)]\n",
    "#print(len(images))\n",
    "#print(images[1])\n",
    "#new_file_name = re.sub('matt_raw_warped_upsampled','matt_preds_registered',data_dicts[0][\"image\"])\n",
    "##images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c0af2-af26-4a37-aab3-65aa5950cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74e64936-b669-4f37-bffd-d9ab6b342c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mov_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3e5481-321c-4534-be04-6bc0cd54e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "537af5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:07<00:22,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:22<00:23, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:31<00:10, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:51<00:00, 12.77s/it]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm(dic.keys()):\n",
    "        fix_file = i\n",
    "    #if not os.path.exists(re.sub('.tif','_warped.tif',fix_file)):\n",
    "        mov_files = dic[i]\n",
    "        mov_files = [x for x in mov_files if os.path.exists(x)]\n",
    "        mov_files = [x for x in mov_files if not os.path.exists(re.sub('.tif','_warped.tif',x))]\n",
    "        #mov_files = sorted(mov_files + [re.sub('.tif','_0001.tif',x) for x in mov_files])\n",
    "        #mov_files.append(re.sub('.tif','_0001.tif',fix_file))\n",
    "        mov_files = [x for x in mov_files if x != fix_file]\n",
    "        mov_files = sorted(mov_files)\n",
    "        mov_files = np.unique(mov_files)\n",
    "        print(fix_file)\n",
    "        fix_numpy = io.imread(fix_file)\n",
    "        #plt.imshow(np.max(fix_numpy[:,0],axis=0))\n",
    "        #plt.show()\n",
    "        fix = ants.from_numpy(np.float32(fix_numpy[:,0])) #convert images to ants \n",
    "        res2 = []\n",
    "        for mov_file in tqdm(mov_files):\n",
    "            # read baseline image\n",
    "            mov_numpy = io.imread(mov_file) # read followup image\n",
    "            mov = ants.from_numpy(np.float32(mov_numpy[:,0]))\n",
    "            mytx = ants.registration(fixed = fix,\n",
    "                                     moving = mov,\n",
    "                                     type_of_transform = 'Rigid',\n",
    "                                     total_sigma = 2,\n",
    "                                     aff_metric = 'meansquares'\n",
    "                                     ) # register images and get displacment\n",
    "            warpedraw_1 = ants.apply_transforms(fixed = fix,\n",
    "                                                moving = ants.from_numpy(np.float32(mov_numpy[:,0])),\n",
    "                                                transformlist = mytx['fwdtransforms'],\n",
    "                                                interpolator = 'linear'\n",
    "                                                ) # move vascular chanel\n",
    "            warpedraw_2 = ants.apply_transforms(fixed = fix,\n",
    "                                                moving = ants.from_numpy(np.float32(mov_numpy[:,1])),\n",
    "                                                transformlist = mytx['fwdtransforms'],\n",
    "                                                interpolator = 'linear'\n",
    "                                                ) # move neuron chanel\n",
    "            mov_numpy[:,0,:,:] = warpedraw_1[:,:,:]\n",
    "            mov_numpy[:,1,:,:] = warpedraw_2[:,:,:]#combine moved chanels int one image\n",
    "            #plt.imshow(np.max(warpedraw_1[:,:,:],axis=0))\n",
    "            #plt.show()\n",
    "            res2.append(_ants_affine_to_distance(ants.read_transform(mytx['fwdtransforms'][0]).parameters))\n",
    "            io.imsave(re.sub('.tif','_warped.tif',mov_file),mov_numpy, check_contrast=False)# save warped followup image and baseline image\n",
    "        res.append(res2)\n",
    "        io.imsave(re.sub('.tif','_warped.tif',fix_file),fix_numpy, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cff1b3f7-e540-41cf-a1b0-4fc2f06dca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_100_warped.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_101_warped.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_102_warped.tif',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_103_warped.tif']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = sorted(list(folder.glob('*.tif')))[0:-1]\n",
    "files = [x.as_posix() for x in files]\n",
    "files = [x for x in files if 'warped' in x]\n",
    "scans = np.unique(['_'.join(x.split('/')[-1].split('_')[0:3]) for x in files])\n",
    "print(len(files))\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1964eadd-24c6-4c03-a785-03589fed1cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../TH1-CHR2_Small_Volumes/Female1/57_art_3.tif'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(file.split('/')[:-1])+'/'+scan+'.tif'\n",
    "#io.imsave('/'.join(file.split('/')[:-1])+'/'+scan+'.tif', img)\n",
    "re.sub('_slices','','/'.join(file.split('/')[:-1])+'/'+scan+'.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4832cc08-aa9d-470f-a435-8f1db0369fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_time(x):\n",
    "    return(int(x.split('_')[-2]))\n",
    "\n",
    "for scan in tqdm(scans):\n",
    "    _files = [x for x in files if scan in x]\n",
    "    _files_pre  = [x for x in _files if '_0001' not in x]\n",
    "    _files_post  = [x for x in _files if '_0001' in x]\n",
    "    _files_pre = sorted(_files_pre, key = grab_time)\n",
    "    _files_post = sorted(_files_post, key = grab_time)\n",
    "    img = io.imread( _files_pre[0])\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    shape = np.array(img.shape)\n",
    "    shape[2] = 1\n",
    "    new = np.zeros(shape)\n",
    "    img = np.append(img,new,axis=2)\n",
    "    for file in _files_pre[1:]:\n",
    "        _img = io.imread(file)\n",
    "        _img = np.expand_dims(_img, axis=0)\n",
    "        _img = np.append(_img,new,axis=2)\n",
    "        img = np.append(img,_img,axis=0)\n",
    "    img = np.append(img,np.concatenate((new,new,np.ones(shape)*1023),axis=2),axis=0)\n",
    "    for file in _files_post:\n",
    "        _img = io.imread(file)\n",
    "        _img = np.expand_dims(_img, axis=0)\n",
    "        _img = np.append(_img,new,axis=2)\n",
    "        img = np.append(img,_img,axis=0)\n",
    "    io.imsave(re.sub('_slices','','/'.join(file.split('/')[:-1])+'/'+scan+'.tif'), img)\n",
    "    print(re.sub('_slices','','/'.join(file.split('/')[:-1])+'/'+scan+'.tif'))\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1925063a-b96a-4719-9759-1fdf6a1f7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 20, 3, 128, 512)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97b52b6b-c87e-4e14-9a42-ca7b3163726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 3, 128, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = np.array(img.shape)\n",
    "shape[2] = 1\n",
    "new = np.zeros(shape)\n",
    "img = np.append(img,new,axis=2)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb9fabf0-5cde-402e-95a6-84dda4ed8624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddcb6d01-bd26-49d5-8672-3eecae9d2f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 3, 128, 512)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((new,new,np.ones(shape)*1023),axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e204f6-a063-4579-ad8a-5134b44a39e3",
   "metadata": {},
   "source": [
    "# predict using trained model\n",
    "run unetr prediction with registered raw images, orediction will be in same coordinate system \\\n",
    "run predict_matt_warped.py via predict_small_volumes.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d1533-8267-4390-9ee2-c7558f5aee8b",
   "metadata": {},
   "source": [
    "# Binarize prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "577b39db-4ee8-4eea-a5b4-52a4f5414078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062\n"
     ]
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = directory.glob('*mean.npy')\n",
    "#files  = directory.glob('*warped.tif')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if not os.path.exists(re.sub('led/','led_seg/',re.sub('mean','seg',x)))]\n",
    "#files = [x for x in files if 'Feb52021_6' in x]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "560a2856-4777-4072-a5c6-4a2a6399db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in files:\n",
    "#    os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0bfc5159-603d-43d0-84e1-89ad4d4c998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = Path('matt_raw_warped_single_upsampled')\n",
    "#files  = directory.glob('*-*_mean.npy')\n",
    "#files = sorted([x.as_posix() for x in files])\n",
    "##files = [x for x in files if not os.path.exists(re.sub('led/','led_seg/',re.sub('mean','seg',x)))]\n",
    "##files = [x for x in files if 'Feb52021_6' in x]\n",
    "##files = [x for x in files if any(y in x for y in problem)]\n",
    "#print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "55de248b-1095-4aa8-a30e-e292103cdc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3062/3062 [04:06<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.5\n",
    "max_var = 0.2\n",
    "#np.random.shuffle(files)\n",
    "for file in tqdm(files):\n",
    "    if not os.path.exists(re.sub('mean','seg',file)):\n",
    "            #print(file)\n",
    "            mean = np.load(file)\n",
    "            seg = np.zeros(mean.shape[1:]).astype('int8')\n",
    "            seg[(mean[1,:,:,:] > min_prob)] = 1\n",
    "            seg[(mean[2,:,:,:] > min_prob)] = 2\n",
    "            seg = seg.astype('int8')\n",
    "            seg = (seg==1)*1\n",
    "            seg = fill_holes(seg)\n",
    "            seg = remove_small_comps_3d(seg)\n",
    "            #plt.imshow(np.max(seg,axis=2))\n",
    "            #plt.show()\n",
    "            #print(seg.shape)\n",
    "            np.save(re.sub('mean','seg',file),seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38b230fb-9ac1-41a9-a4bb-4939f06d9a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(re.sub('mean','std',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7ef75327-1e5e-40f3-ba2b-529b366e32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_seg.npy'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = directory.glob('*_seg.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dc3b9-a4b3-4ed8-a416-22f5e5cc69e5",
   "metadata": {},
   "source": [
    "# Get distance transform of neuron segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e9e9eea-315e-44dd-be5b-5e53d5bd0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = Path('matt_raw_warped_single_upsampled')\n",
    "#files  = directory.glob('*-*_mean.npy')\n",
    "#files = sorted([x.as_posix() for x in files])\n",
    "#print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5a2f1d5f-c29a-44f6-9b5c-83556204e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_prob = 0.75\n",
    "#max_var = 0.1\n",
    "#for file in tqdm(files[::-1]):\n",
    "#    if not os.path.exists(re.sub('led/','led_seg/',re.sub('mean','seg_nrn_dst',file))):\n",
    "#        if os.path.exists(re.sub('mean','2x_std',file)):\n",
    "#            mean = np.load(file)\n",
    "#            std = np.load(re.sub('mean','2x_std',file))\n",
    "#            seg = np.zeros(mean.shape[1:])\n",
    "#            seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "#            seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "#            seg = seg.astype('int8')\n",
    "#            seg = (seg==2)*1\n",
    "#            np.save(re.sub('led/','led_seg/',re.sub('mean','seg_nrn',file)),seg)\n",
    "#            np.save(re.sub('led/','led_seg/',re.sub('mean','seg_nrn_dst',file)),distance_transform_edt(1-seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11ea7971-ee61-47b0-83ec-b7ee61723ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('mean','seg_nrn_dst',file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c169a-1a31-4f0d-91cc-e74df4d23990",
   "metadata": {},
   "source": [
    "# Problem Segmentations at graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a03273e7-e883-4ddf-87d0-c43a6ebdf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem = [\n",
    "#    \"XYZres038\",\n",
    "#    \"XYZres041\",\n",
    "#    \"XYZres042\",\n",
    "#    \"XYZres048\",\n",
    "#    \"XYZres052\",\n",
    "#    \"XYZres026\",\n",
    "#    \"XYZres024\"\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a1845cf5-823e-4893-8cba-29fe8d4bbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c0658-4dcd-479c-8d63-d972dd97b347",
   "metadata": {},
   "source": [
    "# get predicted images and save matlab .mat of intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d45028c-7248-49a7-a668-a653db13b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_seg.npy'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = directory.glob('*_seg.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ebd14da-3635-43a6-afb8-289ee7ed6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['128_cap',\n",
    "        '276_cap',\n",
    "        '304_arteriole',\n",
    "        '57_art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0abc6a56-584a-4c8c-93c7-5b49abf91e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for key in keys:\n",
    "        slices = [x for x in files if key in x]\n",
    "        dic[slices[0]] = slices[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9c030-e5a8-4b9c-80c5-bed76d1e5777",
   "metadata": {},
   "source": [
    "Currently set to union as intersection makes it choppy, retraining unetr on zoomed in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "006f0a9e-63bb-4056-a6e4-7d6bd94758f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2691774/3046212601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_warped_seg.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_seg_warped_single_sing.mat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_0001'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "re.sub('_warped_seg.npy','_seg_warped_single_sing.mat',re.sub('_0001','',image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6540342e-dad7-42c5-bd78-05072c4c61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 24.28it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for image in tqdm(list(dic.keys())):\n",
    "    if not os.path.exists(re.sub('_warped_seg.npy','_seg_warped_single_sing.mat',re.sub('_0001','',image))):\n",
    "        print(image)\n",
    "        img = binary_dilation(np.load(image))\n",
    "        _img = np.copy(img)\n",
    "        key = image\n",
    "        mut_info = []\n",
    "        mov_files = dic[image]\n",
    "        for i in tqdm(mov_files):\n",
    "            img_0001 = binary_dilation(np.load(i))\n",
    "            _mut_info = normalized_mutual_info_score(_img.flatten(),img_0001.flatten()) # calculate mutual information between masks, judges registration\n",
    "            mut_info.append(_mut_info)\n",
    "            if _mut_info > 0.2:\n",
    "                img += img_0001\n",
    "                #img = img * img_0001\n",
    "                #print(i)\n",
    "        seg = img\n",
    "        seg[seg!=0] = seg[seg!=0]/seg[seg!=0]\n",
    "        seg = (seg==1)*1\n",
    "        seg = seg.astype('int8')\n",
    "        seg = binary_closing(binary_closing(binary_closing(fill_holes(seg))))\n",
    "        seg = remove_small_comps_3d(seg,thresh=250)\n",
    "        #print(mut_info)\n",
    "        #print(mov_files)\n",
    "        plt.imshow(np.max(seg,axis=2))\n",
    "        plt.show()\n",
    "        res += mut_info\n",
    "        savemat(re.sub('_warped_seg.npy','_seg_warped_single_sing.mat',re.sub('_0001','',image)),{'FinalImage':fill_holes(binary_closing(seg))})\n",
    "        np.save(re.sub('_warped_seg.npy','_seg_warped_single_sing.npy',re.sub('_0001','',image)),fill_holes(binary_closing(seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e412c422-9000-48f6-8456-2850eff5cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files  = directory.glob('*_seg_warped_single_sing.mat')\n",
    "files = sorted([x.as_posix() for x in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1367951-8637-4975-88c6-5960759564b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0_seg_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0_seg_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0_seg_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0_seg_warped_single_sing.mat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0b5ca-031a-439c-9810-7f693af7bacf",
   "metadata": {},
   "source": [
    "# Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4408af-5005-48da-892f-14b99d25b1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0_skel_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0_skel_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0_skel_warped_single_sing.mat',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0_skel_warped_single_sing.mat']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files_seg_0001 = directory.glob('*_skel_warped_single_sing.mat')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "\n",
    "files_seg_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29a85f96-992f-4f32-9ca7-9e56f41138ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files_seg_0001 = directory.glob('*_warped_seg.npy')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "files_seg_0001 = [x for x in files_seg_0001 if  any(y in x for y in list(dic.keys()))]\n",
    "np.random.shuffle(files_seg_0001)\n",
    "\n",
    "len(files_seg_0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad38c70b-9273-43a0-8c29-81562c2c5ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_seg.npy',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0001_0_warped_seg.npy',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0001_0_warped_seg.npy',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0001_0_warped_seg.npy']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa50a805-93d7-449a-bd5e-c07c5a86f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c44109a-8051-421d-bb15-a77c730df0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1972170/923751762.py:27: UserWarning:\n",
      "\n",
      "../TH1-CHR2_Small_Volumes/Female1_slices/276_cap_1_0001_0_single_skel_sing.tif is a low contrast image\n",
      "\n",
      " 25%|██▌       | 1/4 [01:23<04:09, 83.23s/it]/tmp/ipykernel_1972170/923751762.py:27: UserWarning:\n",
      "\n",
      "../TH1-CHR2_Small_Volumes/Female1_slices/304_arteriole_1_0001_0_single_skel_sing.tif is a low contrast image\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "22\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:53<01:44, 52.10s/it]/tmp/ipykernel_1972170/923751762.py:27: UserWarning:\n",
      "\n",
      "../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_single_skel_sing.tif is a low contrast image\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:12<00:37, 37.04s/it]/tmp/ipykernel_1972170/923751762.py:27: UserWarning:\n",
      "\n",
      "../TH1-CHR2_Small_Volumes/Female1_slices/57_art_1_0001_0_single_skel_sing.tif is a low contrast image\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "11\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n",
      "not matched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:43<00:00, 55.81s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(files_seg_0001)\n",
    "for file_0001 in tqdm(files_seg_0001[:]):\n",
    "    #if not os.path.exists(re.sub('_warped_seg.npy','_warped.pickle',file_0001)) or (time.time() - os.path.getmtime(re.sub('_warped_seg.npy','_warped_sing.pickle',file_0001)))/3600>48:\n",
    "        #if os.path.exists(re.sub('_0001_warped_seg.npy','_skel_warped_single_sing.mat',file_0001)):\n",
    "            file = file_0001\n",
    "            skel_file = re.sub('_warped_seg.npy','_skel_warped_single_sing.mat',re.sub('_0001','',file))\n",
    "            skel = loadmat(skel_file)['FilteredImage']\n",
    "            if np.sum(skel) != 0:\n",
    "                graph = sknw.build_sknw(skel, multi=False)\n",
    "                print(len(graph.edges))\n",
    "                while len(list(nx.selfloop_edges(graph)))>0:\n",
    "                    if len(list(nx.selfloop_edges(graph))) !=0:\n",
    "                        for edge in list(nx.selfloop_edges(graph)):\n",
    "                            skel[graph[edge[0]][edge[1]]['pts'][1:-1,0],graph[edge[0]][edge[1]]['pts'][1:-1,1],graph[edge[0]][edge[1]]['pts'][1:-1,2]] = 0\n",
    "                    for edge in graph.edges:\n",
    "                        if (graph.degree(edge[0]) == 1 and graph.degree(edge[1]) > 2) or (graph.degree(edge[1]) == 1 and graph.degree(edge[0]) > 2):\n",
    "                            if graph[edge[0]][edge[1]]['weight']<20:\n",
    "                                skel[graph[edge[0]][edge[1]]['pts'][1:-1,0],graph[edge[0]][edge[1]]['pts'][1:-1,1],graph[edge[0]][edge[1]]['pts'][1:-1,2]] = 0\n",
    "                    graph = sknw.build_sknw(skel, multi=False)\n",
    "                for edge in graph.edges:\n",
    "                    if (graph.degree(edge[0]) == 1 and graph.degree(edge[1]) > 2) or (graph.degree(edge[1]) == 1 and graph.degree(edge[0]) > 2):\n",
    "                        if graph[edge[0]][edge[1]]['weight']<20:\n",
    "                            skel[graph[edge[0]][edge[1]]['pts'][1:-1,0],graph[edge[0]][edge[1]]['pts'][1:-1,1],graph[edge[0]][edge[1]]['pts'][1:-1,2]] = 0\n",
    "                graph = sknw.build_sknw(skel, multi=False)\n",
    "                graph.remove_nodes_from(list(nx.isolates(graph)))\n",
    "                print(len(graph.edges))\n",
    "                io.imsave(re.sub('_warped_seg.npy','_single_skel_sing.tif',file),skel)\n",
    "                nx.write_gpickle(graph,re.sub('_warped_seg.npy','_warped.pickle',file))\n",
    "                key = [x for x in list(dic.keys()) if x in file][0]\n",
    "                mov_files = [re.sub(key,x,file) for x in dic[key]]\n",
    "                mov_files = sorted(mov_files + [re.sub('_0001','',x) for x in mov_files])\n",
    "                mov_files.append(re.sub('_0001','',file))\n",
    "                seg = np.load(re.sub('_0001','',file))\n",
    "                for _file in mov_files:\n",
    "                    if os.path.exists(_file):\n",
    "                        if not os.path.exists(re.sub('_warped_seg.npy','_warped.pickle',_file)):\n",
    "                            seg_0001 = np.load(_file)\n",
    "                            _mut_info = normalized_mutual_info_score(seg.flatten(),seg_0001.flatten()) # calculate mutual information between masks, judges registration\n",
    "                            if _mut_info > 0.1:\n",
    "                                print('matched')\n",
    "                                nx.write_gpickle(graph,re.sub('_warped_seg.npy','_warped.pickle',_file))\n",
    "                            else:\n",
    "                                print('not matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d75073b-dcff-4e7c-9f30-473f2cc6b8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 100, 32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3107ad5-fda1-4a48-9857-8e5e9730dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932\n"
     ]
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4e447af-0caa-494b-8d1f-07703c6a1d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2932/2932 [00:15<00:00, 192.91it/s]\n"
     ]
    }
   ],
   "source": [
    "res_num_edges = []\n",
    "res_num_nodes = []\n",
    "res_mean_path_length = []\n",
    "res_num_terminal_nodes = []\n",
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    res_num_edges.append(len(graph.edges))\n",
    "    res_num_nodes.append(len(graph.nodes))\n",
    "    res_mean_path_length.append(np.mean(nx.to_pandas_edgelist(graph)['weight']))\n",
    "    res_num_terminal_nodes.append(np.sum([d == 1 for n,d in graph.degree()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "074b30a1-996d-40b4-b581-f6e11fa5ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.281036834924965\n",
      "4.484794138098887\n",
      "25.15825375170532\n",
      "6.08877509985768\n",
      "67.58601362199684\n",
      "13.943615400888259\n",
      "21.246930422919508\n",
      "7.273858104449935\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(res_num_edges))\n",
    "print(np.std(res_num_edges))\n",
    "print(np.mean(res_num_nodes))\n",
    "print(np.std(res_num_nodes))\n",
    "print(np.mean(res_mean_path_length))\n",
    "print(np.std(res_mean_path_length))\n",
    "print(np.mean(res_num_terminal_nodes))\n",
    "print(np.std(res_num_terminal_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a91fbe-ec29-42ee-a832-8097b6cb6eb6",
   "metadata": {},
   "source": [
    "# write vessel measurments to graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f810e37f-eb93-4106-a2c9-4b4fc4de373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1972170/3789618196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "\n",
    "print(len(files))\n",
    "files = [x for x in files if not os.path.exists(re.sub('.pickle','_radii.pickle',x))]\n",
    "print(len(files))\n",
    "#files = [x for x in files if not os.path.exists(re.sub('.pickle','_radii_forepaw.pickle',x))]\n",
    "np.random.shuffle(files)\n",
    "print(len(files))\n",
    "file = files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576d8987-a235-4d86-b2d1-e1187da14ece",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1972170/3947409337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_upsampled_seg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_upsampled'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_warped.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_warped_mean.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "file\n",
    "os.path.exists(re.sub('_upsampled_seg','_upsampled',re.sub('_warped.pickle','_warped_mean.npy',file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e708a72-87b6-4891-a90d-bfd81f59cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.5\n",
    "#max_var = 0.1\n",
    "sampling = 1/5\n",
    "\n",
    "for file in tqdm(files):\n",
    "    if not os.path.exists(re.sub('.pickle','_radii.pickle',file)):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        print(len(graph.edges))\n",
    "        if len(graph.edges) < 1500:\n",
    "                            img_file = re.sub('_warped.pickle','_warped.tif',file)\n",
    "                            seg_file = re.sub('_warped.pickle','_warped_seg.npy',file)\n",
    "                            mean_file = re.sub('_upsampled_seg','_upsampled',re.sub('_warped.pickle','_warped_mean.npy',file))\n",
    "                            #std_file = re.sub('_upsampled_seg','_upsampled',re.sub('_warped.pickle','_warped_2x_std.npy',file))\n",
    "                            img = io.imread(img_file)\n",
    "                            img_ch2 = sp.ndimage.zoom(np.swapaxes(img[:,1,:,:],0,2),(1,1,2.6))\n",
    "                            img = sp.ndimage.zoom(np.swapaxes(img[:,0,:,:],0,2),(1,1,2.6))\n",
    "                            seg = np.load(seg_file)\n",
    "                            mean = np.load(mean_file)\n",
    "                            #std = np.load(std_file)\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            #nrn_dst = np.load(re.sub('_warped.pickle','_warped_seg_nrn_dst.npy',file))\n",
    "                            a, b, c = np.mgrid[-15:16:1, -15:16:1, -15:16:1]\n",
    "                            abc = np.dstack([a.flat,b.flat, c.flat])\n",
    "                            mu = np.array([0,0,0])\n",
    "                            sigma = np.array([0.636,0.127,0.127])\n",
    "                            covariance = np.diag(sigma**2)\n",
    "                            d = multivariate_normal.pdf(abc, mean=mu, cov=covariance)\n",
    "                            d = d.reshape((len(a),len(b),len(c)))\n",
    "                            deconv_img = np.copy(img)\n",
    "                            deconv_img =  1023 * restoration.richardson_lucy(img/1023.0, d, iterations=10) - 1023 * restoration.richardson_lucy(img_ch2/1023.0, d, iterations=10)\n",
    "                            deconv_img = np.int16(deconv_img)\n",
    "                            \n",
    "                            for i in tqdm(range(len(graph.edges))):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii == 0:\n",
    "                                    _pred_radii =1\n",
    "                                \n",
    "                                _box_fit = max([np.int16(_pred_radii_max)+10, 15])\n",
    "                                #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "                                path_smooth = np.float32(np.copy(path))\n",
    "                                for k in range(len(path[0])):\n",
    "                                    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),3,mode='nearest')\n",
    "                                path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "                                res_fwhm = []\n",
    "                                X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                x,y = np.meshgrid(X,Y)\n",
    "                                x = x.flatten()\n",
    "                                y = y.flatten()\n",
    "                                z = np.zeros(len(x))\n",
    "                                xy = np.vstack([x,y,z])\n",
    "                                \n",
    "                                \n",
    "                                res_fwhm = []\n",
    "                                \n",
    "                                res_fwhm_sigma = []\n",
    "                                \n",
    "                                def calc_fwhm_path(I):\n",
    "                                    point_grad = path_grad[I]\n",
    "                                    point = path[I]\n",
    "                                    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "                                        rotated = xy.T + point\n",
    "                                    else:\n",
    "                                        rotated = _rotmat(point_grad,xy.T) + point\n",
    "                                    points_img = sp.ndimage.map_coordinates(#np.int16(mean[1]*1024),\n",
    "                                                                        deconv_img,\n",
    "                                                                        rotated.T, \n",
    "                                                                        order=3,\n",
    "                                                                        mode='constant')\n",
    "                                    \n",
    "                                            \n",
    "                                    points_img = np.reshape(points_img,(len(X),len(Y)))\n",
    "                                    points_img_no_smooth = np.copy(points_img)\n",
    "                                    points_img = sp.ndimage.gaussian_filter(points_img, sigma = _pred_radii*.4)\n",
    "\n",
    "                                    \n",
    "                                    \n",
    "                                    _point = np.array(np.arange(0,_pred_radii+20,sampling))\n",
    "                                    _zeros = np.zeros(len(_point))\n",
    "                                    _point = np.array([_point,_zeros])\n",
    "                                    _centre = closest_node([len(X)//2+1,len(Y)//2+1],peak_local_max(points_img.T))\n",
    "                                    \n",
    "                                    _res = []\n",
    "                                    \n",
    "                                    #fig,ax = plt.subplots(1)\n",
    "                                    #ax.set_aspect('equal')\n",
    "                                    #ax.imshow(points_img_no_smooth,\n",
    "                                    #          vmin = 0,\n",
    "                                    #          vmax = np.max(deconv_img))\n",
    "                                    #ax.scatter(_centre[0],_centre[1])\n",
    "                                    for deg in np.arange(0,360,10):\n",
    "                                        rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "                                        rot_point[0] = rot_point[0] + _centre[0]\n",
    "                                        rot_point[1] = rot_point[1] + _centre[1]\n",
    "                                        points_vals = sp.ndimage.map_coordinates(points_img.T,\n",
    "                                                                                 rot_point, \n",
    "                                                                                 order=3,\n",
    "                                                                                 cval=0)\n",
    "                                        points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=_pred_radii*.4/sampling)\n",
    "                                        points_vals_grad = np.gradient(points_vals)\n",
    "                                        _ = np.array(sp.signal.argrelextrema(points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals)),np.less,order=3))\n",
    "                                        if _.shape[1] != 0:\n",
    "                                            points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "                                            _ = np.argmin(points_vals_grad)\n",
    "                                            _res.append(_*sampling)\n",
    "                                            #ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "                                        else:\n",
    "                                            points_vals_grad = np.gradient(points_vals)\n",
    "                                            _ = np.argmin(points_vals_grad)\n",
    "                                            _res.append(_*sampling)\n",
    "                                            #ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "                                    _res = np.array(_res)\n",
    "                                    _res = _res[~np.isnan(_res)]\n",
    "                                    _res = _res[np.where(_res!=0)]\n",
    "                                    _mean = np.mean(_res)\n",
    "                                    _std = np.std(_res)\n",
    "                                    _mask = np.where(np.logical_and(_res>_mean-2*_std, _res<_mean+2*_std))\n",
    "                                    _res = _res[_mask]\n",
    "                                    radii = np.mean(_res)\n",
    "                                    radii_std = np.std(_res)\n",
    "                                    circ = Circle(_centre,radii,fill=False)\n",
    "                                    #ax.add_patch(circ)\n",
    "                                    #ax.set_title(radii)\n",
    "                                    #fig.savefig('/home/rozakmat/scratch/_tmp/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'_'+str(I)+'.png')\n",
    "                                    #plt.clf()\n",
    "                                    \n",
    "                                        \n",
    "                                    return radii, radii_std\n",
    "                                \n",
    "                                pool = multiprocessing.Pool(16)\n",
    "                                _vals, _vals_sigma = zip(*pool.map(calc_fwhm_path, range(len(path))))\n",
    "                                #images = []\n",
    "                                #for I in tqdm(range(len(path))):\n",
    "                                #    images.append(imageio.imread('/home/rozakmat/scratch/_tmp/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'_'+str(I)+'.png'))\n",
    "                                #    os.remove('/home/rozakmat/scratch/_tmp/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'_'+str(I)+'.png')\n",
    "                                #imageio.mimsave('/home/rozakmat/scratch/gifs/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'.gif', images, format='GIF', fps=2)\n",
    "                                \n",
    "                                #_nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty'] = _vals_sigma\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['wavelength'] = wavelength\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['power'] = power_per\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            nx.write_gpickle(graph, re.sub('.pickle','_radii.pickle',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f22c777-065b-445a-9f96-5c4b3d554853",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(files)\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f930e593-ccc5-47d6-bd70-62ec68472bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matt_raw_warped/20220129_67-XYZres395_0001_warped.tif'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('matt_raw_warped_single_upsampled_seg','matt_raw_warped',re.sub('_warped.pickle','_warped.tif',file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b8f56-367c-4548-a376-96678fe04178",
   "metadata": {},
   "source": [
    "# Get pickle files with vascular measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37024f67-d7aa-4994-a70e-53327065c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932\n"
     ]
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files = directory.glob('*_warped_radii.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files2 = directory.glob('*_radii_forepaw.pickle')\n",
    "#files2 = sorted([x.as_posix() for x in files2])\n",
    "#files += files2\n",
    "files = sorted(files)\n",
    "print(len(files))\n",
    "#print(files2)\n",
    "#files = [x for x in files if '45-' in x]\n",
    "#print(sorted(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0227ad30-c2ea-45d3-9356-abd681cf6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_radii.pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'128_cap'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[0]\n",
    "print(file)\n",
    "'_'.join(re.sub('../TH1-CHR2_Small_Volumes/Female1_slices/','', file).split('_')[0:3])[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f9379b8-2bb4-4804-a899-e99b6e6c48dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2932/2932 [02:56<00:00, 16.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_radii_amended.pickle'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "sampling = 1/5\n",
    "#xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "#xls2 = pd.ExcelFile('../TBI_monai_UNET/p3_metalog.xlsx')\n",
    "#df = {}\n",
    "#for sheet_name in xls.sheet_names:\n",
    "#    df[sheet_name] = xls.parse(sheet_name)\n",
    "#for sheet_name in xls2.sheet_names:\n",
    "#    df[sheet_name] = xls2.parse(sheet_name)\n",
    "for file in tqdm(files[::-1]):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    #for sheet_name in xls.sheet_names + xls2.sheet_names:\n",
    "        #if re.sub('_0001','',re.sub('matt_preds_graphs_fwhm_single/','',re.sub('_warped_radii.pickle','',re.sub('_warped_radii_forepaw.pickle','',re.sub('xyz','XYZ',file)))).split('-')[1]) in df[sheet_name].values:\n",
    "            #subj = sheet_name\n",
    "            #if (re.sub('matt_preds_graphs_fwhm_single/','',re.sub('_warped.pickle','',file)).split('-')[0].split(' ') + [''])[0] in sheet_name or (re.sub('matt_preds_graphs_fwhm_single/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_') + [''])[1] in sheet_name:\n",
    "    scan = '_'.join(re.sub('../TH1-CHR2_Small_Volumes/Female1_slices/','', file).split('_')[0:3])\n",
    "    count = 0\n",
    "    for edge in graph.edges:\n",
    "        graph[edge[0]][edge[1]]['scan'] = scan\n",
    "        graph[edge[0]][edge[1]]['location'] = scan[:-2]\n",
    "        graph[edge[0]][edge[1]]['ID'] = '_'.join(scan.split('_')[0:2]) + str(count)\n",
    "        count +=1\n",
    "    #print(np.max(_res))\n",
    "    #print(gender)\n",
    "    #print(subj)\n",
    "    #print(file)\n",
    "    nx.write_gpickle(graph, re.sub('.pickle','_amended.pickle',file))\n",
    "re.sub('.pickle','_amended.pickle',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb541b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'_'.join(scan.split('_')[0:2]) + str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e50d2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(dic.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668eaf-4bd5-4ed0-b318-4d96e284d986",
   "metadata": {},
   "source": [
    "# Grab labels from James labelled AVC for his data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7271f5b-05ef-40a6-9b05-99bf645f8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932\n"
     ]
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files = directory.glob('*_amended.pickle')\n",
    "#files = directory.glob('*_with_branch_order.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "#files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ec6d6-62fe-45a3-8110-9e8e7395fe89",
   "metadata": {},
   "source": [
    "# convert graphs to excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "862c43de-9a0c-4a20-9e1d-418fd88a8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932\n",
      "2932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_0_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_100_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_101_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_102_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_103_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_104_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_105_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_106_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_107_warped_radii_amended.pickle',\n",
       " '../TH1-CHR2_Small_Volumes/Female1_slices/128_cap_1_0001_108_warped_radii_amended.pickle']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "_files = directory.glob('*_warped_radii.pickle')\n",
    "_files = sorted([x.as_posix() for x in _files])\n",
    "_files = sorted(_files)\n",
    "print(len(_files))\n",
    "\n",
    "directory = Path('../TH1-CHR2_Small_Volumes/Female1_slices')\n",
    "files = directory.glob('*_radii*amended.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if any(re.sub('matt_preds_graphs_fwhm_single_excel/','',re.sub('_amended','',files[0])) not in y for y in _files)]\n",
    "print(len(files))\n",
    "files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0a1f087-f8b8-4de6-96d2-2ae4fbf9f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2931/2931 [00:39<00:00, 73.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "res=[]\n",
    "#np.random.shuffle(files)\n",
    "graph = nx.read_gpickle(files[0])\n",
    "df = nx.to_pandas_edgelist(graph)\n",
    "if '_0001' in files[0]:\n",
    "    df['scan'] = df['scan'] + '_0001'\n",
    "    df['stim'] = 'post'\n",
    "df['time'] = re.sub('_0001','',files[0]).split('/')[-1].split('_')[3]\n",
    "for file in tqdm(files[1:]):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    \n",
    "    if '_0001' in file:\n",
    "        edge_df['scan'] = edge_df['scan'] + '_0001'\n",
    "        edge_df['stim'] = 'post'\n",
    "    else:\n",
    "        edge_df['stim'] = 'pre'\n",
    "    edge_df['time'] = re.sub('_0001','',file).split('/')[-1].split('_')[3]\n",
    "    df = df.append(edge_df, ignore_index=True)\n",
    "\n",
    "    #edge_df.to_excel(re.sub('matt_preds_graphs_fwhm_single','matt_preds_graphs_fwhm_single_excel',re.sub('.pickle','.xlsx',file)))\n",
    "    #res.append(len(edge_df))\n",
    "    #print(edge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76e0fd04-38cd-4553-8751-ed8c87630104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>location</th>\n",
       "      <th>end-1x</th>\n",
       "      <th>radii_std</th>\n",
       "      <th>ID</th>\n",
       "      <th>end-0x</th>\n",
       "      <th>end-0z</th>\n",
       "      <th>radii</th>\n",
       "      <th>path_weights</th>\n",
       "      <th>...</th>\n",
       "      <th>path_weights_uncertanty</th>\n",
       "      <th>end-1y</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>weight</th>\n",
       "      <th>euclidean-dst</th>\n",
       "      <th>end-1z</th>\n",
       "      <th>end-0y</th>\n",
       "      <th>scan</th>\n",
       "      <th>stim</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128_cap</td>\n",
       "      <td>41</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>128_cap0</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1.655158</td>\n",
       "      <td>(1.572222222222222, 1.4444444444444449, 1.4294...</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.41674073415754886, 0.18921540406584889, 0.3...</td>\n",
       "      <td>77</td>\n",
       "      <td>13.513514</td>\n",
       "      <td>51.315650</td>\n",
       "      <td>42.355637</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>128_cap_1_0001</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>128_cap</td>\n",
       "      <td>17</td>\n",
       "      <td>0.436825</td>\n",
       "      <td>128_cap1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1.930099</td>\n",
       "      <td>(1.6971428571428568, 1.7125000000000001, 1.972...</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.25910363540010584, 0.42701727131346806, 0.4...</td>\n",
       "      <td>110</td>\n",
       "      <td>59.175676</td>\n",
       "      <td>103.024335</td>\n",
       "      <td>65.741920</td>\n",
       "      <td>81</td>\n",
       "      <td>62</td>\n",
       "      <td>128_cap_1_0001</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>128_cap</td>\n",
       "      <td>46</td>\n",
       "      <td>0.439350</td>\n",
       "      <td>128_cap2</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>1.134007</td>\n",
       "      <td>(0.8181818181818182, 1.2411764705882353, 0.760...</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.20516740460376676, 0.6821754333009274, 0.23...</td>\n",
       "      <td>44</td>\n",
       "      <td>73.437500</td>\n",
       "      <td>94.479695</td>\n",
       "      <td>60.382117</td>\n",
       "      <td>102</td>\n",
       "      <td>25</td>\n",
       "      <td>128_cap_1_0001</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>128_cap</td>\n",
       "      <td>17</td>\n",
       "      <td>0.440368</td>\n",
       "      <td>128_cap3</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>1.768766</td>\n",
       "      <td>(2.070588235294118, 1.964705882352941, 2.11764...</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.673677096575078, 0.47395851949373385, 0.694...</td>\n",
       "      <td>79</td>\n",
       "      <td>140.938144</td>\n",
       "      <td>124.377732</td>\n",
       "      <td>86.706401</td>\n",
       "      <td>186</td>\n",
       "      <td>68</td>\n",
       "      <td>128_cap_1_0001</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>128_cap</td>\n",
       "      <td>13</td>\n",
       "      <td>0.386318</td>\n",
       "      <td>128_cap4</td>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>1.345884</td>\n",
       "      <td>(1.1235294117647054, 1.464705882352941, 1.8352...</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.5291829570915192, 0.6014112583998606, 0.812...</td>\n",
       "      <td>5</td>\n",
       "      <td>128.333333</td>\n",
       "      <td>57.336830</td>\n",
       "      <td>36.455452</td>\n",
       "      <td>145</td>\n",
       "      <td>15</td>\n",
       "      <td>128_cap_1_0001</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47731</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>57_art</td>\n",
       "      <td>22</td>\n",
       "      <td>0.331275</td>\n",
       "      <td>57_art6</td>\n",
       "      <td>12</td>\n",
       "      <td>198</td>\n",
       "      <td>2.516753</td>\n",
       "      <td>(3.165714285714286, 2.7588235294117647, 2.4666...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.0949084390011425, 1.0230052748581226, 0.747...</td>\n",
       "      <td>94</td>\n",
       "      <td>205.338710</td>\n",
       "      <td>75.651268</td>\n",
       "      <td>53.572381</td>\n",
       "      <td>211</td>\n",
       "      <td>43</td>\n",
       "      <td>57_art_3</td>\n",
       "      <td>pre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47732</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>57_art</td>\n",
       "      <td>23</td>\n",
       "      <td>1.044262</td>\n",
       "      <td>57_art7</td>\n",
       "      <td>10</td>\n",
       "      <td>277</td>\n",
       "      <td>8.403477</td>\n",
       "      <td>(9.627777777777776, 9.896969696969698, 10.0, 9...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.9596784190710579, 0.6032662854850572, 0.877...</td>\n",
       "      <td>45</td>\n",
       "      <td>301.557692</td>\n",
       "      <td>59.312980</td>\n",
       "      <td>51.903757</td>\n",
       "      <td>327</td>\n",
       "      <td>50</td>\n",
       "      <td>57_art_3</td>\n",
       "      <td>pre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47733</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>57_art</td>\n",
       "      <td>27</td>\n",
       "      <td>1.343611</td>\n",
       "      <td>57_art8</td>\n",
       "      <td>23</td>\n",
       "      <td>328</td>\n",
       "      <td>4.768834</td>\n",
       "      <td>(4.548387096774193, 7.0, 6.958823529411765, 7....</td>\n",
       "      <td>...</td>\n",
       "      <td>(3.3019906965092294, 3.525491584033482, 4.7467...</td>\n",
       "      <td>2</td>\n",
       "      <td>387.108696</td>\n",
       "      <td>162.545905</td>\n",
       "      <td>133.824512</td>\n",
       "      <td>455</td>\n",
       "      <td>44</td>\n",
       "      <td>57_art_3</td>\n",
       "      <td>pre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47734</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>57_art</td>\n",
       "      <td>23</td>\n",
       "      <td>0.561632</td>\n",
       "      <td>57_art9</td>\n",
       "      <td>23</td>\n",
       "      <td>328</td>\n",
       "      <td>8.202435</td>\n",
       "      <td>(9.481481481481481, 9.344827586206897, 9.72121...</td>\n",
       "      <td>...</td>\n",
       "      <td>(5.519865607397624, 4.835186136052415, 4.83846...</td>\n",
       "      <td>91</td>\n",
       "      <td>346.530612</td>\n",
       "      <td>63.672447</td>\n",
       "      <td>57.801384</td>\n",
       "      <td>363</td>\n",
       "      <td>45</td>\n",
       "      <td>57_art_3</td>\n",
       "      <td>pre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47735</th>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>57_art</td>\n",
       "      <td>10</td>\n",
       "      <td>2.451442</td>\n",
       "      <td>57_art10</td>\n",
       "      <td>25</td>\n",
       "      <td>430</td>\n",
       "      <td>7.890432</td>\n",
       "      <td>(6.634285714285714, 5.9142857142857155, 5.9142...</td>\n",
       "      <td>...</td>\n",
       "      <td>(1.7340197489636382, 1.8856060575002491, 1.940...</td>\n",
       "      <td>45</td>\n",
       "      <td>478.690265</td>\n",
       "      <td>131.082532</td>\n",
       "      <td>91.131773</td>\n",
       "      <td>506</td>\n",
       "      <td>93</td>\n",
       "      <td>57_art_3</td>\n",
       "      <td>pre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47736 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target location  end-1x  radii_std        ID  end-0x  end-0z  \\\n",
       "0           0       1  128_cap      41   0.242195  128_cap0      13       7   \n",
       "1           2       4  128_cap      17   0.436825  128_cap1       4      38   \n",
       "2           3       6  128_cap      46   0.439350  128_cap2       4      63   \n",
       "3           5      14  128_cap      17   0.440368  128_cap3      16     100   \n",
       "4           7       8  128_cap      13   0.386318  128_cap4      11     110   \n",
       "...       ...     ...      ...     ...        ...       ...     ...     ...   \n",
       "47731      10      11   57_art      22   0.331275   57_art6      12     198   \n",
       "47732      13      14   57_art      23   1.044262   57_art7      10     277   \n",
       "47733      14      18   57_art      27   1.343611   57_art8      23     328   \n",
       "47734      14      16   57_art      23   0.561632   57_art9      23     328   \n",
       "47735      17      19   57_art      10   2.451442  57_art10      25     430   \n",
       "\n",
       "          radii                                       path_weights  ...  \\\n",
       "0      1.655158  (1.572222222222222, 1.4444444444444449, 1.4294...  ...   \n",
       "1      1.930099  (1.6971428571428568, 1.7125000000000001, 1.972...  ...   \n",
       "2      1.134007  (0.8181818181818182, 1.2411764705882353, 0.760...  ...   \n",
       "3      1.768766  (2.070588235294118, 1.964705882352941, 2.11764...  ...   \n",
       "4      1.345884  (1.1235294117647054, 1.464705882352941, 1.8352...  ...   \n",
       "...         ...                                                ...  ...   \n",
       "47731  2.516753  (3.165714285714286, 2.7588235294117647, 2.4666...  ...   \n",
       "47732  8.403477  (9.627777777777776, 9.896969696969698, 10.0, 9...  ...   \n",
       "47733  4.768834  (4.548387096774193, 7.0, 6.958823529411765, 7....  ...   \n",
       "47734  8.202435  (9.481481481481481, 9.344827586206897, 9.72121...  ...   \n",
       "47735  7.890432  (6.634285714285714, 5.9142857142857155, 5.9142...  ...   \n",
       "\n",
       "                                 path_weights_uncertanty end-1y  mean_depth  \\\n",
       "0      (0.41674073415754886, 0.18921540406584889, 0.3...     77   13.513514   \n",
       "1      (0.25910363540010584, 0.42701727131346806, 0.4...    110   59.175676   \n",
       "2      (0.20516740460376676, 0.6821754333009274, 0.23...     44   73.437500   \n",
       "3      (0.673677096575078, 0.47395851949373385, 0.694...     79  140.938144   \n",
       "4      (0.5291829570915192, 0.6014112583998606, 0.812...      5  128.333333   \n",
       "...                                                  ...    ...         ...   \n",
       "47731  (1.0949084390011425, 1.0230052748581226, 0.747...     94  205.338710   \n",
       "47732  (1.9596784190710579, 0.6032662854850572, 0.877...     45  301.557692   \n",
       "47733  (3.3019906965092294, 3.525491584033482, 4.7467...      2  387.108696   \n",
       "47734  (5.519865607397624, 4.835186136052415, 4.83846...     91  346.530612   \n",
       "47735  (1.7340197489636382, 1.8856060575002491, 1.940...     45  478.690265   \n",
       "\n",
       "           weight  euclidean-dst  end-1z  end-0y            scan  stim time  \n",
       "0       51.315650      42.355637      14      46  128_cap_1_0001  post    0  \n",
       "1      103.024335      65.741920      81      62  128_cap_1_0001  post    0  \n",
       "2       94.479695      60.382117     102      25  128_cap_1_0001  post    0  \n",
       "3      124.377732      86.706401     186      68  128_cap_1_0001  post    0  \n",
       "4       57.336830      36.455452     145      15  128_cap_1_0001  post    0  \n",
       "...           ...            ...     ...     ...             ...   ...  ...  \n",
       "47731   75.651268      53.572381     211      43        57_art_3   pre    9  \n",
       "47732   59.312980      51.903757     327      50        57_art_3   pre    9  \n",
       "47733  162.545905     133.824512     455      44        57_art_3   pre    9  \n",
       "47734   63.672447      57.801384     363      45        57_art_3   pre    9  \n",
       "47735  131.082532      91.131773     506      93        57_art_3   pre    9  \n",
       "\n",
       "[47736 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b968725-e836-4251-a422-11f31a3a3de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '100', '101', '102', '103', '104', '105', '106',\n",
       "       '107', '108', '109', '11', '110', '111', '112', '113', '114',\n",
       "       '115', '116', '117', '118', '119', '12', '120', '121', '122',\n",
       "       '123', '124', '125', '126', '127', '128', '129', '13', '130',\n",
       "       '131', '132', '133', '134', '135', '136', '137', '138', '139',\n",
       "       '14', '140', '141', '142', '143', '144', '145', '146', '147',\n",
       "       '148', '149', '15', '150', '151', '152', '153', '154', '155',\n",
       "       '156', '157', '158', '159', '16', '160', '161', '162', '163',\n",
       "       '164', '165', '166', '167', '168', '169', '17', '170', '171',\n",
       "       '172', '173', '174', '175', '176', '177', '178', '179', '18',\n",
       "       '180', '181', '182', '183', '184', '185', '186', '187', '188',\n",
       "       '189', '19', '190', '191', '2', '20', '21', '22', '23', '24', '25',\n",
       "       '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35',\n",
       "       '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45',\n",
       "       '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55',\n",
       "       '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65',\n",
       "       '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75',\n",
       "       '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85',\n",
       "       '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95',\n",
       "       '96', '97', '98', '99'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae9f9f65-d416-4789-ae96-524d597ae13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['mean_vessel_radii_baseline'] = np.nan\n",
    "#df['std_vessel_radii_baseline'] = np.nan\n",
    "#df['num_vessel_radii_baseline'] = np.nan\n",
    "#df['vertex_id_base'] = np.nan\n",
    "#for i in tqdm(np.unique(df['ID'])):\n",
    "#    df['mean_vessel_radii_baseline'].iloc[np.where(df['ID']==i)] = np.mean(df.iloc[np.where(df['ID']==i)][~df.iloc[np.where(df['ID']==i)]['stim'].str.contains('pre')]['radii'])\n",
    "#    df['std_vessel_radii_baseline'].iloc[np.where(df['ID']==i)] = np.std(df.iloc[np.where(df['ID']==i)][~df.iloc[np.where(df['ID']==i)]['stim'].str.contains('pre')]['radii'])\n",
    "#    df['num_vessel_radii_baseline'].iloc[np.where(df['ID']==i)] = len(df.iloc[np.where(df['ID']==i)][~df.iloc[np.where(df['ID']==i)]['stim'].str.contains('pre')]['radii'])\n",
    "#    for j in list(np.where(df['ID']==i))[0]:\n",
    "#        #print(j)\n",
    "#        df['vertex_id_base'].iloc[j] = list(np.arange(0,len(list(df['path_weights'].iloc[np.where(df['ID']==i)])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7b5d3b-2e1c-4173-b5e5-88441573f83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n#p.repeat(tuple(),len(df['vertex_id_base'].iloc[np.where(df['vessel_id']==i-1)]),axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc3feeea-3a6e-4227-96e1-d9e2361cdfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ac5b147-aaa7-4680-8c46-e9675860bf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163812/163812 [1:00:09<00:00, 45.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for rows containing '_0001'\n",
    "mask = df['scan'].str.contains('_0001')\n",
    "exit \n",
    "# Set 'delta_radii' and 'timepoint' for rows without '_0001'\n",
    "df.loc[~mask, ['delta_radii', 'timepoint']] = [0, 0]\n",
    "\n",
    "# Set 'timepoint' for rows with '_0001'\n",
    "df.loc[mask, 'timepoint'] = 1\n",
    "\n",
    "# Find unique scan values\n",
    "unique_scans = np.unique(df['scan'])\n",
    "\n",
    "# Iterate over the rows with '_0001'\n",
    "for i in tqdm(df[mask].index):\n",
    "    scan_without_suffix = df.at[i, 'scan'].replace('_0001', '')\n",
    "    if scan_without_suffix in unique_scans:\n",
    "        # Find the corresponding row index for the matching scan and vessel_id\n",
    "        match_mask = (df['scan'] == scan_without_suffix) & (df['vessel_id'] == df.at[i, 'vessel_id'])\n",
    "        match_idx = df[match_mask].index\n",
    "        if not match_idx.empty:\n",
    "            # Calculate 'delta_radii' using the matching row index\n",
    "            df.at[i, 'delta_radii'] = df.at[i, 'radii'] - df.at[match_idx[0], 'radii']\n",
    "        else:\n",
    "            df.at[i, 'delta_radii'] = np.nan\n",
    "    else:\n",
    "        df.at[i, 'delta_radii'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d753ea5-3c4c-4008-ad77-9ee67788e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['delta_radii'] = 0\n",
    "#df['timepoint'] = '_'\n",
    "#for i in tqdm(range(len(df))):\n",
    "#    if '_0001' not in df.iloc[i]['scan']:\n",
    "#        df['delta_radii'].iloc[i] = 0\n",
    "#        df['timepoint'].iloc[i] = 'pre-stimulus'\n",
    "#    elif '_0001' in df.iloc[i]['scan']:\n",
    "#        df['timepoint'].iloc[i] = 'post-stimulus'\n",
    "#        if re.sub('_0001','',df.iloc[i]['scan']) in np.unique(df['scan']):\n",
    "#            df['delta_radii'].iloc[i] = df['radii'].iloc[i] - df['radii'].iloc[np.where((df['scan'] == re.sub('_0001','',df.iloc[i]['scan'])) & (df['vessel_id']==df.iloc[i]['vessel_id']))]\n",
    "#        elif re.sub('_0001','',df.iloc[i]['scan']) not in np.unique(df['scan']):\n",
    "#            df['delta_radii'].iloc[i] = \"NA\"\n",
    "#        else:\n",
    "#            print('error')\n",
    "#            break\n",
    "#    else:\n",
    "#        print('error')\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f6466a-7a1e-4f79-9fd1-f65990626d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163812.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[\"timepoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca55bbb3-9ae6-4500-bf29-05c2e9e7c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('results_sv.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a62776-188f-4950-bebf-ce025c34412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('matt_preds_graphs_fwhm_single_excel/results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f1cd72-5ad0-4285-a054-a3eec9116660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SHAM'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sham = df[df['treatment']=='SHAM']\n",
    "np.unique(df_sham['treatment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ac1ae98-4077-4275-928f-7103c23f3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [13:52<00:00,  1.06s/it] \n"
     ]
    }
   ],
   "source": [
    "scans = sorted(list(np.unique(df['scan'])))\n",
    "_scans = [re.sub('vbm','',re.sub('TBI','',re.sub('SHAM','',re.sub('_3D','',x)))) + '_warped' for x in scans]\n",
    "for file in tqdm(files[::-1]):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    _file = re.sub(' 2020_',' ',re.sub('-xyz','_xyz',re.sub('-XYZ','_XYZ',file)))\n",
    "    if ' ' in _file:\n",
    "        _file = _file.split(' ')[0] + '_' + _file.split(' ')[-1]\n",
    "    match_file = list(filter(lambda str: str in _file, _scans))\n",
    "    #print(file)\n",
    "    #print(match_file)\n",
    "    if len(match_file) == 1:\n",
    "        scan = np.array(scans)[np.array(_scans) == match_file[0]][0]\n",
    "        df_subset = df[df[\"scan\"] == scan]\n",
    "        if len(df_subset) == len(graph.edges):\n",
    "            #print(df_subset)\n",
    "            for i in range(len(df_subset)):\n",
    "                graph[df_subset.iloc[i]['source']][df_subset.iloc[i]['target']]['mean_vessel_radii_baseline'] = df_subset.iloc[i]['mean_vessel_radii_baseline']\n",
    "                graph[df_subset.iloc[i]['source']][df_subset.iloc[i]['target']]['std_vessel_radii_baseline'] = df_subset.iloc[i]['std_vessel_radii_baseline']\n",
    "                graph[df_subset.iloc[i]['source']][df_subset.iloc[i]['target']]['num_vessel_radii_baseline'] = df_subset.iloc[i]['num_vessel_radii_baseline']\n",
    "                graph[df_subset.iloc[i]['source']][df_subset.iloc[i]['target']]['delta_radii'] = df_subset.iloc[i]['delta_radii']\n",
    "                graph[df_subset.iloc[i]['source']][df_subset.iloc[i]['target']]['timepoint'] = df_subset.iloc[i]['timepoint']\n",
    "            nx.write_gpickle(graph,re.sub('.pickle','_full.pickle',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c3f7224-1c8e-4c57-aec2-78f6d024edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[0]['pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1514e80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('path_weights_nrn',axis=1)\n",
    "df = df.drop('path_weights_uncertanty',axis=1)\n",
    "df = df.drop('path_weights',axis=1)\n",
    "df = df.drop('pts',axis=1)\n",
    "len(df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae0151-dd0c-4379-a019-dfd11bdfda1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d487cdd-5b69-412d-a3b9-579bb9962580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('matt_preds_graphs_fwhm_single_excel/results_smaller.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6782f754-084c-4775-ac43-b4cbbf52a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19b62220-c16d-4f0a-b704-ef40deec2844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.  , 247.95, 249.2 , 249.85, 250.8 , 500.  ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['start_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a3e0f3-a324-4f40-9b39-caa755e6e2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject                                                      C5703_3D\n",
       "vessel_id                                                       12334\n",
       "start_weight                                                     42.0\n",
       "wavelength                                                        552\n",
       "power                                                               9\n",
       "path_weights_nrn    [131.0, 130.4, 129.9, 130.2, 130.6, 130.6, 132...\n",
       "path_weights        (0.9757575757575756, 0.723529411764706, 0.8625...\n",
       "gender                                                             NA\n",
       "scan                                               C5703_3D_XYZres462\n",
       "treatment                                                         C57\n",
       "euclidean-dst                                               82.957821\n",
       "weight                                                     138.912901\n",
       "start_depth                                                     500.0\n",
       "imaging_weight                                                   31.0\n",
       "pts                 [[1, 223, 87], [1, 223, 86], [1, 223, 85], [1,...\n",
       "radii                                                        1.403185\n",
       "age                                                           unknown\n",
       "stim                                                      optogenetic\n",
       "vertex_id_base      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "timepoint                                                         0.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sham = df[df['treatment']!='VBM']\n",
    "df_sham = df_sham.drop('neuron_distance_min',axis=1)\n",
    "df_sham = df_sham.drop('neuron_distance_std',axis=1)\n",
    "df_sham = df_sham.drop('end-0z',axis=1)\n",
    "df_sham = df_sham.drop('end-0y',axis=1)\n",
    "df_sham = df_sham.drop('end-0x',axis=1)\n",
    "df_sham = df_sham.drop('end-1z',axis=1)\n",
    "df_sham = df_sham.drop('end-1y',axis=1)\n",
    "df_sham = df_sham.drop('end-1x',axis=1)\n",
    "#df_sham = df_sham.drop('pts',axis=1)\n",
    "df_sham = df_sham.drop('mean_depth',axis=1)\n",
    "df_sham = df_sham.drop('delta_radii',axis=1)\n",
    "df_sham = df_sham.drop('num_vessel_radii_baseline',axis=1)\n",
    "df_sham = df_sham.drop('path_weights_uncertanty',axis=1)\n",
    "#df_sham = df_sham.drop('start_depth',axis=1)\n",
    "df_sham = df_sham.drop('source',axis=1)\n",
    "df_sham = df_sham.drop('target',axis=1)\n",
    "df_sham = df_sham.drop('radii_std',axis=1)\n",
    "df_sham = df_sham.drop('days_post_injury',axis=1)\n",
    "df_sham = df_sham.drop('mean_vessel_radii_baseline',axis=1)\n",
    "df_sham = df_sham.drop('std_vessel_radii_baseline',axis=1)\n",
    "df_sham = df_sham.drop('current',axis=1)\n",
    "df_sham = df_sham.drop('frequency',axis=1)\n",
    "df_sham = df_sham.drop('mean_neuron_distance',axis=1)\n",
    "df_sham = df_sham.drop('path_weights_nrn_dst',axis=1)\n",
    "df_sham.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d12e89-ac5e-4158-99df-31a6bef2f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "_scans = [re.sub('vbm','',re.sub('TBI','',re.sub('SHAM','',re.sub('_3D','',x)))) for x in scans]\n",
    "_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f0b347f-7558-46a2-9a7d-41b00f0e45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sham_exp = df_sham.explode(['path_weights', 'path_weights_nrn','pts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73e94493-7f87-45c9-84b8-7425f2a0c348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject                                                      C5703_3D\n",
       "vessel_id                                                       12334\n",
       "start_weight                                                     42.0\n",
       "wavelength                                                        552\n",
       "power                                                               9\n",
       "path_weights_nrn                                                131.0\n",
       "path_weights                                                 0.975758\n",
       "gender                                                             NA\n",
       "scan                                               C5703_3D_XYZres462\n",
       "treatment                                                         C57\n",
       "euclidean-dst                                               82.957821\n",
       "weight                                                     138.912901\n",
       "start_depth                                                     500.0\n",
       "imaging_weight                                                   31.0\n",
       "pts                                                      [1, 223, 87]\n",
       "radii                                                        1.403185\n",
       "age                                                           unknown\n",
       "stim                                                      optogenetic\n",
       "vertex_id_base      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "timepoint                                                         0.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sham_exp.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a19d96b9-0c1f-4f47-b2d8-98859b73e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 504, 504, 504], dtype=int16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(df_sham_exp['pts'].values)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54d73c53-4d6c-4187-a5d1-77d48015b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sham_exp['a'] = np.stack(df_sham_exp['pts'].values)[:,0]\n",
    "df_sham_exp['b'] = np.stack(df_sham_exp['pts'].values)[:,1]\n",
    "df_sham_exp['c'] = np.stack(df_sham_exp['pts'].values)[:,2]\n",
    "df_sham_exp = df_sham_exp.drop('pts',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1971d580-dc61-4b24-86b6-1b676039206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sham_exp['vertex_id'] = df_sham_exp['vessel_id'].astype('str') + '_' + df_sham_exp['a'].astype('str') + '_' + df_sham_exp['b'].astype('str') + '_' + df_sham_exp['c'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2bf3347-c93e-4646-a888-9b480df9ca2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sham_exp.to_csv('matt_preds_graphs_fwhm_single_excel/results_vertexwise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d88f6061-0386-4c11-a0f1-2d63a2470ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           16419_1_278_153\n",
       "0           16419_1_278_152\n",
       "0           16419_1_278_151\n",
       "0           16419_1_278_150\n",
       "0           16419_1_277_149\n",
       "                ...        \n",
       "326435    30130_510_203_137\n",
       "326435    30130_509_202_138\n",
       "326435    30130_509_202_139\n",
       "326435    30130_509_202_140\n",
       "326435    30130_509_202_141\n",
       "Name: vertex_id, Length: 6481061, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sham_exp['vertex_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b480674-d193-42a2-bfef-f59e83fe08e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight', 'euclidean-dst', 'path_weights_nrn', 'power', 'gender',\n",
       "       'imaging_weight', 'vessel_id', 'path_weights', 'start_weight', 'radii',\n",
       "       'treatment', 'subject', 'scan', 'wavelength', 'age', 'start_depth',\n",
       "       'stim', 'timepoint', 'a', 'b', 'c'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sham_exp.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7edf396-7373-4a47-a8ad-d76cce2f7e3e",
   "metadata": {},
   "source": [
    "# radii via path gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330932e-e467-45fc-b9bf-76be7ef19346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634549f-9913-492d-8332-fd8b5f879ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "from skimage.feature import peak_local_max\n",
    "import imageio\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    nodes = np.asarray(nodes)\n",
    "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "    if np.min(dist_2)>10:\n",
    "        return node\n",
    "    else:\n",
    "        return nodes[np.argmin(dist_2)]\n",
    "\n",
    "sampling = 1/5\n",
    "\n",
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for i in tqdm(range(len(graph.edges))):\n",
    "    path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "    _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii == 0:\n",
    "        _pred_radii =1\n",
    "    _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii_0001 == 0:\n",
    "        _pred_radii_0001 =1\n",
    "    \n",
    "    _box_fit = max([np.int16(_pred_radii_max)+15, np.int16(_pred_radii_max_0001)+15, 10])\n",
    "    #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "    path_smooth = np.float32(np.copy(path))\n",
    "    for k in range(len(path[0])):\n",
    "        path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),3,mode='nearest')\n",
    "    path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    x,y = np.meshgrid(X,Y)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = np.zeros(len(x))\n",
    "    xy = np.vstack([x,y,z])\n",
    "    \n",
    "    \n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    \n",
    "    res_fwhm_sigma = []\n",
    "    res_fwhm_sigma_0001 = []\n",
    "    \n",
    "    for I in tqdm(range(len(path))):\n",
    "        point_grad = path_grad[I]\n",
    "        point = path[I]\n",
    "        if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "            rotated = xy.T + point\n",
    "        else:\n",
    "            rotated = _rotmat(point_grad,xy.T) + point\n",
    "        points_img = sp.ndimage.map_coordinates(#np.int16(mean[1]*1024),\n",
    "                                            deconv_img,\n",
    "                                            rotated.T, \n",
    "                                            order=1,\n",
    "                                            mode='constant')\n",
    "        points_img_0001 = sp.ndimage.map_coordinates(#np.int16(mean_0001[1]*1024),\n",
    "                                                 deconv_img_0001,\n",
    "                                                 rotated.T, \n",
    "                                                 order=1,\n",
    "                                                 mode='constant')\n",
    "                \n",
    "        points_img = np.reshape(points_img,(len(X),len(Y)))\n",
    "        points_img = sp.ndimage.gaussian_filter(points_img, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        #points_img = sp.ndimage.median_filter(points_img, size = np.int32(np.max([np.min([_pred_radii,_pred_radii_0001])*.4,1])))\n",
    "        points_img_0001 = np.reshape(points_img_0001,(len(X),len(Y)))\n",
    "        points_img_0001 = sp.ndimage.gaussian_filter(points_img_0001, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        #points_img_0001 = sp.ndimage.median_filter(points_img_0001, size = np.int32(np.max([np.min([_pred_radii,_pred_radii_0001])*.4,1])))\n",
    "        \n",
    "        _point = np.array(np.arange(0,np.max([_pred_radii,_pred_radii_0001])+10,sampling))\n",
    "        _zeros = np.zeros(len(_point))\n",
    "        _point = np.array([_point,_zeros])\n",
    "        _centre = closest_node([len(X)//2+1,len(Y)//2+1],peak_local_max(points_img.T))\n",
    "        _centre_0001 = closest_node([len(X)//2+1,len(Y)//2+1],peak_local_max(points_img_0001.T))\n",
    "        \n",
    "        _res = []\n",
    "        \n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img,\n",
    "                  vmin = 0,\n",
    "                  vmax = np.max(deconv_img))\n",
    "        ax.scatter(_centre[0],_centre[1])\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "            rot_point[0] = rot_point[0] + _centre[0]\n",
    "            rot_point[1] = rot_point[1] + _centre[1]\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img.T,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=np.min([_pred_radii,_pred_radii_0001])*.4/sampling)\n",
    "            points_vals_grad = np.gradient(points_vals)\n",
    "            #plt.scatter(*rot_point,\n",
    "            #            c=points_vals,\n",
    "            #            vmin=np.min(points_vals), \n",
    "            #            vmax=np.max(points_vals))\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals)),np.less,order=3))\n",
    "            if _.shape[1] != 0:\n",
    "                points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "            else:\n",
    "                points_vals_grad = np.gradient(points_vals)\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "        _res = np.array(_res)\n",
    "        _res = _res[np.where(_res!=0)]\n",
    "        _mean = np.mean(_res)\n",
    "        _std = np.std(_res)\n",
    "        _mask = np.where(np.logical_and(_res>_mean-2*_std, _res<_mean+2*_std))\n",
    "        _res = _res[_mask]\n",
    "        radii = np.mean(_res)\n",
    "        circ = Circle(_centre,radii,fill=False)\n",
    "        #ax.scatter(_centre[0],_centre[1],color='blue')\n",
    "        ax.add_patch(circ)\n",
    "        fig.savefig('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png')\n",
    "        plt.show()\n",
    "        #plt.clf()\n",
    "        _res_0001 = []\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img_0001,\n",
    "                  vmin = 0,\n",
    "                  vmax = np.max(deconv_img_0001))\n",
    "        ax.scatter(_centre_0001[0],_centre_0001[1])\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "            rot_point[0] = rot_point[0] + _centre_0001[0]\n",
    "            rot_point[1] = rot_point[1] + _centre_0001[1]\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img_0001.T,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=np.min([_pred_radii,_pred_radii_0001])*.4/sampling)\n",
    "            points_vals_grad = np.gradient(points_vals)\n",
    "            #plt.scatter(*rot_point,\n",
    "            #            c=points_vals,\n",
    "            #            vmin=np.min(points_vals), \n",
    "            #            vmax=np.max(points_vals))\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals)),np.less,order=3))\n",
    "            if _.shape[1] != 0:\n",
    "                points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res_0001.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre_0001[0],_*sampling*np.sin(np.deg2rad(deg))+_centre_0001[1],color='r')\n",
    "            else:\n",
    "                points_vals_grad = np.gradient(points_vals)\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res_0001.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre_0001[0],_*sampling*np.sin(np.deg2rad(deg))+_centre_0001[1],color='r')\n",
    "        _res_0001 = np.array(_res_0001)\n",
    "        _res_0001 = _res_0001[np.where(_res_0001!=0)]\n",
    "        _mean_0001 = np.mean(_res_0001)\n",
    "        _std_0001 = np.std(_res_0001)\n",
    "        _mask = np.where(np.logical_and(_res_0001>_mean_0001-2*_std_0001, _res_0001<_mean_0001+2*_std_0001))\n",
    "        _res_0001 = _res_0001[_mask]\n",
    "        radii_0001 = np.mean(_res_0001)\n",
    "        circ = Circle(_centre_0001,radii_0001,fill=False)\n",
    "        ax.add_patch(circ)\n",
    "        res_fwhm.append(radii)\n",
    "        res_fwhm_0001.append(radii_0001)\n",
    "        #plt.imshow(points_img)\n",
    "        #for i in range(len(_res)):\n",
    "        #ax.scatter(_centre_0001[0],_centre_0001[1],color='blue')\n",
    "        fig.savefig('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png')\n",
    "        plt.show()\n",
    "        #plt.clf()\n",
    "    images = []\n",
    "    for I in tqdm(range(len(path))):\n",
    "        images.append(imageio.imread('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png'))\n",
    "        os.remove('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png')\n",
    "    imageio.mimsave('/home/rozakmat/scratch/gifs/'+str(i)+'_0001.gif', images, format='GIF', fps=2)\n",
    "    for I in tqdm(range(len(path))):\n",
    "        images.append(imageio.imread('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png'))\n",
    "        os.remove('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png')\n",
    "    imageio.mimsave('/home/rozakmat/scratch/gifs/'+str(i)+'.gif', images, format='GIF', fps=2)\n",
    "    plt.plot(res_fwhm)\n",
    "    plt.plot(res_fwhm_0001)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790bdc8-6edc-4e38-a3f5-b80aba7a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df13528-29dd-4040-9837-67e2f5b14e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_fwhm)\n",
    "plt.plot(res_fwhm_0001)\n",
    "print(np.mean(res_fwhm))\n",
    "print(np.mean(res_fwhm_0001))\n",
    "print(np.mean(res_fwhm_0001)-np.mean(res_fwhm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf279a7-7816-4b14-9b9b-4ef46851a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_pred_radii)\n",
    "#plt.scatter(*_point + len(x)//2 +1)\n",
    "_res = []\n",
    "for deg in np.arange(0,360,10):\n",
    "    rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "    rot_point[0] = rot_point[0] + _centre_0001[0]\n",
    "    rot_point[1] = rot_point[1] + _centre_0001[1]\n",
    "    points_vals = sp.ndimage.map_coordinates(points_img_0001.T,\n",
    "                                             rot_point, \n",
    "                                             order=5,\n",
    "                                             cval=0)\n",
    "    points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=_pred_radii/sampling)\n",
    "    points_vals = points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals))\n",
    "    #plt.plot(points_vals)\n",
    "    #plt.show()\n",
    "    #points_vals_grad = np.gradient(points_vals)\n",
    "    _ = np.array(sp.signal.argrelextrema(points_vals,np.less,order=5))\n",
    "    #print(_)\n",
    "    if _.shape[1] != 0:\n",
    "        print(_)\n",
    "        #print(points_vals)\n",
    "        #print(_[0,0])\n",
    "        plt.plot(points_vals[:(_[0,0]+3)])\n",
    "        #plt.show()\n",
    "        points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "        _ = np.argmin(points_vals_grad)\n",
    "        _res.append(_*sampling)\n",
    "        #plt.plot(points_vals_grad)\n",
    "    else:\n",
    "        plt.plot(points_vals)\n",
    "        #plt.show()\n",
    "        points_vals_grad = np.gradient(points_vals)\n",
    "        _ = np.argmin(points_vals_grad)\n",
    "        _res.append(_*sampling)\n",
    "        #plt.plot(points_vals_grad)\n",
    "plt.show()\n",
    "_res = np.array(_res)\n",
    "plt.plot(_res)\n",
    "plt.show()\n",
    "#_mean = np.mean(_res)\n",
    "#_std = np.std(_res)\n",
    "#_mask = np.where(np.logical_and(_res>_mean-2*_std, _res<_mean+2*_std))\n",
    "#_res = _res[_mask]\n",
    "#plt.plot(_res)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684651e-315e-42c3-bb51-4d2b54626ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(points_img_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89bec5-7c3c-4ec8-bea1-832bbf44b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888b6c6-9472-42f4-ad2f-3cc594ec8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3525b-d7ef-4c63-acb0-ceaa7a5deabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res = np.array(_res)\n",
    "_mean = np.mean(_res)\n",
    "_std = np.std(_res)\n",
    "_mask = np.where(np.logical_and(_res>_mean-_std, _res<_mean+_std))\n",
    "_res = _res[_mask]\n",
    "plt.hist(_res)\n",
    "plt.show()\n",
    "#_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcc75e-bab8-46aa-abe9-273b5e88776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(graph.edges))):\n",
    "    path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "    _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii == 0:\n",
    "        _pred_radii =1\n",
    "    _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii_0001 == 0:\n",
    "        _pred_radii_0001 =1\n",
    "    \n",
    "    _box_fit = max([np.int16(_pred_radii_max)+10, np.int16(_pred_radii_max_0001)+10, 10])\n",
    "    #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "    path_smooth = np.float32(np.copy(path))\n",
    "    for k in range(len(path[0])):\n",
    "        path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),3,mode='nearest')\n",
    "    path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    x,y = np.meshgrid(X,Y)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = np.zeros(len(x))\n",
    "    xy = np.vstack([x,y,z])\n",
    "    \n",
    "    \n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    \n",
    "    res_fwhm_sigma = []\n",
    "    res_fwhm_sigma_0001 = []\n",
    "    \n",
    "    def calc_fwhm_path(I):\n",
    "        point_grad = path_grad[I]\n",
    "        point = path[I]\n",
    "        if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "            rotated = xy.T + point\n",
    "        else:\n",
    "            rotated = _rotmat(point_grad,xy.T) + point\n",
    "        points_img = sp.ndimage.map_coordinates(#np.int16(mean[1]*1024),\n",
    "                                            deconv_img,\n",
    "                                            rotated.T, \n",
    "                                            order=3,\n",
    "                                            mode='constant')\n",
    "        points_img_0001 = sp.ndimage.map_coordinates(#np.int16(mean_0001[1]*1024),\n",
    "                                                 deconv_img_0001,\n",
    "                                                 rotated.T, \n",
    "                                                 order=3,\n",
    "                                                 mode='constant')\n",
    "                \n",
    "        points_img = np.reshape(points_img,(len(X),len(Y)))\n",
    "        points_img_no_smooth = np.copy(points_img)\n",
    "        points_img = sp.ndimage.gaussian_filter(points_img, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        #points_img = sp.ndimage.median_filter(points_img, size = np.int32(np.max([np.min([_pred_radii,_pred_radii_0001])*.4,1])))\n",
    "        points_img_0001 = np.reshape(points_img_0001,(len(X),len(Y)))\n",
    "        points_img_0001_no_smooth = np.copy(points_img_0001)\n",
    "        points_img_0001 = sp.ndimage.gaussian_filter(points_img_0001, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        #points_img_0001 = sp.ndimage.median_filter(points_img_0001, size = np.int32(np.max([np.min([_pred_radii,_pred_radii_0001])*.4,1])))\n",
    "        \n",
    "        _point = np.array(np.arange(0,np.max([_pred_radii,_pred_radii_0001])+20,sampling))\n",
    "        _zeros = np.zeros(len(_point))\n",
    "        _point = np.array([_point,_zeros])\n",
    "        _centre = closest_node([len(X)//2+1,len(Y)//2+1],peak_local_max(points_img.T))\n",
    "        _centre_0001 = closest_node([len(X)//2+1,len(Y)//2+1],peak_local_max(points_img_0001.T))\n",
    "        \n",
    "        _res = []\n",
    "        \n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img_no_smooth,\n",
    "                  vmin = 0,\n",
    "                  vmax = np.max(deconv_img))\n",
    "        ax.scatter(_centre[0],_centre[1])\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "            rot_point[0] = rot_point[0] + _centre[0]\n",
    "            rot_point[1] = rot_point[1] + _centre[1]\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img.T,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=np.min([_pred_radii,_pred_radii_0001])*.4/sampling)\n",
    "            points_vals_grad = np.gradient(points_vals)\n",
    "            #plt.scatter(*rot_point,\n",
    "            #            c=points_vals,\n",
    "            #            vmin=np.min(points_vals), \n",
    "            #            vmax=np.max(points_vals))\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals)),np.less,order=3))\n",
    "            if _.shape[1] != 0:\n",
    "                points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "            else:\n",
    "                points_vals_grad = np.gradient(points_vals)\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                _res.append(_*sampling)\n",
    "                ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre[0],_*sampling*np.sin(np.deg2rad(deg))+_centre[1],color='r')\n",
    "        _res = np.array(_res)\n",
    "        _res = _res[np.where(_res!=0)]\n",
    "        _mean = np.mean(_res)\n",
    "        _std = np.std(_res)\n",
    "        _mask = np.where(np.logical_and(_res>_mean-2*_std, _res<_mean+2*_std))\n",
    "        _res = _res[_mask]\n",
    "        radii = np.mean(_res)\n",
    "        circ = Circle(_centre,radii,fill=False)\n",
    "        ax.add_patch(circ)\n",
    "        ax.set_title(radii)\n",
    "        fig.savefig('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png')\n",
    "        plt.clf()\n",
    "        _res_0001 = []\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img_0001_no_smooth,\n",
    "                  vmin = 0,\n",
    "                  vmax = np.max(deconv_img_0001))\n",
    "        ax.scatter(_centre_0001[0],_centre_0001[1])\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point)\n",
    "            rot_point[0] = rot_point[0] + _centre_0001[0]\n",
    "            rot_point[1] = rot_point[1] + _centre_0001[1]\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img_0001.T,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            points_vals = sp.ndimage.gaussian_filter1d(points_vals,sigma=np.min([_pred_radii,_pred_radii_0001])*.4/sampling)\n",
    "            points_vals_grad = np.gradient(points_vals)\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals + np.random.uniform(-1e-5,1e-5,len(points_vals)),np.less,order=3))\n",
    "            if _.shape[1] != 0:\n",
    "                points_vals_grad = np.gradient(points_vals[:_[0,0]+3])\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                if _ != 0:\n",
    "                    _res_0001.append(_*sampling)\n",
    "                    ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre_0001[0],_*sampling*np.sin(np.deg2rad(deg))+_centre_0001[1],color='r')\n",
    "            else:\n",
    "                points_vals_grad = np.gradient(points_vals)\n",
    "                _ = np.argmin(points_vals_grad)\n",
    "                if _ != 0:\n",
    "                    _res_0001.append(_*sampling)\n",
    "                    ax.scatter(_*sampling*np.cos(np.deg2rad(deg))+_centre_0001[0],_*sampling*np.sin(np.deg2rad(deg))+_centre_0001[1],color='r')\n",
    "        _res_0001 = np.array(_res_0001)\n",
    "        _res_0001 = _res_0001[np.where(_res_0001!=0)]\n",
    "        _mean_0001 = np.mean(_res_0001)\n",
    "        _std_0001 = np.std(_res_0001)\n",
    "        _mask = np.where(np.logical_and(_res_0001>_mean_0001-2*_std_0001, _res_0001<_mean_0001+2*_std_0001))\n",
    "        _res_0001 = _res_0001[_mask]\n",
    "        radii_0001 = np.mean(_res_0001)\n",
    "        circ = Circle(_centre_0001,radii_0001,fill=False)\n",
    "        ax.add_patch(circ)\n",
    "        ax.set_title(radii_0001)\n",
    "        fig.savefig('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png')\n",
    "        plt.clf()\n",
    "            \n",
    "        return radii, radii_0001\n",
    "    \n",
    "    pool = multiprocessing.Pool(8)\n",
    "    res_fwhm, res_fwhm_0001,  = zip(*pool.map(calc_fwhm_path, range(len(path))))\n",
    "    print(np.mean(res_fwhm_0001)-np.mean(res_fwhm))\n",
    "    #plt.plot(res_fwhm)\n",
    "    #plt.plot(res_fwhm_0001)\n",
    "    #plt.show()\n",
    "    images = []\n",
    "    for I in tqdm(range(len(path))):\n",
    "        images.append(imageio.imread('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png'))\n",
    "        os.remove('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'_0001.png')\n",
    "    imageio.mimsave('/home/rozakmat/scratch/gifs/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'_0001.gif', images, format='GIF', fps=2)\n",
    "    images = []\n",
    "    for I in tqdm(range(len(path))):\n",
    "        images.append(imageio.imread('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png'))\n",
    "        os.remove('/home/rozakmat/scratch/_tmp/'+str(i)+'_'+str(I)+'.png')\n",
    "    imageio.mimsave('/home/rozakmat/scratch/gifs/'+re.sub('matt_raw_warped_upsampled_seg/','',re.sub('_warped.pickle','',file))+str(i)+'.gif', images, format='GIF', fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a19f84-ffda-480f-98be-20bef424b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffae09b-fa4d-441f-b3b7-f5d0adc0773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c6557-9a89-419c-933b-e34838b72d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bfd91b-62e0-4630-9091-db51ced7df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_std,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022f6e6-ad34-40c3-b834-889ff8336209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_img,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8abecf-6fae-4e6f-bda6-9ed0dfe61712",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_0001,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5112a-edf5-4da6-ae45-e9f9efe87cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_std_0001,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d234ce0-24e3-476d-bc89-2421e357e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_img_0001,(len(X),len(Y))))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4766b-8db9-4c5f-bb73-f073f83db44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.reshape(points,(len(X),len(Y)))\n",
    "points_std = np.reshape(points_std,(len(X),len(Y)))\n",
    "_bin = np.zeros(points.shape)\n",
    "_bin[(points > min_prob) * (points_std < max_var)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e25fe5-64f8-4f5a-9f3d-f88f6db0c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9892d-d90b-4d5c-ac36-57cb973d61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_0001 = np.reshape(points_0001,(len(X),len(Y)))\n",
    "points_std_0001 = np.reshape(points_std_0001,(len(X),len(Y)))\n",
    "_bin_0001 = np.zeros(points_0001.shape)\n",
    "_bin_0001[(points_0001 > min_prob) * (points_std_0001 < max_var)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b99fef-cebc-414b-b737-76ec22d31d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_bin_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0850bd6-21ae-42a2-b80a-efa7e7145964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = sp.ndimage.zoom(np.swapaxes(img[:,0,:,:],0,2),(1,1,2.645833333))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7d109-1283-4586-a943-a7c5b8318f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argwhere(img_lab)[((np.argwhere(img_lab) - [int(img_lab.shape[0]/2),int(img_lab.shape[1]/2)])**2).sum(1).argmin()]\n",
    "cent_val = img_lab[idx[0],idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb411c-cf19-4fc9-bf33-685957853842",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lab, N = cc3d.connected_components(_bin,return_N=True)\n",
    "unique, counts = np.unique(img_lab, return_counts=True)\n",
    "img_lab =  np.reshape(img_lab,(len(X),len(Y)))\n",
    "cent_val = img_lab[int(img_lab.shape[0]/2),[int(img_lab.shape[1]/2)]][0]\n",
    "if cent_val == 0 and np.sum(img_lab) == 0:\n",
    "    area = 0\n",
    "    radii = 0\n",
    "elif cent_val == 0 and np.sum(img_lab) != 0:\n",
    "    idx = np.argwhere(img_lab)[((np.argwhere(img_lab) - [int(img_lab.shape[0]/2),int(img_lab.shape[1]/2)])**2).sum(1).argmin()]\n",
    "    cent_val = img_lab[idx[0],idx[1]]\n",
    "    area = np.sum(img_lab==cent_val)\n",
    "    radii = np.sqrt(area/np.pi)\n",
    "else:\n",
    "    area = np.sum(img_lab==cent_val)\n",
    "    radii = np.sqrt(area/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e54f92-e4a2-4231-9614-5ce5143a912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488f89d-45cf-4429-a48d-bcf8b81c15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0ff5d-c740-46e4-8f81-f13f52412c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lab_0001, N_0001 = cc3d.connected_components(_bin_0001,return_N=True)\n",
    "unique_0001, counts_0001 = np.unique(img_lab_0001, return_counts=True)\n",
    "img_lab_0001 =  np.reshape(img_lab_0001,(len(X),len(Y)))\n",
    "cent_val_0001 = img_lab_0001[int(img_lab_0001.shape[0]/2),[int(img_lab_0001.shape[1]/2)]][0]\n",
    "if cent_val_0001 == 0 and np.sum(img_lab_0001) == 0:\n",
    "    area_0001 = 0\n",
    "    radii_0001 = 0\n",
    "elif cent_val_0001 == 0 and np.sum(img_lab_0001) == 0:\n",
    "    idx_0001 = np.argwhere(img_lab_0001)[((np.argwhere(img_lab_0001) - [int(img_lab_0001.shape[0]/2),int(img_lab_0001.shape[1]/2)])**2).sum(1).argmin()]\n",
    "    cent_val_0001 = img_lab_0001[idx_0001[0],idx_0001[1]]\n",
    "    area_0001 = np.sum(img_lab_0001==cent_val_0001)\n",
    "    radii_0001 = np.sqrt(area_0001/np.pi)\n",
    "else:\n",
    "    area_0001 = np.sum(img_lab_0001==cent_val_0001)\n",
    "    radii_0001 = np.sqrt(area_0001/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739e615-f7fb-4a37-b598-66b00619b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5c651-6b22-4421-b6a3-85c3d5187677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "\n",
    "sampling = 1/3\n",
    "\n",
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for i in tqdm(range(len(graph.edges))):\n",
    "    i=20\n",
    "    path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "    _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii == 0:\n",
    "        _pred_radii =1\n",
    "    _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "    if _pred_radii_0001 == 0:\n",
    "        _pred_radii_0001 =1\n",
    "    \n",
    "    _box_fit = max([np.int16(_pred_radii_max)+10, np.int16(_pred_radii_max_0001)+10, 10])\n",
    "    #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "    path_smooth = np.float32(np.copy(path))\n",
    "    for k in range(len(path[0])):\n",
    "        path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),3,mode='nearest')\n",
    "    path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "    x,y = np.meshgrid(X,Y)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = np.zeros(len(x))\n",
    "    xy = np.vstack([x,y,z])\n",
    "    \n",
    "    \n",
    "    res_fwhm = []\n",
    "    res_fwhm_0001 = []\n",
    "    \n",
    "    res_fwhm_sigma = []\n",
    "    res_fwhm_sigma_0001 = []\n",
    "    \n",
    "    for I in range(len(path)):\n",
    "        point_grad = path_grad[I]\n",
    "        point = path[I]\n",
    "        if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "            rotated = xy.T + point\n",
    "        else:\n",
    "            rotated = _rotmat(point_grad,xy.T) + point\n",
    "        points_img = sp.ndimage.map_coordinates(deconv_img,\n",
    "                                            rotated.T, \n",
    "                                            order=1,\n",
    "                                            cval=-10000)\n",
    "        points_img_0001 = sp.ndimage.map_coordinates(deconv_img_0001,\n",
    "                                                 rotated.T, \n",
    "                                                 order=1,\n",
    "                                                 cval=-10000)\n",
    "                \n",
    "        points_img = np.reshape(points_img,(len(X),len(Y)))\n",
    "        points_img = sp.ndimage.gaussian_filter(points_img, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        points_img_lp = sp.ndimage.laplace(points_img)\n",
    "        plt.imshow(points_img_lp)\n",
    "        plt.show()\n",
    "        points_img_0001 = np.reshape(points_img_0001,(len(X),len(Y)))\n",
    "        points_img_0001 = sp.ndimage.gaussian_filter(points_img_0001, sigma = np.min([_pred_radii,_pred_radii_0001])*.4)\n",
    "        points_img_0001_lp = sp.ndimage.laplace(points_img_0001)\n",
    "        _point = np.array(np.arange(0,np.max([_pred_radii,_pred_radii_0001])+5,sampling))\n",
    "        _zeros = np.zeros(len(_point))\n",
    "        _point = np.array([_point,_zeros])\n",
    "        \n",
    "        _res = []\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point) + len(X)//2 +1\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img_lp,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            #points_vals_grad = np.gradient(points_vals)\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals, np.greater))\n",
    "            if _.shape[1] != 0:\n",
    "                _res.append(_[0,0]*sampling)\n",
    "        _res = np.array(_res)\n",
    "        _mean = np.mean(_res)\n",
    "        _std = np.std(_res)\n",
    "        _mask = np.where(np.logical_and(_res>_mean-2*_std, _res<_mean+2*_std))\n",
    "        _res = _res[_mask]\n",
    "        radii = np.mean(_res)\n",
    "        \n",
    "        _res_0001 = []\n",
    "        for deg in np.arange(0,360,10):\n",
    "            rot_point = np.dot(np.array([[np.cos(np.deg2rad(deg)),-1*np.sin(np.deg2rad(deg))],[np.sin(np.deg2rad(deg)),np.cos(np.deg2rad(deg))]]),_point) + len(X)//2 +1\n",
    "            points_vals = sp.ndimage.map_coordinates(points_img_0001_lp,\n",
    "                                                     rot_point, \n",
    "                                                     order=3,\n",
    "                                                     cval=0)\n",
    "            #points_vals_grad = np.gradient(points_vals)\n",
    "            _ = np.array(sp.signal.argrelextrema(points_vals, np.greater))\n",
    "            if _.shape[1] != 0:\n",
    "                _res_0001.append(_[0,0]*sampling)\n",
    "        _res_0001 = np.array(_res_0001)\n",
    "        _mean = np.mean(_res_0001)\n",
    "        _std = np.std(_res_0001)\n",
    "        _mask = np.where(np.logical_and(_res_0001>_mean-2*_std, _res_0001<_mean+2*_std))\n",
    "        _res_0001 = _res_0001[_mask]\n",
    "        radii_0001 = np.mean(_res_0001)\n",
    "        res_fwhm.append(radii)\n",
    "        res_fwhm_0001.append(radii_0001)\n",
    "        \n",
    "        #plt.imshow(points_img)\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img)\n",
    "        circ = Circle((len(X)//2+1,len(Y)//2+1),_mean,fill=False)\n",
    "        ax.add_patch(circ)\n",
    "        for i in range(len(_res)):\n",
    "            ax.scatter(_res[i]*np.cos(np.deg2rad(i*10))+len(X)//2+1,_res[i]*np.sin(np.deg2rad(i*10))+len(Y)//2+1)\n",
    "        plt.show()\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.imshow(points_img_0001)\n",
    "        circ = Circle((len(X)//2+1,len(Y)//2+1),_mean,fill=False)\n",
    "        ax.add_patch(circ)\n",
    "        for i in range(len(_res_0001)):\n",
    "            ax.scatter(_res_0001[i]*np.cos(np.deg2rad(i*10))+len(X)//2+1,_res_0001[i]*np.sin(np.deg2rad(i*10))+len(Y)//2+1)\n",
    "        plt.show()\n",
    "        break\n",
    "    #lt.plot(res_fwhm)\n",
    "    #lt.plot(res_fwhm_0001)\n",
    "    #plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf8e8e-599c-4c18-ac09-5da389a8077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "radii_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee8e16-8830-482e-b37a-bcd2ca02b9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
