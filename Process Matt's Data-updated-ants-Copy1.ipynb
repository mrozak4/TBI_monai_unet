{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7be0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ants\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation, binary_closing\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import tifffile as tif\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import cc3d\n",
    "from scipy.io import loadmat, savemat\n",
    "#import skan\n",
    "import sknw\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy as sp\n",
    "import vg\n",
    "from pytransform3d.rotations import matrix_from_axis_angle\n",
    "import multiprocessing\n",
    "from scipy.ndimage import convolve as conv\n",
    "from scipy.stats import multivariate_normal\n",
    "from skimage import color, data, restoration\n",
    "from RedLionfishDeconv import doRLDeconvolutionFromNpArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f724d",
   "metadata": {},
   "source": [
    "# Define connected componnet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9888d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_comps_3d(image, thresh = 500):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : binary np array with uint8 elements\n",
    "        3d numpy matrix, connected components will be removed form this image\n",
    "    thresh : int64\n",
    "        smallest connected components to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array with uint8 elements, binary\n",
    "        binary image with connected components below the threshold removed.\n",
    "\n",
    "    \"\"\"\n",
    "    img_lab, N = cc3d.connected_components(image,return_N=True)\n",
    "    unique, counts = np.unique(img_lab, return_counts=True)\n",
    "    unique_keep = unique[counts>thresh]\n",
    "    unique_keep = np.delete(unique_keep,[0])\n",
    "    img_filt = np.zeros(img_lab.shape).astype('int8')\n",
    "    img_filt[np.isin(img_lab,unique_keep)] = 1\n",
    "    return img_filt.astype('uint8')   \n",
    "\n",
    "def fill_holes(img,thresh=100):\n",
    "    #res = np.zeros(img.shape)\n",
    "    for i in np.unique(img)[::-1]:\n",
    "        _tmp = (img==i)*1.0\n",
    "        _tmp = _tmp.astype('int8')\n",
    "        _tmp = remove_small_comps_3d(_tmp,thresh=thresh)\n",
    "        img[_tmp==1] = i\n",
    "    res = img.astype('int8')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7b76",
   "metadata": {},
   "source": [
    "# Get mean predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b09644",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if 'vbm' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5c3c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8db528",
   "metadata": {},
   "source": [
    "# High bias low varience segmentation\n",
    "\n",
    "With removal of connected components under 500 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files[:]):\n",
    "    #if (time.time() - os.path.getmtime(re.sub('mean','seg',file)))/3600>48:\n",
    "    if not os.path.exists(re.sub('mean','seg',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==1)*1\n",
    "        seg = fill_holes(seg)\n",
    "        np.save(re.sub('mean','seg',file),seg)\n",
    "        #savemat(re.sub('mean.npy','seg.mat',file),{'FinalImage':fill_holes(binary_dilation(binary_dilation(seg)))})\n",
    "        #tif.imwrite(re.sub('mean.npy','seg.tif',file),seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3743f6-0c58-47e5-a874-d1960fa54645",
   "metadata": {},
   "source": [
    "# Get distance transform of neuron segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6c5ef-34e0-40fd-9513-493f5302d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "#files = [x for x in files if 'vbm' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddcafd-b682-4000-bd3d-56b82e12da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files):\n",
    "    #if (time.time() - os.path.getmtime(re.sub('mean','seg_nrn_dst',file)))/3600>48:\n",
    "    if not os.path.exists(re.sub('mean','seg_nrn_dst',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==2)*1\n",
    "        np.save(re.sub('mean','seg_nrn',file),seg)\n",
    "        np.save(re.sub('mean','seg_nrn_dst',file),distance_transform_edt(1-seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('mean','seg_nrn_dst',file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca6732",
   "metadata": {},
   "source": [
    "# ANTs registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9228eb",
   "metadata": {},
   "source": [
    "## Upsample raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b86439",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI')\n",
    "images = list(image_path.glob('*?[0-9]/*res*?[0-9].tif'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8959038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(images))[:]):\n",
    "    if not os.path.exists('matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i]))):\n",
    "        image = io.imread(images[i])\n",
    "        if image.shape[0] == 96:\n",
    "            image = np.swapaxes(image,0,1)\n",
    "            image = np.swapaxes(image,1,3)\n",
    "            image = resize(image,(2,507,507,252),preserve_range=True, order=3)\n",
    "            zeros = np.zeros((1,507,507,252)).astype('uint16')\n",
    "            image = np.append(image,zeros,axis = 0)\n",
    "            image = image.astype('float16')\n",
    "            io.imsave('matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i])),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53558e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'matt_preds/'+re.sub('/','-',re.sub('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/','',images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f08281",
   "metadata": {},
   "source": [
    "## reshape numpy seg files and resave as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "files_seg  = list(directory_seg.glob('*_seg.npy'))\n",
    "files_seg = sorted([x.as_posix() for x in files_seg])\n",
    "#files_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(files_seg))):\n",
    "    if not os.path.exists(re.sub('.npy','.tif',files_seg[i])):\n",
    "        tmp = np.load(files_seg[i])\n",
    "        tmp = np.reshape(tmp,(1,507,507,252))\n",
    "        io.imsave(re.sub('.npy','.tif',files_seg[i]),tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf7115",
   "metadata": {},
   "source": [
    "## Register images and transform masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001.tif'))\n",
    "images = sorted([x.as_posix() for x in images])#[0:2]\n",
    "#np.random.shuffle(images)\n",
    "print(len(images))\n",
    "print(images[0])\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31929326-d6a2-4573-ae0b-bc128b3300c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('_0001','',images[i]) #fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbfefa-028a-42fe-882e-73ac611d9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('.tif','_warped.tif',images[i]) #mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade09ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(images))):\n",
    "    if os.path.exists(re.sub('.tif','_seg.tif',images[i])):\n",
    "        if not os.path.exists(re.sub('.tif','_warped.tif',images[i])):\n",
    "            fix_numpy = io.imread(re.sub('_0001','',images[i]))\n",
    "            fix_numpy = np.swapaxes(fix_numpy,1,3)\n",
    "            mov_numpy = io.imread(images[i])\n",
    "            mov_numpy = np.swapaxes(mov_numpy,1,3)\n",
    "            fix = ants.from_numpy(np.float32(fix_numpy[0]))\n",
    "            mov = ants.from_numpy(np.float32(mov_numpy[0]))\n",
    "            fix_mask = ants.image_read(re.sub('.tif','_seg.tif',re.sub('_0001','',images[i])))\n",
    "            mov_mask = ants.image_read(re.sub('.tif','_seg.tif',images[i]))\n",
    "            mytx = ants.registration(fixed = fix,\n",
    "                                    moving = mov,\n",
    "                                    type_of_transform = 'Rigid'\n",
    "                                    )\n",
    "            warpedmask = ants.apply_transforms(fixed = fix_mask,\n",
    "                                               moving = mov_mask,\n",
    "                                               transformlist = mytx['fwdtransforms'],\n",
    "                                               interpolator = 'nearestNeighbor'\n",
    "                                              )\n",
    "            warpedraw_1 = ants.apply_transforms(fixed = fix,\n",
    "                                                moving = ants.from_numpy(np.float32(mov_numpy[0])),\n",
    "                                                transformlist = mytx['fwdtransforms'],\n",
    "                                                interpolator = 'linear'\n",
    "                                                )\n",
    "            warpedraw_2 = ants.apply_transforms(fixed = fix,\n",
    "                                                moving = ants.from_numpy(np.float32(mov_numpy[1])),\n",
    "                                                transformlist = mytx['fwdtransforms'],\n",
    "                                                interpolator = 'linear'\n",
    "                                                )\n",
    "            mov_numpy[0,:,:,:] = warpedraw_1[:,:,:]\n",
    "            mov_numpy[1,:,:,:] = warpedraw_2[:,:,:]\n",
    "            io.imsave(re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',images[i])),warpedmask.numpy())\n",
    "            io.imsave(re.sub('.tif','_warped.tif',images[i]),mov_numpy)\n",
    "            io.imsave(re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',re.sub('_0001','',images[i]))),fix_mask.numpy())\n",
    "            print(2 * np.sum(warpedmask.numpy()*fix_mask.numpy())/(np.sum(warpedmask.numpy())+np.sum(fix_mask.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27156607-0bd7-403e-8c2d-cb35f37597a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mov_numpy.shape\n",
    "re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400211d-1c9b-4b1d-a0eb-428a6c0f0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('.tif','_warped.tif',images[i])\n",
    "re.sub('seg','seg_warped',re.sub('.tif','_seg.tif',re.sub('_0001','',images[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af4374-bf21-4f39-8628-ffd253a5d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mov_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58cb04-3be4-43a8-b4bf-6e7ebac54cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fix_mask.numpy()[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a8329",
   "metadata": {},
   "source": [
    "## Save Matlab .mat file of registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af813286",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001_seg_warped.tif'))\n",
    "images = sorted([x.as_posix() for x in images])[::-1]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d576f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images):\n",
    "    #if not os.path.exists(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image))):\n",
    "        img_0001 = io.imread(image)\n",
    "        img = io.imread(re.sub('_0001','',image))\n",
    "        seg = img*img_0001\n",
    "        seg = (seg==1)*1\n",
    "        seg = seg.astype('int8')\n",
    "        seg = fill_holes(seg)\n",
    "        savemat(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image)),{'FinalImage':fill_holes(binary_dilation(seg))})\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce09b0-d23d-4b99-abb1-c18431ad1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5818c18",
   "metadata": {},
   "source": [
    "# Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd876acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files_seg_0001 = directory.glob('*_0001_seg_warped.tif')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "len(files_seg_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_0001 in tqdm(files_seg_0001):\n",
    "    #if not os.path.exists(re.sub('_0001_seg_warped.tif','_warped.pickle',file_0001)):\n",
    "    if (time.time() - os.path.getmtime(re.sub('_0001_seg_warped.tif','_warped.pickle',file_0001)))/3600>48:\n",
    "        file = file_0001\n",
    "        skel_file = re.sub('_0001_seg_warped.tif','_skel_warped_single.mat',file)\n",
    "        #seg = io.imread(file)\n",
    "        skel = loadmat(skel_file)['FilteredImage']\n",
    "        if np.sum(skel) != 0:\n",
    "        #skel = skeletonize_3d(skel)\n",
    "            io.imsave(re.sub('_seg_warped.tif','_single_skel.tif',file),skel)\n",
    "            #dst_tsfm = distance_transform_edt(seg)\n",
    "            #dst_tsfm[dst_tsfm==0]=0.00001\n",
    "            #skel_dst = skel*dst_tsfm\n",
    "            #\n",
    "            #\n",
    "            #np.save(re.sub('seg','dst_skel',file),skel_dst)\n",
    "            #io.imsave(re.sub('_seg_warped.tif','_dst_skel_warped.tif',file),skel_dst)\n",
    "            graph = sknw.build_sknw(skel, multi=False)\n",
    "            print(len(graph.edges))\n",
    "            #graph, c0  = skan.csr.skeleton_to_csgraph(skel)\n",
    "            #print(len(graph.edges))\n",
    "            \n",
    "            #print(len(graph_0001.edges))\n",
    "            #pickle.dump(graph, open(str(re.sub('_seg.npy','.pickle',file)), 'w'))\n",
    "            #nx.write_pajek(graph,re.sub('_seg.npy','.pajek',file))\n",
    "            \n",
    "            nx.write_gpickle(graph,re.sub('_0001_seg_warped.tif','_warped.pickle',file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba7bff",
   "metadata": {},
   "source": [
    "# write vessel measurments to graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1118fd-ef33-4b59-ad35-52edb6610051",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f52c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    }
   ],
   "source": [
    "directory = Path('matt_preds')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if '-' in x]\n",
    "#files = [x for x in files if not os.path.exists(re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',x)))]\n",
    "print(len(files))\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9d4364-488f-407b-a9ae-e3878dad3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rotmat(vector, points):\n",
    "    \"\"\"\n",
    "    Rotates a 3xn array of 3D coordinates from the +z normal to an\n",
    "    arbitrary new normal vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    vector = vg.normalize(vector)\n",
    "    axis = vg.perpendicular(vg.basis.z, vector)\n",
    "    angle = vg.angle(vg.basis.z, vector, units='rad')\n",
    "    \n",
    "    a = np.hstack((axis, (angle,)))\n",
    "    R = matrix_from_axis_angle(a)\n",
    "    \n",
    "    r = sp.spatial.transform.Rotation.from_matrix(R)\n",
    "    rotmat = r.apply(points)\n",
    "    \n",
    "    return rotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e13ca7-1348-43fa-b7dc-cff0cbfe1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoD_Gaussian(xy, amplitude, sigma, x0, y0, offset):\n",
    "    theta=0\n",
    "    x, y = xy   \n",
    "    a = (np.cos(theta)**2)/(2*sigma**2) + (np.sin(theta)**2)/(2*sigma**2)\n",
    "    b = -(np.sin(2*theta))/(4*sigma**2) + (np.sin(2*theta))/(4*sigma**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma**2) + (np.cos(theta)**2)/(2*sigma**2)\n",
    "    g = offset + amplitude*np.exp( - (a*((x-x0)**2) + 2*b*(x-x0)*(y-y0) + c*((y-y0)**2)))\n",
    "    return g.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24e097-8a92-4408-84e4-00cd00a36c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75bf94-6290-45b0-b713-055580848466",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d716ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]\n",
      "  0%|          | 0/349 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/349 [00:01<10:43,  1.85s/it]\u001b[A\n",
      "  1%|          | 2/349 [00:03<10:00,  1.73s/it]\u001b[A\n",
      "  1%|          | 3/349 [00:05<10:30,  1.82s/it]\u001b[A\n",
      "  1%|          | 4/349 [00:07<11:52,  2.07s/it]\u001b[A\n",
      "  1%|▏         | 5/349 [00:08<08:26,  1.47s/it]\u001b[A\n",
      "  2%|▏         | 6/349 [00:11<11:26,  2.00s/it]\u001b[A\n",
      "  2%|▏         | 7/349 [00:13<12:22,  2.17s/it]\u001b[A\n",
      "  2%|▏         | 8/349 [00:15<11:40,  2.05s/it]\u001b[A\n",
      "  3%|▎         | 9/349 [00:17<12:02,  2.13s/it]\u001b[A\n",
      "  3%|▎         | 10/349 [00:21<13:55,  2.46s/it]\u001b[A\n",
      "  3%|▎         | 11/349 [00:24<15:48,  2.81s/it]\u001b[A\n",
      "  3%|▎         | 12/349 [00:27<15:59,  2.85s/it]\u001b[A\n",
      "  4%|▎         | 13/349 [00:28<11:53,  2.12s/it]\u001b[A\n",
      "  4%|▍         | 14/349 [00:30<12:32,  2.25s/it]\u001b[A\n",
      "  4%|▍         | 15/349 [00:31<09:30,  1.71s/it]\u001b[A\n",
      "  5%|▍         | 16/349 [00:33<10:39,  1.92s/it]\u001b[A\n",
      "  5%|▍         | 17/349 [00:35<10:11,  1.84s/it]\u001b[A\n",
      "  5%|▌         | 18/349 [00:37<10:22,  1.88s/it]\u001b[A\n",
      "  5%|▌         | 19/349 [00:39<10:59,  2.00s/it]\u001b[A/tmp/ipykernel_2988487/4208746146.py:174: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "\n",
      "  6%|▌         | 20/349 [00:44<15:11,  2.77s/it]\u001b[A\n",
      "  6%|▌         | 21/349 [00:44<11:21,  2.08s/it]\u001b[A\n",
      "  6%|▋         | 22/349 [00:46<10:28,  1.92s/it]\u001b[A\n",
      "  7%|▋         | 23/349 [00:47<09:40,  1.78s/it]\u001b[A\n",
      "  7%|▋         | 24/349 [00:50<11:36,  2.14s/it]\u001b[A\n",
      "  7%|▋         | 25/349 [00:53<12:20,  2.28s/it]\u001b[A\n",
      "  7%|▋         | 26/349 [00:55<12:40,  2.36s/it]\u001b[A\n",
      "  8%|▊         | 27/349 [00:57<11:50,  2.21s/it]\u001b[A\n",
      "  8%|▊         | 28/349 [00:59<11:58,  2.24s/it]\u001b[A\n",
      "  8%|▊         | 29/349 [01:02<12:25,  2.33s/it]\u001b[A\n",
      "  9%|▊         | 30/349 [01:03<09:49,  1.85s/it]\u001b[A\n",
      "  9%|▉         | 31/349 [01:04<09:22,  1.77s/it]\u001b[A\n",
      "  9%|▉         | 32/349 [01:05<07:14,  1.37s/it]\u001b[A\n",
      "  9%|▉         | 33/349 [01:05<06:12,  1.18s/it]\u001b[A\n",
      " 10%|▉         | 34/349 [01:06<05:09,  1.02it/s]\u001b[A\n",
      " 10%|█         | 35/349 [01:11<11:09,  2.13s/it]\u001b[A\n",
      " 10%|█         | 36/349 [01:12<09:13,  1.77s/it]\u001b[A\n",
      " 11%|█         | 37/349 [01:12<07:53,  1.52s/it]\u001b[A\n",
      " 11%|█         | 38/349 [01:14<07:53,  1.52s/it]\u001b[A\n",
      " 11%|█         | 39/349 [01:17<10:08,  1.96s/it]\u001b[A\n",
      " 11%|█▏        | 40/349 [01:19<09:22,  1.82s/it]\u001b[A\n",
      " 12%|█▏        | 41/349 [01:21<09:54,  1.93s/it]\u001b[A\n",
      " 12%|█▏        | 42/349 [01:22<09:38,  1.88s/it]\u001b[A\n",
      " 12%|█▏        | 43/349 [01:23<07:25,  1.45s/it]\u001b[A\n",
      " 13%|█▎        | 44/349 [01:24<06:08,  1.21s/it]\u001b[A\n",
      " 13%|█▎        | 45/349 [01:26<07:49,  1.54s/it]\u001b[A\n",
      " 13%|█▎        | 46/349 [01:29<10:41,  2.12s/it]\u001b[A\n",
      " 13%|█▎        | 47/349 [01:33<12:28,  2.48s/it]\u001b[A\n",
      " 14%|█▍        | 48/349 [01:33<09:31,  1.90s/it]\u001b[A\n",
      " 14%|█▍        | 49/349 [01:37<12:53,  2.58s/it]\u001b[A\n",
      " 14%|█▍        | 50/349 [01:38<10:07,  2.03s/it]\u001b[A\n",
      " 15%|█▍        | 51/349 [01:39<07:53,  1.59s/it]\u001b[A\n",
      " 15%|█▍        | 52/349 [01:39<06:18,  1.27s/it]\u001b[A\n",
      " 15%|█▌        | 53/349 [01:40<05:56,  1.20s/it]\u001b[A\n",
      " 15%|█▌        | 54/349 [01:41<05:30,  1.12s/it]\u001b[A\n",
      " 16%|█▌        | 55/349 [01:42<04:54,  1.00s/it]\u001b[A\n",
      " 16%|█▌        | 56/349 [01:42<04:12,  1.16it/s]\u001b[A\n",
      " 16%|█▋        | 57/349 [01:43<04:26,  1.10it/s]\u001b[A\n",
      " 17%|█▋        | 58/349 [01:45<05:09,  1.06s/it]\u001b[A\n",
      " 17%|█▋        | 59/349 [01:46<05:07,  1.06s/it]\u001b[A\n",
      " 17%|█▋        | 60/349 [01:48<06:17,  1.31s/it]\u001b[A\n",
      " 17%|█▋        | 61/349 [01:48<05:19,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 62/349 [01:50<05:38,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 63/349 [01:50<04:51,  1.02s/it]\u001b[A\n",
      " 18%|█▊        | 64/349 [01:53<06:48,  1.43s/it]\u001b[A\n",
      " 19%|█▊        | 65/349 [01:53<05:21,  1.13s/it]\u001b[A\n",
      " 19%|█▉        | 66/349 [01:57<08:44,  1.85s/it]\u001b[A\n",
      " 19%|█▉        | 67/349 [01:57<06:44,  1.44s/it]\u001b[A\n",
      " 19%|█▉        | 68/349 [01:58<05:41,  1.22s/it]\u001b[A\n",
      " 20%|█▉        | 69/349 [01:59<04:44,  1.01s/it]\u001b[A\n",
      " 20%|██        | 70/349 [02:00<05:26,  1.17s/it]\u001b[A\n",
      " 20%|██        | 71/349 [02:01<05:40,  1.22s/it]\u001b[A\n",
      " 21%|██        | 72/349 [02:02<04:31,  1.02it/s]\u001b[A\n",
      " 21%|██        | 73/349 [02:03<04:05,  1.13it/s]\u001b[A\n",
      " 21%|██        | 74/349 [02:04<05:29,  1.20s/it]\u001b[A\n",
      " 21%|██▏       | 75/349 [02:06<05:56,  1.30s/it]\u001b[A\n",
      " 22%|██▏       | 76/349 [02:06<04:52,  1.07s/it]\u001b[A\n",
      " 22%|██▏       | 77/349 [02:07<04:11,  1.08it/s]\u001b[A\n",
      " 22%|██▏       | 78/349 [02:10<06:42,  1.49s/it]\u001b[A\n",
      " 23%|██▎       | 79/349 [02:10<05:15,  1.17s/it]\u001b[A\n",
      " 23%|██▎       | 80/349 [02:13<06:53,  1.54s/it]\u001b[A\n",
      " 23%|██▎       | 81/349 [02:15<07:14,  1.62s/it]\u001b[A\n",
      " 23%|██▎       | 82/349 [02:15<05:36,  1.26s/it]\u001b[A\n",
      " 24%|██▍       | 83/349 [02:16<04:44,  1.07s/it]\u001b[A\n",
      " 24%|██▍       | 84/349 [02:16<04:00,  1.10it/s]\u001b[A\n",
      " 24%|██▍       | 85/349 [02:17<04:05,  1.08it/s]\u001b[A\n",
      " 25%|██▍       | 86/349 [02:19<04:54,  1.12s/it]\u001b[A\n",
      " 25%|██▍       | 87/349 [02:21<06:26,  1.47s/it]\u001b[A\n",
      " 25%|██▌       | 88/349 [02:23<06:36,  1.52s/it]\u001b[A\n",
      " 26%|██▌       | 89/349 [02:23<05:10,  1.19s/it]\u001b[A\n",
      " 26%|██▌       | 90/349 [02:25<05:42,  1.32s/it]\u001b[A\n",
      " 26%|██▌       | 91/349 [02:27<06:27,  1.50s/it]\u001b[A\n",
      " 26%|██▋       | 92/349 [02:27<05:22,  1.25s/it]\u001b[A\n",
      " 27%|██▋       | 93/349 [02:28<04:37,  1.08s/it]\u001b[A\n",
      " 27%|██▋       | 94/349 [02:32<08:17,  1.95s/it]\u001b[A\n",
      " 27%|██▋       | 95/349 [02:32<06:18,  1.49s/it]\u001b[A\n",
      " 28%|██▊       | 96/349 [02:35<07:43,  1.83s/it]\u001b[A\n",
      " 28%|██▊       | 97/349 [02:38<09:40,  2.30s/it]\u001b[A\n",
      " 28%|██▊       | 98/349 [02:39<07:16,  1.74s/it]\u001b[A\n",
      " 28%|██▊       | 99/349 [02:40<06:57,  1.67s/it]\u001b[A\n",
      " 29%|██▊       | 100/349 [02:41<05:27,  1.31s/it]\u001b[A\n",
      " 29%|██▉       | 101/349 [02:42<04:47,  1.16s/it]\u001b[A\n",
      " 29%|██▉       | 102/349 [02:43<05:02,  1.22s/it]\u001b[A\n",
      " 30%|██▉       | 103/349 [02:43<04:03,  1.01it/s]\u001b[A\n",
      " 30%|██▉       | 104/349 [02:47<07:39,  1.88s/it]\u001b[A\n",
      " 30%|███       | 105/349 [02:48<06:23,  1.57s/it]\u001b[A\n",
      " 30%|███       | 106/349 [02:51<07:32,  1.86s/it]\u001b[A\n",
      " 31%|███       | 107/349 [02:51<05:51,  1.45s/it]\u001b[A\n",
      " 31%|███       | 108/349 [02:53<06:03,  1.51s/it]\u001b[A\n",
      " 31%|███       | 109/349 [02:53<04:43,  1.18s/it]\u001b[A\n",
      " 32%|███▏      | 110/349 [02:54<04:35,  1.15s/it]\u001b[A\n",
      " 32%|███▏      | 111/349 [02:55<03:43,  1.07it/s]\u001b[A\n",
      " 32%|███▏      | 112/349 [02:55<03:17,  1.20it/s]\u001b[A\n",
      " 32%|███▏      | 113/349 [02:56<02:55,  1.34it/s]\u001b[A\n",
      " 33%|███▎      | 114/349 [02:59<05:18,  1.36s/it]\u001b[A\n",
      " 33%|███▎      | 115/349 [03:00<05:17,  1.36s/it]\u001b[A\n",
      " 33%|███▎      | 116/349 [03:01<04:39,  1.20s/it]\u001b[A\n",
      " 34%|███▎      | 117/349 [03:03<05:41,  1.47s/it]\u001b[A\n",
      " 34%|███▍      | 118/349 [03:04<04:39,  1.21s/it]\u001b[A\n",
      " 34%|███▍      | 119/349 [03:04<03:53,  1.02s/it]\u001b[A\n",
      " 34%|███▍      | 120/349 [03:05<04:11,  1.10s/it]\u001b[A\n",
      " 35%|███▍      | 121/349 [03:07<04:35,  1.21s/it]\u001b[A\n",
      " 35%|███▍      | 122/349 [03:07<03:41,  1.02it/s]\u001b[A\n",
      " 35%|███▌      | 123/349 [03:09<04:22,  1.16s/it]\u001b[A\n",
      " 36%|███▌      | 124/349 [03:11<05:09,  1.38s/it]\u001b[A\n",
      " 36%|███▌      | 125/349 [03:12<04:27,  1.20s/it]\u001b[A\n",
      " 36%|███▌      | 126/349 [03:13<04:54,  1.32s/it]\u001b[A\n",
      " 36%|███▋      | 127/349 [03:15<05:14,  1.42s/it]\u001b[A\n",
      " 37%|███▋      | 128/349 [03:16<04:53,  1.33s/it]\u001b[A\n",
      " 37%|███▋      | 129/349 [03:17<04:03,  1.10s/it]\u001b[A\n",
      " 37%|███▋      | 130/349 [03:17<03:34,  1.02it/s]\u001b[A\n",
      " 38%|███▊      | 131/349 [03:18<03:06,  1.17it/s]\u001b[A\n",
      " 38%|███▊      | 132/349 [03:19<03:40,  1.02s/it]\u001b[A\n",
      " 38%|███▊      | 133/349 [03:20<03:00,  1.20it/s]\u001b[A\n",
      " 38%|███▊      | 134/349 [03:20<02:42,  1.32it/s]\u001b[A\n",
      " 39%|███▊      | 135/349 [03:21<02:29,  1.43it/s]\u001b[A\n",
      " 39%|███▉      | 136/349 [03:24<05:23,  1.52s/it]\u001b[A\n",
      " 39%|███▉      | 137/349 [03:26<05:23,  1.53s/it]\u001b[A\n",
      " 40%|███▉      | 138/349 [03:27<05:21,  1.52s/it]\u001b[A\n",
      " 40%|███▉      | 139/349 [03:29<05:11,  1.48s/it]\u001b[A\n",
      " 40%|████      | 140/349 [03:32<06:41,  1.92s/it]\u001b[A\n",
      " 40%|████      | 141/349 [03:32<05:07,  1.48s/it]\u001b[A\n",
      " 41%|████      | 142/349 [03:34<05:26,  1.58s/it]\u001b[A\n",
      " 41%|████      | 143/349 [03:34<04:17,  1.25s/it]\u001b[A\n",
      " 41%|████▏     | 144/349 [03:37<05:19,  1.56s/it]\u001b[A\n",
      " 42%|████▏     | 145/349 [03:38<05:25,  1.59s/it]\u001b[A\n",
      " 42%|████▏     | 146/349 [03:39<04:22,  1.29s/it]\u001b[A\n",
      " 42%|████▏     | 147/349 [03:40<04:40,  1.39s/it]\u001b[A\n",
      " 42%|████▏     | 148/349 [03:41<04:05,  1.22s/it]\u001b[A\n",
      " 43%|████▎     | 149/349 [03:42<03:16,  1.02it/s]\u001b[A\n",
      " 43%|████▎     | 150/349 [03:44<04:34,  1.38s/it]\u001b[A\n",
      " 43%|████▎     | 151/349 [03:45<03:48,  1.15s/it]\u001b[A\n",
      " 44%|████▎     | 152/349 [03:46<03:40,  1.12s/it]\u001b[A\n",
      " 44%|████▍     | 153/349 [03:46<02:58,  1.10it/s]\u001b[A\n",
      " 44%|████▍     | 154/349 [03:48<03:27,  1.06s/it]\u001b[A\n",
      " 44%|████▍     | 155/349 [03:49<03:54,  1.21s/it]\u001b[A\n",
      " 45%|████▍     | 156/349 [03:50<03:09,  1.02it/s]\u001b[A\n",
      " 45%|████▍     | 157/349 [03:51<03:22,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 158/349 [03:52<03:51,  1.21s/it]\u001b[A\n",
      " 46%|████▌     | 159/349 [03:53<03:23,  1.07s/it]\u001b[A\n",
      " 46%|████▌     | 160/349 [03:54<03:03,  1.03it/s]\u001b[A\n",
      " 46%|████▌     | 161/349 [03:55<03:40,  1.17s/it]\u001b[A\n",
      " 46%|████▋     | 162/349 [03:56<03:08,  1.01s/it]\u001b[A\n",
      " 47%|████▋     | 163/349 [04:00<05:41,  1.84s/it]\u001b[A\n",
      " 47%|████▋     | 164/349 [04:01<04:34,  1.48s/it]\u001b[A\n",
      " 47%|████▋     | 165/349 [04:01<03:53,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 166/349 [04:03<03:57,  1.30s/it]\u001b[A\n",
      " 48%|████▊     | 167/349 [04:04<03:48,  1.25s/it]\u001b[A\n",
      " 48%|████▊     | 168/349 [04:06<04:58,  1.65s/it]\u001b[A\n",
      " 48%|████▊     | 169/349 [04:07<03:54,  1.31s/it]\u001b[A\n",
      " 49%|████▊     | 170/349 [04:08<03:41,  1.24s/it]\u001b[A\n",
      " 49%|████▉     | 171/349 [04:10<04:31,  1.52s/it]\u001b[A\n",
      " 49%|████▉     | 172/349 [04:12<05:08,  1.74s/it]\u001b[A\n",
      " 50%|████▉     | 173/349 [04:13<04:01,  1.37s/it]\u001b[A\n",
      " 50%|████▉     | 174/349 [04:14<03:18,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 175/349 [04:14<02:52,  1.01it/s]\u001b[A\n",
      " 50%|█████     | 176/349 [04:15<02:40,  1.08it/s]\u001b[A\n",
      " 51%|█████     | 177/349 [04:16<02:29,  1.15it/s]\u001b[A\n",
      " 51%|█████     | 178/349 [04:17<03:08,  1.10s/it]\u001b[A\n",
      " 51%|█████▏    | 179/349 [04:18<02:34,  1.10it/s]\u001b[A\n",
      " 52%|█████▏    | 180/349 [04:18<02:18,  1.22it/s]\u001b[A\n",
      " 52%|█████▏    | 181/349 [04:19<02:15,  1.24it/s]\u001b[A\n",
      " 52%|█████▏    | 182/349 [04:21<02:48,  1.01s/it]\u001b[A\n",
      " 52%|█████▏    | 183/349 [04:23<03:41,  1.33s/it]\u001b[A\n",
      " 53%|█████▎    | 184/349 [04:23<03:06,  1.13s/it]\u001b[A\n",
      " 53%|█████▎    | 185/349 [04:24<02:36,  1.05it/s]\u001b[A\n",
      " 53%|█████▎    | 186/349 [04:27<04:18,  1.59s/it]\u001b[A\n",
      " 54%|█████▎    | 187/349 [04:27<03:21,  1.25s/it]\u001b[A\n",
      " 54%|█████▍    | 188/349 [04:29<03:57,  1.47s/it]\u001b[A\n",
      " 54%|█████▍    | 189/349 [04:30<03:33,  1.33s/it]\u001b[A\n",
      " 54%|█████▍    | 190/349 [04:32<03:42,  1.40s/it]\u001b[A\n",
      " 55%|█████▍    | 191/349 [04:32<02:55,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 192/349 [04:35<04:02,  1.55s/it]\u001b[A\n",
      " 55%|█████▌    | 193/349 [04:37<04:45,  1.83s/it]\u001b[A\n",
      " 56%|█████▌    | 194/349 [04:39<04:47,  1.86s/it]\u001b[A\n",
      " 56%|█████▌    | 195/349 [04:40<03:40,  1.43s/it]\u001b[A\n",
      " 56%|█████▌    | 196/349 [04:42<03:56,  1.55s/it]\u001b[A\n",
      " 56%|█████▋    | 197/349 [04:46<05:45,  2.28s/it]\u001b[A\n",
      " 57%|█████▋    | 198/349 [04:46<04:22,  1.74s/it]\u001b[A\n",
      " 57%|█████▋    | 199/349 [04:51<06:19,  2.53s/it]\u001b[A\n",
      " 57%|█████▋    | 200/349 [04:51<04:43,  1.90s/it]\u001b[A\n",
      " 58%|█████▊    | 201/349 [04:52<03:43,  1.51s/it]\u001b[A\n",
      " 58%|█████▊    | 202/349 [04:52<03:10,  1.30s/it]\u001b[A\n",
      " 58%|█████▊    | 203/349 [04:53<02:39,  1.10s/it]\u001b[A\n",
      " 58%|█████▊    | 204/349 [04:54<02:36,  1.08s/it]\u001b[A\n",
      " 59%|█████▊    | 205/349 [04:54<02:06,  1.13it/s]\u001b[A\n",
      " 59%|█████▉    | 206/349 [04:55<02:07,  1.13it/s]\u001b[A\n",
      " 59%|█████▉    | 207/349 [04:59<03:58,  1.68s/it]\u001b[A\n",
      " 60%|█████▉    | 208/349 [05:00<03:30,  1.50s/it]\u001b[A\n",
      " 60%|█████▉    | 209/349 [05:02<03:36,  1.54s/it]\u001b[A\n",
      " 60%|██████    | 210/349 [05:03<03:43,  1.61s/it]\u001b[A\n",
      " 60%|██████    | 211/349 [05:06<04:32,  1.98s/it]\u001b[A\n",
      " 61%|██████    | 212/349 [05:07<03:27,  1.51s/it]\u001b[A\n",
      " 61%|██████    | 213/349 [05:10<04:53,  2.16s/it]\u001b[A\n",
      " 61%|██████▏   | 214/349 [05:11<03:41,  1.64s/it]\u001b[A\n",
      " 62%|██████▏   | 215/349 [05:11<02:58,  1.33s/it]\u001b[A\n",
      " 62%|██████▏   | 216/349 [05:13<03:18,  1.49s/it]\u001b[A\n",
      " 62%|██████▏   | 217/349 [05:15<03:15,  1.48s/it]\u001b[A\n",
      " 62%|██████▏   | 218/349 [05:17<03:39,  1.68s/it]\u001b[A\n",
      " 63%|██████▎   | 219/349 [05:17<02:49,  1.30s/it]\u001b[A\n",
      " 63%|██████▎   | 220/349 [05:20<03:28,  1.61s/it]\u001b[A\n",
      " 63%|██████▎   | 221/349 [05:21<03:38,  1.71s/it]\u001b[A\n",
      " 64%|██████▎   | 222/349 [05:23<03:40,  1.74s/it]\u001b[A\n",
      " 64%|██████▍   | 223/349 [05:24<02:52,  1.37s/it]\u001b[A\n",
      " 64%|██████▍   | 224/349 [05:25<02:40,  1.29s/it]\u001b[A\n",
      " 64%|██████▍   | 225/349 [05:27<02:55,  1.41s/it]\u001b[A\n",
      " 65%|██████▍   | 226/349 [05:28<02:58,  1.45s/it]\u001b[A\n",
      " 65%|██████▌   | 227/349 [05:31<03:39,  1.80s/it]\u001b[A\n",
      " 65%|██████▌   | 228/349 [05:31<02:48,  1.39s/it]\u001b[A\n",
      " 66%|██████▌   | 229/349 [05:33<02:46,  1.39s/it]\u001b[A\n",
      " 66%|██████▌   | 230/349 [05:33<02:18,  1.16s/it]\u001b[A\n",
      " 66%|██████▌   | 231/349 [05:34<01:56,  1.01it/s]\u001b[A\n",
      " 66%|██████▋   | 232/349 [05:35<02:04,  1.06s/it]\u001b[A\n",
      " 67%|██████▋   | 233/349 [05:35<01:42,  1.13it/s]\u001b[A\n",
      " 67%|██████▋   | 234/349 [05:37<02:11,  1.14s/it]\u001b[A\n",
      " 67%|██████▋   | 235/349 [05:38<02:05,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 236/349 [05:40<02:11,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 237/349 [05:40<01:58,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 238/349 [05:41<01:59,  1.08s/it]\u001b[A\n",
      " 68%|██████▊   | 239/349 [05:43<02:23,  1.30s/it]\u001b[A\n",
      " 69%|██████▉   | 240/349 [05:45<02:32,  1.39s/it]\u001b[A\n",
      " 69%|██████▉   | 241/349 [05:46<02:34,  1.43s/it]\u001b[A\n",
      " 69%|██████▉   | 242/349 [05:47<02:18,  1.29s/it]\u001b[A\n",
      " 70%|██████▉   | 243/349 [05:51<03:19,  1.89s/it]\u001b[A\n",
      " 70%|██████▉   | 244/349 [05:52<03:04,  1.76s/it]\u001b[A\n",
      " 70%|███████   | 245/349 [05:54<03:21,  1.94s/it]\u001b[A\n",
      " 70%|███████   | 246/349 [05:58<04:23,  2.55s/it]\u001b[A\n",
      " 71%|███████   | 247/349 [05:59<03:15,  1.92s/it]\u001b[A\n",
      " 71%|███████   | 248/349 [05:59<02:32,  1.51s/it]\u001b[A\n",
      " 71%|███████▏  | 249/349 [06:01<02:25,  1.45s/it]\u001b[A\n",
      " 72%|███████▏  | 250/349 [06:03<02:42,  1.64s/it]\u001b[A\n",
      " 72%|███████▏  | 251/349 [06:03<02:09,  1.32s/it]\u001b[A\n",
      " 72%|███████▏  | 252/349 [06:05<02:20,  1.44s/it]\u001b[A\n",
      " 72%|███████▏  | 253/349 [06:06<02:03,  1.28s/it]\u001b[A\n",
      " 73%|███████▎  | 254/349 [06:07<01:37,  1.03s/it]\u001b[A\n",
      " 73%|███████▎  | 255/349 [06:09<02:10,  1.39s/it]\u001b[A\n",
      " 73%|███████▎  | 256/349 [06:10<02:12,  1.42s/it]\u001b[A\n",
      " 74%|███████▎  | 257/349 [06:11<01:52,  1.23s/it]\u001b[A\n",
      " 74%|███████▍  | 258/349 [06:13<02:02,  1.35s/it]\u001b[A\n",
      " 74%|███████▍  | 259/349 [06:14<02:10,  1.44s/it]\u001b[A\n",
      " 74%|███████▍  | 260/349 [06:16<02:04,  1.40s/it]\u001b[A\n",
      " 75%|███████▍  | 261/349 [06:16<01:37,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 262/349 [06:18<02:02,  1.40s/it]\u001b[A\n",
      " 75%|███████▌  | 263/349 [06:20<02:18,  1.61s/it]\u001b[A\n",
      " 76%|███████▌  | 264/349 [06:25<03:30,  2.47s/it]\u001b[A\n",
      " 76%|███████▌  | 265/349 [06:26<02:59,  2.14s/it]\u001b[A\n",
      " 76%|███████▌  | 266/349 [06:28<02:41,  1.95s/it]\u001b[A\n",
      " 77%|███████▋  | 267/349 [06:29<02:33,  1.87s/it]\u001b[A\n",
      " 77%|███████▋  | 268/349 [06:30<01:59,  1.48s/it]\u001b[A\n",
      " 77%|███████▋  | 269/349 [06:31<01:44,  1.30s/it]\u001b[A\n",
      " 77%|███████▋  | 270/349 [06:31<01:21,  1.03s/it]\u001b[A\n",
      " 78%|███████▊  | 271/349 [06:32<01:10,  1.11it/s]\u001b[A\n",
      " 78%|███████▊  | 272/349 [06:32<01:01,  1.26it/s]\u001b[A\n",
      " 78%|███████▊  | 273/349 [06:34<01:21,  1.07s/it]\u001b[A\n",
      " 79%|███████▊  | 274/349 [06:36<01:33,  1.25s/it]\u001b[A\n",
      " 79%|███████▉  | 275/349 [06:37<01:24,  1.15s/it]\u001b[A\n",
      " 79%|███████▉  | 276/349 [06:37<01:08,  1.07it/s]\u001b[A\n",
      " 79%|███████▉  | 277/349 [06:38<01:01,  1.18it/s]\u001b[A\n",
      " 80%|███████▉  | 278/349 [06:39<01:08,  1.04it/s]\u001b[A\n",
      " 80%|███████▉  | 279/349 [06:41<01:25,  1.22s/it]\u001b[A\n",
      " 80%|████████  | 280/349 [06:42<01:31,  1.32s/it]\u001b[A\n",
      " 81%|████████  | 281/349 [06:46<02:28,  2.18s/it]\u001b[A\n",
      " 81%|████████  | 282/349 [06:48<02:09,  1.93s/it]\u001b[A\n",
      " 81%|████████  | 283/349 [06:49<01:53,  1.72s/it]\u001b[A\n",
      " 81%|████████▏ | 284/349 [06:51<01:56,  1.79s/it]\u001b[A\n",
      " 82%|████████▏ | 285/349 [06:51<01:28,  1.39s/it]\u001b[A\n",
      " 82%|████████▏ | 286/349 [06:52<01:12,  1.15s/it]\u001b[A\n",
      " 82%|████████▏ | 287/349 [06:53<01:00,  1.03it/s]\u001b[A\n",
      " 83%|████████▎ | 288/349 [06:53<00:57,  1.05it/s]\u001b[A\n",
      " 83%|████████▎ | 289/349 [06:55<01:00,  1.00s/it]\u001b[A\n",
      " 83%|████████▎ | 290/349 [06:56<01:06,  1.13s/it]\u001b[A\n",
      " 83%|████████▎ | 291/349 [06:56<00:53,  1.08it/s]\u001b[A\n",
      " 84%|████████▎ | 292/349 [06:58<00:57,  1.00s/it]\u001b[A\n",
      " 84%|████████▍ | 293/349 [06:58<00:47,  1.18it/s]\u001b[A\n",
      " 84%|████████▍ | 294/349 [06:59<00:41,  1.33it/s]\u001b[A\n",
      " 85%|████████▍ | 295/349 [07:00<00:48,  1.12it/s]\u001b[A\n",
      " 85%|████████▍ | 296/349 [07:00<00:39,  1.35it/s]\u001b[A\n",
      " 85%|████████▌ | 297/349 [07:01<00:46,  1.12it/s]\u001b[A\n",
      " 85%|████████▌ | 298/349 [07:02<00:38,  1.32it/s]\u001b[A\n",
      " 86%|████████▌ | 299/349 [07:04<01:02,  1.24s/it]\u001b[A\n",
      " 86%|████████▌ | 300/349 [07:07<01:17,  1.57s/it]\u001b[A\n",
      " 86%|████████▌ | 301/349 [07:10<01:46,  2.23s/it]\u001b[A\n",
      " 87%|████████▋ | 302/349 [07:11<01:21,  1.74s/it]\u001b[A\n",
      " 87%|████████▋ | 303/349 [07:12<01:03,  1.38s/it]\u001b[A\n",
      " 87%|████████▋ | 304/349 [07:13<01:04,  1.43s/it]\u001b[A\n",
      " 87%|████████▋ | 305/349 [07:15<01:02,  1.43s/it]\u001b[A\n",
      " 88%|████████▊ | 306/349 [07:16<01:05,  1.52s/it]\u001b[A\n",
      " 88%|████████▊ | 307/349 [07:18<01:02,  1.48s/it]\u001b[A\n",
      " 88%|████████▊ | 308/349 [07:20<01:17,  1.88s/it]\u001b[A\n",
      " 89%|████████▊ | 309/349 [07:21<01:03,  1.58s/it]\u001b[A\n",
      " 89%|████████▉ | 310/349 [07:22<00:48,  1.25s/it]\u001b[A\n",
      " 89%|████████▉ | 311/349 [07:23<00:45,  1.20s/it]\u001b[A\n",
      " 89%|████████▉ | 312/349 [07:23<00:36,  1.01it/s]\u001b[A\n",
      " 90%|████████▉ | 313/349 [07:24<00:33,  1.07it/s]\u001b[A\n",
      " 90%|████████▉ | 314/349 [07:25<00:29,  1.18it/s]\u001b[A\n",
      " 90%|█████████ | 315/349 [07:26<00:28,  1.20it/s]\u001b[A\n",
      " 91%|█████████ | 316/349 [07:27<00:29,  1.14it/s]\u001b[A\n",
      " 91%|█████████ | 317/349 [07:30<00:54,  1.69s/it]\u001b[A\n",
      " 91%|█████████ | 318/349 [07:32<00:56,  1.81s/it]\u001b[A\n",
      " 91%|█████████▏| 319/349 [07:33<00:44,  1.49s/it]\u001b[A\n",
      " 92%|█████████▏| 320/349 [07:34<00:38,  1.33s/it]\u001b[A\n",
      " 92%|█████████▏| 321/349 [07:35<00:30,  1.09s/it]\u001b[A\n",
      " 92%|█████████▏| 322/349 [07:35<00:25,  1.07it/s]\u001b[A\n",
      " 93%|█████████▎| 323/349 [07:37<00:28,  1.08s/it]\u001b[A\n",
      " 93%|█████████▎| 324/349 [07:37<00:25,  1.03s/it]\u001b[A\n",
      " 93%|█████████▎| 325/349 [07:38<00:20,  1.19it/s]\u001b[A\n",
      " 93%|█████████▎| 326/349 [07:39<00:18,  1.22it/s]\u001b[A\n",
      " 94%|█████████▎| 327/349 [07:40<00:19,  1.12it/s]\u001b[A\n",
      " 94%|█████████▍| 328/349 [07:41<00:22,  1.05s/it]\u001b[A\n",
      " 94%|█████████▍| 329/349 [07:42<00:18,  1.07it/s]\u001b[A\n",
      " 95%|█████████▍| 330/349 [07:44<00:26,  1.42s/it]\u001b[A\n",
      " 95%|█████████▍| 331/349 [07:45<00:21,  1.20s/it]\u001b[A\n",
      " 95%|█████████▌| 332/349 [07:46<00:19,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 333/349 [07:48<00:20,  1.31s/it]\u001b[A\n",
      " 96%|█████████▌| 334/349 [07:52<00:30,  2.06s/it]\u001b[A\n",
      " 96%|█████████▌| 335/349 [07:53<00:24,  1.75s/it]\u001b[A\n",
      " 96%|█████████▋| 336/349 [07:53<00:18,  1.42s/it]\u001b[A\n",
      " 97%|█████████▋| 337/349 [07:54<00:15,  1.33s/it]\u001b[A\n",
      " 97%|█████████▋| 338/349 [07:55<00:12,  1.13s/it]\u001b[A\n",
      " 97%|█████████▋| 339/349 [07:57<00:13,  1.38s/it]\u001b[A\n",
      " 97%|█████████▋| 340/349 [07:58<00:10,  1.21s/it]\u001b[A\n",
      " 98%|█████████▊| 341/349 [08:01<00:14,  1.78s/it]\u001b[A\n",
      " 98%|█████████▊| 342/349 [08:06<00:19,  2.77s/it]\u001b[A\n",
      " 98%|█████████▊| 343/349 [08:08<00:15,  2.61s/it]\u001b[A\n",
      " 99%|█████████▊| 344/349 [08:09<00:09,  1.99s/it]\u001b[A\n",
      " 99%|█████████▉| 345/349 [08:10<00:06,  1.71s/it]\u001b[A\n",
      " 99%|█████████▉| 346/349 [08:10<00:04,  1.37s/it]\u001b[A\n",
      " 99%|█████████▉| 347/349 [08:11<00:02,  1.12s/it]\u001b[A\n",
      "100%|█████████▉| 348/349 [08:13<00:01,  1.31s/it]\u001b[A\n",
      "100%|██████████| 349/349 [08:14<00:00,  1.42s/it]\u001b[A\n",
      "  0%|          | 0/380 [11:58<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(files[:]):\n",
    "    #if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file))):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        if len(graph.edges) < 1500:\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                if re.sub('matt_preds/','',re.sub('_warped.pickle','',re.sub('xyz','XYZ',file))).split('-')[1] in df[sheet_name].values:\n",
    "                    subj = sheet_name\n",
    "                    if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1] in sheet_name:\n",
    "                        if subj in [\"TBI07_3D\",\n",
    "                                    \"TBI11_3D\",\n",
    "                                    \"TBI22_3D\",\n",
    "                                    \"TBI31_3D\",\n",
    "                                    \"TBI38_3D\",\n",
    "                                    \"SHAM09_3D\",\n",
    "                                    \"SHAM12_3D\",\n",
    "                                    \"SHAM23_3D\",\n",
    "                                    \"SHAM32_3D\",\n",
    "                                    'TBI38_3D',\n",
    "                                    'TBI6_3D',\n",
    "                                    'SHAM7_3D',\n",
    "                                    'TBI43_3D',\n",
    "                                    'TBI45_3D',\n",
    "                                    'SHAM53_3D',\n",
    "                                    'SHAM56_3D',\n",
    "                                    'SHAM55_3D']:\n",
    "                            gender = 'male'\n",
    "                        else:\n",
    "                            gender = 'female'\n",
    "                        treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                        _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',re.sub('xyz','XYZ',file))).split('-')[1]]\n",
    "                        if _tmp['Unnamed: 12'].iloc[0] == 'raster':\n",
    "                            seg_file = re.sub('_warped.pickle','_seg_warped.tif',file)\n",
    "                            seg_0001_file = re.sub('_warped.pickle','_0001_seg_warped.tif',file)\n",
    "                            img_file = re.sub('_warped.pickle','.tif',file)\n",
    "                            img_0001_file = re.sub('_warped.pickle','_0001_warped.tif',file)\n",
    "                            seg = io.imread(seg_file)\n",
    "                            seg_0001 = io.imread(seg_0001_file)\n",
    "                            img = io.imread(img_file)\n",
    "                            img = np.swapaxes(img,1,3)\n",
    "                            img_0001 = np.int16(io.imread(img_0001_file))\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "                            nrn_dst = np.load(re.sub('_warped.pickle','_seg_nrn_dst.npy',file))\n",
    "                            nrn_dst = np.swapaxes(nrn_dst,0,2)\n",
    "                            wavelength = _tmp['Unnamed: 11'].iloc[0]\n",
    "                            power_per = _tmp['Unnamed: 10'].iloc[0]\n",
    "                            start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                            age = _tmp['Unnamed: 14'].iloc[0]\n",
    "                            days_post_injury = _tmp['Unnamed: 15'].iloc[0]\n",
    "                            \n",
    "                            a, b, c = np.mgrid[-15:16:1, -15:16:1, -15:16:1]\n",
    "                            abc = np.dstack([a.flat,b.flat, c.flat])\n",
    "                            mu = np.array([0,0,0])\n",
    "                            sigma = np.array([0.636,0.127,0.127])\n",
    "                            covariance = np.diag(sigma**2)\n",
    "                            d = multivariate_normal.pdf(abc, mean=mu, cov=covariance)\n",
    "                            d = d.reshape((len(a),len(b),len(c)))\n",
    "                            deconv_img = np.copy(img)\n",
    "                            deconv_img[0] =  1023 * restoration.richardson_lucy(img[0]/1023.0, d, iterations=10)\n",
    "                            deconv_img[1] =  1023 * restoration.richardson_lucy(img[1]/1023.0, d, iterations=10)\n",
    "                            deconv_img = np.int16(deconv_img)\n",
    "                            deconv_img_0001 = np.copy(img_0001)\n",
    "                            deconv_img_0001[0] =  1023 * restoration.richardson_lucy(img_0001[0]/1023.0, d, iterations=10)\n",
    "                            deconv_img_0001[1] =  1023 * restoration.richardson_lucy(img_0001[1]/1023.0, d, iterations=10)\n",
    "                            deconv_img_0001 = np.int16(deconv_img_0001)\n",
    "                            \n",
    "                            for i in tqdm(range(len(graph.edges))):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii == 0:\n",
    "                                    _pred_radii =1\n",
    "                                    _pred_radii_max = 5\n",
    "                                _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii_0001 == 0:\n",
    "                                    _pred_radii_0001 =1\n",
    "                                    _pred_radii_max_0001 = 5\n",
    "                                \n",
    "                                _box_fit = max([np.int16(_pred_radii_max)+5, np.int16(_pred_radii_max_0001)+5, 10])\n",
    "                                #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "                                path_smooth = np.float32(np.copy(path))\n",
    "                                for k in range(len(path[0])):\n",
    "                                    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "                                path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "                                res_fwhm = []\n",
    "                                res_fwhm_0001 = []\n",
    "                                X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                x,y = np.meshgrid(X,Y)\n",
    "                                x = x.flatten()\n",
    "                                y = y.flatten()\n",
    "                                z = np.zeros(len(x))\n",
    "                                xy = np.vstack([x,y,z])\n",
    "                                \n",
    "                                def calc_fwhm_path(I):\n",
    "                                    point_grad = path_grad[I]\n",
    "                                    point = path[I]\n",
    "                                    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "                                        rotated = xy.T + point\n",
    "                                    else:\n",
    "                                        rotated = _rotmat(point_grad,xy.T) + point\n",
    "                                    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                                                        rotated.T, \n",
    "                                                                        order=1,\n",
    "                                                                        cval=-10000)\n",
    "                                    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                                                             rotated.T, \n",
    "                                                                             order=1,\n",
    "                                                                             cval=-10000)\n",
    "                                    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                      xy[0:2, points!=-10000], \n",
    "                                                                      points[points!=-10000], \n",
    "                                                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                           0,\n",
    "                                                                           0,\n",
    "                                                                           np.mean(points[points!=-10000])]),\n",
    "                                                                      bounds = ((-1023, 1e-4, -1*_pred_radii/2, -1*_pred_radii/2, -1023), \n",
    "                                                                                (1023, _pred_radii_max*5/(2*np.sqrt(2*np.log(2))), _pred_radii/2, _pred_radii/2, 1023)),\n",
    "                                                                      maxfev=10000\n",
    "                                                                     )\n",
    "                                    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                                xy[0:2, points_0001!=-10000], \n",
    "                                                                                points_0001[points_0001!=-10000], \n",
    "                                                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                                     0,\n",
    "                                                                                     0,\n",
    "                                                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/2, -1*_pred_radii_0001/2, -1023), \n",
    "                                                                                          (1023, _pred_radii_max_0001*5/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/2, _pred_radii_0001/2, 1023)),\n",
    "                                                                                maxfev=10000\n",
    "                                                                               )\n",
    "                                    sigma = popt[1]\n",
    "                                    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "                                    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    sigma_0001= popt_0001[1]\n",
    "                                    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "                                    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    return fwhm, fwhm_0001, fwhm_sigma, fwhm_sigma_0001\n",
    "                                \n",
    "                                pool = multiprocessing.Pool(16)\n",
    "                                _vals, _vals_0001, _vals_sigma, _vals_sigma_0001 = zip(*pool.map(calc_fwhm_path, range(len(path))))\n",
    "                                _nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty'] = _vals_sigma\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty_0001'] = _vals_sigma_0001\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['wavelength'] = wavelength\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['power'] = power_per\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            #nx.write_gpickle(graph, re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',file)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4feb5-5a35-48d0-8b7d-f7b2b7848162",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dafe5c-dcae-4ffd-825f-5e0726eee8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_pred_radii)\n",
    "print(_pred_radii_0001)\n",
    "max([np.int16(_pred_radii)+10, np.int16(_pred_radii)+10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d617d5-e284-478b-98e4-204d1b2e0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=341\n",
    "path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "_pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "_pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "if _pred_radii == 0:\n",
    "    _pred_radii =1\n",
    "_pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "_pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "if _pred_radii_0001 == 0:\n",
    "    _pred_radii_0001 =1\n",
    "\n",
    "#a, b, c = np.mgrid[-15:16:1, -15:16:1, -15:16:1]\n",
    "#abc = np.dstack([a.flat,b.flat, c.flat])\n",
    "#mu = np.array([0,0,0])\n",
    "#sigma = np.array([0.636,0.127,0.127])\n",
    "#covariance = np.diag(sigma**2)\n",
    "#d = multivariate_normal.pdf(abc, mean=mu, cov=covariance)\n",
    "#d = d.reshape((len(a),len(b),len(c)))\n",
    "#deconv_img = np.copy(img)\n",
    "#deconv_img[0] =  1023 * restoration.richardson_lucy(img[0]/1023.0, d, iterations=10)\n",
    "#deconv_img[1] =  1023 * restoration.richardson_lucy(img[1]/1023.0, d, iterations=10)\n",
    "#deconv_img = np.int16(deconv_img)\n",
    "#deconv_img_0001 = np.copy(img_0001)\n",
    "#deconv_img_0001[0] =  1023 * restoration.richardson_lucy(img_0001[0]/1023.0, d, iterations=10)\n",
    "#deconv_img_0001[1] =  1023 * restoration.richardson_lucy(img_0001[1]/1023.0, d, iterations=10)\n",
    "#deconv_img_0001 = np.int16(deconv_img_0001)\n",
    "\n",
    "\n",
    "_box_fit = max([np.int16(_pred_radii_max)+5, np.int16(_pred_radii_max_0001)+5, 10])\n",
    "#path_grad = np.gradient(path,edge_order=2)[0]\n",
    "path_smooth = np.float32(np.copy(path))\n",
    "for k in range(len(path[0])):\n",
    "    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "res_fwhm = []\n",
    "res_fwhm_0001 = []\n",
    "X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "x,y = np.meshgrid(X,Y)\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "z = np.zeros(len(x))\n",
    "xy = np.vstack([x,y,z])\n",
    "\n",
    "def calc_fwhm_path(I):\n",
    "    point_grad = path_grad[I]\n",
    "    point = path[I]\n",
    "    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "        rotated = xy.T + point\n",
    "    else:\n",
    "        rotated = _rotmat(point_grad,xy.T) + point\n",
    "    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                        rotated.T, \n",
    "                                        order=1,\n",
    "                                        cval=-10000)\n",
    "    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                             rotated.T, \n",
    "                                             order=1,\n",
    "                                             cval=-10000)\n",
    "    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                      xy[0:2, points!=-10000], \n",
    "                                      points[points!=-10000], \n",
    "                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                           0,\n",
    "                                           0,\n",
    "                                           np.mean(points[points!=-10000])]),\n",
    "                                      bounds = ((-1023, 1e-4, -1*_pred_radii/2, -1*_pred_radii/2, -1023), \n",
    "                                                (1023, _pred_radii_max*5/(2*np.sqrt(2*np.log(2))), _pred_radii/2, _pred_radii/2, 1023)),\n",
    "                                      maxfev=10000\n",
    "                                     )\n",
    "    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                xy[0:2, points_0001!=-10000], \n",
    "                                                points_0001[points_0001!=-10000], \n",
    "                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                     0,\n",
    "                                                     0,\n",
    "                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/2, -1*_pred_radii_0001/2, -1023), \n",
    "                                                          (1023, _pred_radii_max_0001*5/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/2, _pred_radii_0001/2, 1023)),\n",
    "                                                maxfev=10000\n",
    "                                               )\n",
    "    sigma = popt[1]\n",
    "    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    sigma_0001= popt_0001[1]\n",
    "    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    return fwhm, fwhm_0001, fwhm_sigma, fwhm_sigma_0001\n",
    "\n",
    "pool = multiprocessing.Pool(16)\n",
    "res_fwhm, res_fwhm_0001, res_fwhm_sigma, res_fwhm_sigma_0001  = zip(*pool.map(calc_fwhm_path, range(len(path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694d5a6-6c72-4111-a983-d948d4ad3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_box_fit = max([np.int16(_pred_radii)+20, np.int16(_pred_radii)+20, 25])\n",
    "#path_grad = np.gradient(path,edge_order=2)[0]\n",
    "path_smooth = np.float32(np.copy(path))\n",
    "for k in range(len(path[0])):\n",
    "    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "res_fwhm = []\n",
    "res_fwhm_0001 = []\n",
    "X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "x,y = np.meshgrid(X,Y)\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "z = np.zeros(len(x))\n",
    "xy = np.vstack([x,y,z])\n",
    "\n",
    "res_fwhm = []\n",
    "res_fwhm_0001 = []\n",
    "\n",
    "res_fwhm_sigma = []\n",
    "res_fwhm_sigma_0001 = []\n",
    "\n",
    "for I in tqdm(range(len(path))):\n",
    "    if I==40:\n",
    "        break\n",
    "    point_grad = path_grad[I]\n",
    "    point = path[I]\n",
    "    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "        rotated = xy.T + point\n",
    "    else:\n",
    "        rotated = _rotmat(point_grad,xy.T) + point\n",
    "    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                        rotated.T, \n",
    "                                        order=1,\n",
    "                                        cval=-10000)\n",
    "    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                             rotated.T, \n",
    "                                             order=1,\n",
    "                                             cval=-10000)\n",
    "    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                      xy[0:2, points!=-10000], \n",
    "                                      points[points!=-10000], \n",
    "                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                           0,\n",
    "                                           0,\n",
    "                                           np.mean(points[points!=-10000])]),\n",
    "                                      bounds = ((-1023, 1e-4, -1*_pred_radii/2, -1*_pred_radii/2, -1023), \n",
    "                                                (1023, _pred_radii_max*5/(2*np.sqrt(2*np.log(2))), _pred_radii/2, _pred_radii/2, 1023)),\n",
    "                                      maxfev=10000\n",
    "                                     )\n",
    "    break\n",
    "    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                xy[0:2, points_0001!=-10000], \n",
    "                                                points_0001[points_0001!=-10000], \n",
    "                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                     0,\n",
    "                                                     0,\n",
    "                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/2, -1*_pred_radii_0001/2, -1023), \n",
    "                                                          (1023, _pred_radii_max_0001*5/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/2, _pred_radii_0001/2, 1023)),\n",
    "                                                maxfev=10000\n",
    "                                               )\n",
    "    sigma = popt[1]\n",
    "    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    sigma_0001= popt_0001[1]\n",
    "    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    #print(fwhm)\n",
    "    #print(I)\n",
    "    res_fwhm.append(fwhm)\n",
    "    res_fwhm_0001.append(fwhm_0001)\n",
    "    res_fwhm_sigma.append(fwhm_sigma)\n",
    "    res_fwhm_sigma_0001.append(fwhm_sigma_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c03767-1002-44b4-ad2b-bc76f762588f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2fc39-8e82-4b0b-9e61-d032e444f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_img_0001 = np.copy(img_0001)\n",
    "deconv_img_0001[0] =  1023 * restoration.richardson_lucy(img_0001[0]/1023, d, iterations=10,clip=False)\n",
    "deconv_img_0001[1] =  1023 * restoration.richardson_lucy(img_0001[1]/1023, d, iterations=10,clip=False)\n",
    "deconv_img_0001 = np.int16(deconv_img_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83ebe7-700c-41a0-a5ed-9a226f4b3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_img_0001[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66712e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.max(np.int16(deconv_img_0001[0]-deconv_img_0001[1]),axis=1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5cc8aaf-093b-4ac6-8147-6521bf189ac0",
   "metadata": {},
   "source": [
    "plt.imshow(np.max(np.int16(deconv_img[0]- deconv_img[1]),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1f0ae-87a1-41b9-956f-6a3fdf3b3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deconv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958163a-d41a-4273-b7c0-8381e411efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(res_fwhm_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669799c-6e41-4779-bb03-6412099bb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(res_fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd716d4a-91d6-499d-b464-6fd77baf4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_fwhm)\n",
    "plt.plot(res_fwhm_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(res_fwhm_0001) - np.array(res_fwhm))\n",
    "plt.plot(np.zeros(len(res_fwhm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e23cdd-06fa-4723-a187-76fc9880988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_fwhm_sigma)\n",
    "plt.plot(res_fwhm_sigma_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b0b91-5f15-4dbd-afb6-e57a963ccba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b1802-94ac-4be3-81e3-9c3ac54aef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e0db5-c428-494e-84bb-a3645840ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30a710-d7a7-4537-8026-7fc6bb5c8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points,(len(X),len(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc7362-65ab-4bb6-9f73-d55d198ec990",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(twoD_Gaussian(xy[0:2],*popt),(len(X),len(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccff47e-0efb-40ea-aeff-62127bd41b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(points_0001,(len(X),len(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87acf992-9fba-48e2-b6c6-64c8407453aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(twoD_Gaussian(xy[0:2],*popt_0001),(len(X),len(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc4e6b-bc44-4e11-ae9b-da0cc5a6b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_img_0001 = io.imread(img_0001_file)\n",
    "img_0001 = np.zeros(img.shape)\n",
    "img_0001[0] = _img_0001[:,:,:507]\n",
    "img_0001[1] = _img_0001[:,:,508:1015]\n",
    "\n",
    "print(img_0001.shape)\n",
    "#img_0001 = np.reshape(img_0001,(252,507,507))\n",
    "#img_0001.shape\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad3c3e-efae-44b8-9f5d-87b8d0b70e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a31b3-ff3e-4eef-baf0-1c2da6996409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.int16(img_0001[0,20,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898f90d1-c48d-4059-af19-13a1a8d54086",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202ac8b-4823-4261-a165-b1f78bcc9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros([len(x),len(y)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db9519-ea5d-4630-9a57-d09a047cd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = _rotmat(point_grad,xy.T)\n",
    "rotated[:,0]*1+rotated[:,1]*1.5+rotated[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec064eab-4b32-4f15-ad94-5faf33de3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nrn_dst.shape)\n",
    "print(seg_dst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ec65da-36a4-48ca-8994-f5153e5cf748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    }
   ],
   "source": [
    "graphs = [file for file in files if not os.path.exists(re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',file)))]\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83abb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 48/380 [00:20<00:01, 228.16it/s]\n",
      "  0%|          | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/43 [00:14<10:18, 14.73s/it]\u001b[A\n",
      "  5%|▍         | 2/43 [00:21<06:40,  9.76s/it]\u001b[A\n",
      "  7%|▋         | 3/43 [00:26<05:11,  7.78s/it]\u001b[A\n",
      "  9%|▉         | 4/43 [00:32<04:29,  6.90s/it]\u001b[A\n",
      " 12%|█▏        | 5/43 [00:37<04:07,  6.51s/it]\u001b[A\n",
      " 14%|█▍        | 6/43 [00:43<03:47,  6.15s/it]\u001b[A\n",
      " 16%|█▋        | 7/43 [01:45<14:37, 24.39s/it]\u001b[A\n",
      " 19%|█▊        | 8/43 [01:51<10:46, 18.48s/it]\u001b[A\n",
      " 21%|██        | 9/43 [01:56<08:05, 14.29s/it]\u001b[A\n",
      " 23%|██▎       | 10/43 [02:01<06:25, 11.68s/it]\u001b[A\n",
      " 26%|██▌       | 11/43 [02:34<09:36, 18.02s/it]\u001b[A\n",
      " 28%|██▊       | 12/43 [02:39<07:16, 14.07s/it]\u001b[A\n",
      " 30%|███       | 13/43 [02:45<05:48, 11.62s/it]\u001b[A\n",
      " 33%|███▎      | 14/43 [02:51<04:52, 10.08s/it]\u001b[A\n",
      " 35%|███▍      | 15/43 [02:57<04:03,  8.69s/it]\u001b[A\n",
      " 37%|███▋      | 16/43 [03:57<10:48, 24.04s/it]\u001b[A\n",
      " 40%|███▉      | 17/43 [04:02<07:58, 18.39s/it]\u001b[A\n",
      " 42%|████▏     | 18/43 [04:57<12:19, 29.57s/it]\u001b[A\n",
      " 44%|████▍     | 19/43 [05:38<13:08, 32.84s/it]\u001b[A\n",
      " 47%|████▋     | 20/43 [06:09<12:24, 32.36s/it]\u001b[A\n",
      " 49%|████▉     | 21/43 [06:20<06:38, 18.14s/it]\u001b[A\n",
      " 14%|█▎        | 52/380 [10:15<1:04:41, 11.83s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x0` is infeasible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_3022298/907876337.py\", line 127, in calc_fwhm_path\n    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian,\n  File \"/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/scipy/optimize/minpack.py\", line 800, in curve_fit\n    res = least_squares(func, p0, jac=jac, bounds=bounds, method=method,\n  File \"/lustre06/project/6023374/rozakmat/monai3.8/lib/python3.8/site-packages/scipy/optimize/_lsq/least_squares.py\", line 808, in least_squares\n    raise ValueError(\"`x0` is infeasible.\")\nValueError: `x0` is infeasible.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3022298/907876337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                 \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                 \u001b[0m_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_vals_0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_vals_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_vals_sigma_0001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_fwhm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                                 \u001b[0m_nrn_dst_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrn_dst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                                 \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'radii'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.8.10/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `x0` is infeasible."
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(graphs):\n",
    "    #if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file))):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        if len(graph.edges) < 1500:\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1] in df[sheet_name].values:\n",
    "                    subj = sheet_name\n",
    "                    if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_')[1] in sheet_name:\n",
    "                        if subj in [\"TBI07_3D\",\n",
    "                                    \"TBI11_3D\",\n",
    "                                    \"TBI22_3D\",\n",
    "                                    \"TBI31_3D\",\n",
    "                                    \"TBI38_3D\",\n",
    "                                    \"SHAM09_3D\",\n",
    "                                    \"SHAM12_3D\",\n",
    "                                    \"SHAM23_3D\",\n",
    "                                    \"SHAM32_3D\",\n",
    "                                    'TBI38_3D',\n",
    "                                    'TBI6_3D',\n",
    "                                    'SHAM7_3D',\n",
    "                                    'TBI43_3D',\n",
    "                                    'TBI45_3D',\n",
    "                                    'SHAM53_3D',\n",
    "                                    'SHAM56_3D',\n",
    "                                    'SHAM55_3D']:\n",
    "                            gender = 'male'\n",
    "                        else:\n",
    "                            gender = 'female'\n",
    "                        treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                        _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[1]]\n",
    "                        if _tmp['Unnamed: 10'].iloc[0] == 2:\n",
    "                            seg_file = re.sub('_warped.pickle','_seg_warped.tif',file)\n",
    "                            seg_0001_file = re.sub('_warped.pickle','_0001_seg_warped.tif',file)\n",
    "                            img_file = re.sub('_warped.pickle','.tif',file)\n",
    "                            img_0001_file = re.sub('_warped.pickle','_0001_warped.tif',file)\n",
    "                            seg = io.imread(seg_file)\n",
    "                            seg_0001 = io.imread(seg_0001_file)\n",
    "                            img = io.imread(img_file)\n",
    "                            img = np.swapaxes(img,1,3)\n",
    "                            img_0001 = np.int16(io.imread(img_0001_file))\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "                            nrn_dst = np.load(re.sub('_warped.pickle','_seg_nrn_dst.npy',file))\n",
    "                            nrn_dst = np.swapaxes(nrn_dst,0,2)\n",
    "                            start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                            age = _tmp['Unnamed: 8'].iloc[0]\n",
    "                            days_post_injury = _tmp['Unnamed: 9'].iloc[0]\n",
    "                            \n",
    "                            a, b, c = np.mgrid[-15:16:1, -15:16:1, -15:16:1]\n",
    "                            abc = np.dstack([a.flat,b.flat, c.flat])\n",
    "                            mu = np.array([0,0,0])\n",
    "                            sigma = np.array([0.636,0.127,0.127])\n",
    "                            covariance = np.diag(sigma**2)\n",
    "                            d = multivariate_normal.pdf(abc, mean=mu, cov=covariance)\n",
    "                            d = d.reshape((len(a),len(b),len(c)))\n",
    "                            deconv_img = np.copy(img)\n",
    "                            deconv_img[0] =  1023 * restoration.richardson_lucy(img[0]/1023.0, d, iterations=10)\n",
    "                            deconv_img[1] =  1023 * restoration.richardson_lucy(img[1]/1023.0, d, iterations=10)\n",
    "                            deconv_img = np.int16(deconv_img)\n",
    "                            deconv_img_0001 = np.copy(img_0001)\n",
    "                            deconv_img_0001[0] =  1023 * restoration.richardson_lucy(img_0001[0]/1023.0, d, iterations=10)\n",
    "                            deconv_img_0001[1] =  1023 * restoration.richardson_lucy(img_0001[1]/1023.0, d, iterations=10)\n",
    "                            deconv_img_0001 = np.int16(deconv_img_0001)\n",
    "                            \n",
    "                            for i in tqdm(range(len(graph.edges))):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii == 0:\n",
    "                                    _pred_radii =1\n",
    "                                    _pred_radii_max = 5\n",
    "                                _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii_0001 == 0:\n",
    "                                    _pred_radii_0001 =1\n",
    "                                    _pred_radii_max_0001 = 5\n",
    "                                \n",
    "                                _box_fit = max([np.int16(_pred_radii_max)+5, np.int16(_pred_radii_max_0001)+5, 10])\n",
    "                                #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "                                path_smooth = np.float32(np.copy(path))\n",
    "                                for k in range(len(path[0])):\n",
    "                                    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "                                path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "                                res_fwhm = []\n",
    "                                res_fwhm_0001 = []\n",
    "                                X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                x,y = np.meshgrid(X,Y)\n",
    "                                x = x.flatten()\n",
    "                                y = y.flatten()\n",
    "                                z = np.zeros(len(x))\n",
    "                                xy = np.vstack([x,y,z])\n",
    "                                \n",
    "                                def calc_fwhm_path(I):\n",
    "                                    point_grad = path_grad[I]\n",
    "                                    point = path[I]\n",
    "                                    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "                                        rotated = xy.T + point\n",
    "                                    else:\n",
    "                                        rotated = _rotmat(point_grad,xy.T) + point\n",
    "                                    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                                                        rotated.T, \n",
    "                                                                        order=3,\n",
    "                                                                        cval=-10000)\n",
    "                                    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                                                             rotated.T, \n",
    "                                                                             order=3,\n",
    "                                                                             cval=-10000)\n",
    "                                    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                      xy[0:2, points!=-10000], \n",
    "                                                                      points[points!=-10000], \n",
    "                                                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                           0,\n",
    "                                                                           0,\n",
    "                                                                           np.mean(points[points!=-10000])]),\n",
    "                                                                      bounds = ((-1023, 1e-4, -1*_pred_radii/2, -1*_pred_radii/2, -1023), \n",
    "                                                                                (1023, _pred_radii_max*5/(2*np.sqrt(2*np.log(2))), _pred_radii/2, _pred_radii/2, 1023)),\n",
    "                                                                      maxfev=10000\n",
    "                                                                     )\n",
    "                                    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                                xy[0:2, points_0001!=-10000], \n",
    "                                                                                points_0001[points_0001!=-10000], \n",
    "                                                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                                     0,\n",
    "                                                                                     0,\n",
    "                                                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/2, -1*_pred_radii_0001/2, -1023), \n",
    "                                                                                          (1023, _pred_radii_max_0001*5/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/2, _pred_radii_0001/2, 1023)),\n",
    "                                                                                maxfev=10000\n",
    "                                                                               )\n",
    "                                    sigma = popt[1]\n",
    "                                    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "                                    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    sigma_0001= popt_0001[1]\n",
    "                                    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "                                    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    return fwhm, fwhm_0001, fwhm_sigma, fwhm_sigma_0001\n",
    "                                \n",
    "                                pool = multiprocessing.Pool(16)\n",
    "                                _vals, _vals_0001, _vals_sigma, _vals_sigma_0001 = zip(*pool.map(calc_fwhm_path, range(len(path))))\n",
    "                                _nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty'] = _vals_sigma\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty_0001'] = _vals_sigma_0001\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            #nx.write_gpickle(graph, re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii_shock.pickle',file)))\n",
    "                            i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b11aefa-4042-4384-8126-42f944e0558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matt_preds/06162021_45-XYZres288_0001_mean.npy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graphs = [file for file in graphs if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii_shock.pickle',file)))]\n",
    "print(len(_graphs))\n",
    "print(_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5be2",
   "metadata": {},
   "source": [
    "# convert graphs to excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds_graphs_fwhm')\n",
    "files = directory.glob('*_warped_radii.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8054d74-c332-4899-973c-8c0c303d0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    edge_df.to_excel(re.sub('.pickle','.xlsx',file))\n",
    "    res.append(len(edge_df))\n",
    "    print(edge_df.shape)\n",
    "#print(np.mean(res))\n",
    "#print(np.std(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e3cf4-9c83-40b7-a7dc-df3c8b02a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01fb99-e049-497b-a79a-8ecce8bcf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46893c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds_graphs')\n",
    "files = directory.glob('*_warped_radii_shock.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(len(files))\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e900d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    edge_df.to_excel(re.sub('.pickle','.xlsx',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb2639-ecdf-4cfd-9175-562423a5fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
