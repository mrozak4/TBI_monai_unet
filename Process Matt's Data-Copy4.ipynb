{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7be0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre06/project/6023374/rozakmat/monai/lib/python3.7/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3838267/3984914506.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ants'"
     ]
    }
   ],
   "source": [
    "#from nipype.interfaces import niftyreg\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ants\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation, binary_closing\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import tifffile as tif\n",
    "from scipy.ndimage import binary_fill_holes \n",
    "import cc3d\n",
    "from scipy.io import loadmat, savemat\n",
    "import skan\n",
    "import sknw\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f724d",
   "metadata": {},
   "source": [
    "# Define connected componnet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9888d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_comps_3d(image, thresh = 500):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : binary np array with uint8 elements\n",
    "        3d numpy matrix, connected components will be removed form this image\n",
    "    thresh : int64\n",
    "        smallest connected components to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array with uint8 elements, binary\n",
    "        binary image with connected components below the threshold removed.\n",
    "\n",
    "    \"\"\"\n",
    "    img_lab, N = cc3d.connected_components(image,return_N=True)\n",
    "    unique, counts = np.unique(img_lab, return_counts=True)\n",
    "    unique_keep = unique[counts>thresh]\n",
    "    unique_keep = np.delete(unique_keep,[0])\n",
    "    img_filt = np.zeros(img_lab.shape).astype('int8')\n",
    "    img_filt[np.isin(img_lab,unique_keep)] = 1\n",
    "    return img_filt.astype('uint8')   \n",
    "\n",
    "def fill_holes(img,thresh=100):\n",
    "    #res = np.zeros(img.shape)\n",
    "    for i in np.unique(img)[::-1]:\n",
    "        _tmp = (img==i)*1.0\n",
    "        _tmp = _tmp.astype('int8')\n",
    "        _tmp = remove_small_comps_3d(_tmp,thresh=thresh)\n",
    "        img[_tmp==1] = i\n",
    "    res = img.astype('int8')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7b76",
   "metadata": {},
   "source": [
    "# Get mean predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b09644",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files  = directory.glob('*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5c3c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8db528",
   "metadata": {},
   "source": [
    "# High bias low varience segmentation\n",
    "\n",
    "With removal of connected components under 500 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files[::-1]):\n",
    "    if not os.path.exists(re.sub('mean','seg',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==1)*1\n",
    "        seg = fill_holes(seg)\n",
    "        np.save(re.sub('mean','seg',file),seg)\n",
    "        #savemat(re.sub('mean.npy','seg.mat',file),{'FinalImage':fill_holes(binary_dilation(binary_dilation(seg)))})\n",
    "        #tif.imwrite(re.sub('mean.npy','seg.tif',file),seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca6732",
   "metadata": {},
   "source": [
    "# ANTs registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9228eb",
   "metadata": {},
   "source": [
    "## Upsample raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b86439",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('../TBI')\n",
    "images = list(image_path.glob('*_*/XYZres*?[0-9].tif'))\n",
    "images = sorted([x.as_posix() for x in images])\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8959038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(images))[::-1]):\n",
    "    if not os.path.exists('matt_preds/'+re.sub('.tif','_upsamp.tif',Path(images[i]).name)):\n",
    "        image = io.imread(images[i])\n",
    "        image = np.swapaxes(image,0,1)\n",
    "        image = np.swapaxes(image,1,3)\n",
    "        image = resize(image,(2,507,507,252),preserve_range=True)\n",
    "        zeros = np.zeros((1,507,507,252)).astype('uint16')\n",
    "        image = np.append(image,zeros,axis = 0)\n",
    "        image = image.astype('float16')\n",
    "        io.imsave('matt_preds/'+re.sub('.tif','_upsamp.tif',Path(images[i]).name),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53558e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f08281",
   "metadata": {},
   "source": [
    "## reshape numpy seg files and resave as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "files_seg  = list(directory_seg.glob('*_seg.npy'))\n",
    "files_seg = sorted([x.as_posix() for x in files_seg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(files_seg))):\n",
    "    if not os.path.exists(re.sub('.npy','.tif',files_seg[0])):\n",
    "        tmp = np.load(files_seg[i])\n",
    "        tmp = np.reshape(tmp,(1,507,507,252))\n",
    "        io.imsave(re.sub('.npy','.tif',files_seg[0]),tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf7115",
   "metadata": {},
   "source": [
    "## Register images and transform masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001_upsamp.tif'))\n",
    "images = sorted([x.as_posix() for x in images])#[0:2]\n",
    "images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade09ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(images))):\n",
    "    if os.path.exists(re.sub('upsamp','seg',images[i])):\n",
    "        if not os.path.exists(re.sub('seg','seg_warped',re.sub('upsamp','seg',images[i]))):\n",
    "            fix = ants.image_read(re.sub('_0001','',images[i]))\n",
    "            mov = ants.image_read(images[i])\n",
    "            fix_mask = ants.image_read(re.sub('upsamp','seg',re.sub('_0001','',images[i])))\n",
    "            mov_mask = ants.image_read(re.sub('upsamp','seg',images[i]))\n",
    "            mytx = ants.registration(fixed = fix,\n",
    "                                    moving = mov,\n",
    "                                    type_of_transform = 'Rigid'\n",
    "                                    )\n",
    "            warpedmask = ants.apply_transforms(fixed = fix_mask,\n",
    "                                               moving = mov_mask,\n",
    "                                               transformlist = mytx['fwdtransforms'],\n",
    "                                               interpolator = 'nearestNeighbor'\n",
    "                                              )\n",
    "            break\n",
    "            #io.imsave(re.sub('seg','seg_warped',re.sub('upsamp','seg',images[i])),warpedmask.numpy())\n",
    "            #io.imsave(re.sub('seg','seg_warped',re.sub('upsamp','seg',re.sub('_0001','',images[i]))),fix_mask.numpy())\n",
    "            #print(2 * np.sum(warpedmask.numpy()*fix_mask.numpy())/(np.sum(warpedmask.numpy())+np.sum(fix_mask.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a8329",
   "metadata": {},
   "source": [
    "## Save Matlab .mat file of registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = ants.image_read(re.sub('_0001','',images[i]))\n",
    "fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af813286",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_seg = Path('matt_preds')\n",
    "images = list(directory_seg.glob('*_0001_seg_warped.tif'))\n",
    "images = sorted([x.as_posix() for x in images])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d576f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images):\n",
    "    if not os.path.exists(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image))):\n",
    "        img_0001 = io.imread(image)\n",
    "        img = io.imread(re.sub('_0001','',image))\n",
    "        seg = img*img_0001\n",
    "        seg = (seg==1)*1\n",
    "        seg = seg.astype('int8')\n",
    "        seg = fill_holes(seg)\n",
    "        savemat(re.sub('_seg_warped.tif','_seg_warped_single.mat',re.sub('_0001','',image)),{'FinalImage':fill_holes(binary_dilation(seg))})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5818c18",
   "metadata": {},
   "source": [
    "# Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd876acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds')\n",
    "files_seg_0001 = directory.glob('*_0001_seg_warped.tif')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "len(files_seg_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_0001 in tqdm(files_seg_0001):\n",
    "    file = file_0001\n",
    "    skel_file = re.sub('_0001_seg_warped.tif','_skel_warped_single.mat',file)\n",
    "    #seg = io.imread(file)\n",
    "    skel = loadmat(skel_file)['FilteredImage']\n",
    "    #skel = skeletonize_3d(skel)\n",
    "    io.imsave(re.sub('_seg_warped.tif','_single_skel.tif',file),skel)\n",
    "    #dst_tsfm = distance_transform_edt(seg)\n",
    "    #dst_tsfm[dst_tsfm==0]=0.00001\n",
    "    #skel_dst = skel*dst_tsfm\n",
    "#\n",
    "    #\n",
    "    #np.save(re.sub('seg','dst_skel',file),skel_dst)\n",
    "    #io.imsave(re.sub('_seg_warped.tif','_dst_skel_warped.tif',file),skel_dst)\n",
    "    graph = sknw.build_sknw(skel, multi=False)\n",
    "    print(len(graph.edges))\n",
    "    #graph, c0  = skan.csr.skeleton_to_csgraph(skel)\n",
    "    #print(len(graph.edges))\n",
    "    \n",
    "    #print(len(graph_0001.edges))\n",
    "    #pickle.dump(graph, open(str(re.sub('_seg.npy','.pickle',file)), 'w'))\n",
    "    #nx.write_pajek(graph,re.sub('_seg.npy','.pajek',file))\n",
    "    \n",
    "    nx.write_gpickle(graph,re.sub('_0001_seg_warped.tif','_warped.pickle',file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba7bff",
   "metadata": {},
   "source": [
    "# write vessel measurments to graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f52c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('matt_preds')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d716ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                         | 9/195 [02:18<53:57, 17.41s/it]/tmp/ipykernel_1184917/2457884963.py:50: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in sqrt\n",
      "\n",
      "100%|███████████████████████████████████████| 195/195 [1:03:48<00:00, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(files[::-1]):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    if len(graph.edges) < 1000:\n",
    "        seg_file = re.sub('_warped.pickle','_seg_warped.tif',file)\n",
    "        seg_0001_file = re.sub('_warped.pickle','_0001_seg_warped.tif',file)\n",
    "        seg = io.imread(seg_file)\n",
    "        seg_0001 = io.imread(seg_0001_file)\n",
    "        seg_dst = distance_transform_edt(seg)\n",
    "        seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            if re.sub('matt_preds/','',re.sub('_warped.pickle','',file)) in df[sheet_name].values:\n",
    "                subj = sheet_name\n",
    "                if subj in [\"TBI07_3D\",\"TBI11_3D\",\"TBI22_3D\",\"TBI31_3D\",\"TBI38_3D\",\"SHAM09_3D\",\"SHAM12_3D\",\"SHAM23_3D\",\"SHAM32_3D\"]:\n",
    "                    gender = 'male'\n",
    "                else:\n",
    "                    gender = 'female'\n",
    "                treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',file))]\n",
    "                if _tmp['Unnamed: 12'].iloc[0] == 'raster':\n",
    "                    wavelength = _tmp['Unnamed: 11'].iloc[0]\n",
    "                    power_per = _tmp['Unnamed: 10'].iloc[0]\n",
    "                    start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                    for i in range(len(graph.edges)):\n",
    "                        path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                        _vals = seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                        _vals_0001 = seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                        #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['wavelength'] = wavelength\n",
    "                        graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['power'] = power_per\n",
    "                    nx.write_gpickle(graph, re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file)))\n",
    "                    i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec064eab-4b32-4f15-ad94-5faf33de3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec65da-36a4-48ca-8994-f5153e5cf748",
   "metadata": {},
   "outputs": [],
   "source": [
    "path[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5be2",
   "metadata": {},
   "source": [
    "# convert graphs to excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds_graphs')\n",
    "files = directory.glob('*_warped_radii.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "len(files)\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(files):\n",
    "    graph = nx.read_gpickle(file)\n",
    "    edge_df = nx.to_pandas_edgelist(graph)\n",
    "    edge_df.to_excel(re.sub('.pickle','.xlsx',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46893c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
