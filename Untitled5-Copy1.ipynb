{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178ba64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import re\n",
    "#import ants\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation, binary_closing\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import tifffile as tif\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import cc3d\n",
    "from scipy.io import loadmat, savemat\n",
    "#import skan\n",
    "import sknw\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy as sp\n",
    "import vg\n",
    "from pytransform3d.rotations import matrix_from_axis_angle\n",
    "import multiprocessing\n",
    "from scipy.ndimage import convolve as conv\n",
    "from scipy.stats import multivariate_normal\n",
    "from skimage import color, data, restoration\n",
    "#from RedLionfishDeconv import doRLDeconvolutionFromNpArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e934790-190f-4188-81b3-521c0c94aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47574f10",
   "metadata": {},
   "source": [
    "# Define connected componnet removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8879e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_comps_3d(image, thresh = 500):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : binary np array with uint8 elements\n",
    "        3d numpy matrix, connected components will be removed form this image\n",
    "    thresh : int64\n",
    "        smallest connected components to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array with uint8 elements, binary\n",
    "        binary image with connected components below the threshold removed.\n",
    "\n",
    "    \"\"\"\n",
    "    img_lab, N = cc3d.connected_components(image,return_N=True)\n",
    "    unique, counts = np.unique(img_lab, return_counts=True)\n",
    "    unique_keep = unique[counts>thresh]\n",
    "    unique_keep = np.delete(unique_keep,[0])\n",
    "    img_filt = np.zeros(img_lab.shape).astype('int8')\n",
    "    img_filt[np.isin(img_lab,unique_keep)] = 1\n",
    "    return img_filt.astype('uint8')   \n",
    "\n",
    "def fill_holes(img,thresh=100):\n",
    "    #res = np.zeros(img.shape)\n",
    "    for i in np.unique(img)[::-1]:\n",
    "        _tmp = (img==i)*1.0\n",
    "        _tmp = _tmp.astype('int8')\n",
    "        _tmp = remove_small_comps_3d(_tmp,thresh=thresh)\n",
    "        img[_tmp==1] = i\n",
    "    res = img.astype('int8')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b7e27",
   "metadata": {},
   "source": [
    "# register raw iamges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4010be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n",
      "/home/rozakmat/projects/rrg-bojana/data/THY1-TBI/20201201_35/XYZ1_res_0001.tif\n"
     ]
    }
   ],
   "source": [
    "mouse_ids_path = Path('/home/rozakmat/projects/rrg-bojana/data/THY1-TBI')#each mouse has its own folder with raw data in it\n",
    "mouse_ids = list(mouse_ids_path.glob('*?[0-9]/*res*?[0-9].tif'))#grab folder names/mouse ids\n",
    "images = sorted([x.as_posix() for x in mouse_ids if '_0001' in x.as_posix()])\n",
    "print(len(images))\n",
    "print(images[182])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537af5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(images))):\n",
    "    basename = re.sub('.tif','_warped.tif',os.path.basename(os.path.dirname(images[i])) + '-' + os.path.basename(images[i]))\n",
    "    new_file_name = 'matt_raw_warped/' + basename\n",
    "    if not os.path.exists(new_file_name):\n",
    "        fix_numpy = io.imread(re.sub('_0001','',images[i]))\n",
    "        break\n",
    "        #fix_numpy = np.swapaxes(fix_numpy,1,3)\n",
    "        mov_numpy = io.imread(images[i])\n",
    "        #mov_numpy = np.swapaxes(mov_numpy,1,3)\n",
    "        fix = ants.from_numpy(np.float32(fix_numpy[:,0]))\n",
    "        mov = ants.from_numpy(np.float32(mov_numpy[:,0]))\n",
    "        mytx = ants.registration(fixed = fix,\n",
    "                                moving = mov,\n",
    "                                type_of_transform = 'Rigid'\n",
    "                                )\n",
    "        warpedraw_1 = ants.apply_transforms(fixed = fix,\n",
    "                                            moving = ants.from_numpy(np.float32(mov_numpy[:,0])),\n",
    "                                            transformlist = mytx['fwdtransforms'],\n",
    "                                            interpolator = 'linear'\n",
    "                                            )\n",
    "        warpedraw_2 = ants.apply_transforms(fixed = fix,\n",
    "                                            moving = ants.from_numpy(np.float32(mov_numpy[:,1])),\n",
    "                                            transformlist = mytx['fwdtransforms'],\n",
    "                                            interpolator = 'linear'\n",
    "                                            )\n",
    "        mov_numpy[:,0,:,:] = warpedraw_1[:,:,:]\n",
    "        mov_numpy[:,1,:,:] = warpedraw_2[:,:,:]\n",
    "        basename = re.sub('.tif','_warped.tif',os.path.basename(os.path.dirname(images[i])) + '-' + os.path.basename(images[i]))\n",
    "        new_file_name = 'matt_raw_warped/' + basename\n",
    "        io.imsave(new_file_name,mov_numpy)\n",
    "        io.imsave(re.sub('_0001','',new_file_name),fix_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e204f6-a063-4579-ad8a-5134b44a39e3",
   "metadata": {},
   "source": [
    "# predict using trained model\n",
    "run unetr prediction with registered raw images, orediction will be in same coordinate system \\\n",
    "run predict_matt_warped.py via predict_matt_warped_array-Copy1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d1533-8267-4390-9ee2-c7558f5aee8b",
   "metadata": {},
   "source": [
    "# Binarize prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "577b39db-4ee8-4eea-a5b4-52a4f5414078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matt_preds_registered/06162021_45-XYZres288_0001_warped_mean.npy\n"
     ]
    }
   ],
   "source": [
    "directory = Path('matt_preds_registered')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55de248b-1095-4aa8-a30e-e292103cdc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [00:00<00:00, 14978.18it/s]\n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files[:]):\n",
    "    if (time.time() - os.path.getmtime(re.sub('mean','seg',file)))/3600>10:\n",
    "    #if not os.path.exists(re.sub('mean','seg',file)):\n",
    "        print(file)\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==1)*1\n",
    "        seg = fill_holes(seg)\n",
    "        seg = sp.ndimage.zoom(seg,(3,3,3),order=0)\n",
    "        np.save(re.sub('mean','seg',file),seg)\n",
    "        #savemat(re.sub('mean.npy','seg.mat',file),{'FinalImage':fill_holes(binary_dilation(binary_dilation(seg)))})\n",
    "        #tif.imwrite(re.sub('mean.npy','seg.tif',file),seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad60e72-38f1-4603-8496-86151bd734af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bde1c8-db22-41ae-80b5-ff9ae5acf7b0",
   "metadata": {},
   "source": [
    "# Get distance transform of neuron segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a87811a-2391-4697-9a73-a20210fde162",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('matt_preds_registered')\n",
    "files  = directory.glob('*-*_mean.npy')\n",
    "files = sorted([x.as_posix() for x in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8bfbe5-7019-42fc-a1b6-92172884f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [1:45:54<00:00,  8.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "min_prob = 0.75\n",
    "max_var = 0.1\n",
    "for file in tqdm(files):\n",
    "    #if (time.time() - os.path.getmtime(re.sub('mean','seg_nrn_dst',file)))/3600>48:\n",
    "    if not os.path.exists(re.sub('mean','seg_nrn_dst',file)):\n",
    "        mean = np.load(file)\n",
    "        std = np.load(re.sub('mean','std',file))\n",
    "        seg = np.zeros(mean.shape[1:])\n",
    "        seg[(mean[1,:,:,:] > min_prob) * (std[1,:,:,:] < max_var)] = 1\n",
    "        seg[(mean[2,:,:,:] > min_prob) * (std[2,:,:,:] < max_var)] = 2\n",
    "        seg = seg.astype('int8')\n",
    "        seg = (seg==2)*1\n",
    "        np.save(re.sub('mean','seg_nrn',file),seg)\n",
    "        np.save(re.sub('mean','seg_nrn_dst',file),distance_transform_edt(1-seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c0658-4dcd-479c-8d63-d972dd97b347",
   "metadata": {},
   "source": [
    "# get predicted images and save matlab .mat of intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de73c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    }
   ],
   "source": [
    "directory_seg = Path('matt_preds_registered')\n",
    "images = list(directory_seg.glob('*_0001_warped_seg.npy'))\n",
    "images = sorted([x.as_posix() for x in images])[:]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540342e-dad7-42c5-bd78-05072c4c61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matt_preds_registered/vbm11 Apr 04 2020-XYZres052_0001_warped_seg.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/380 [08:20<52:44:35, 500.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matt_preds_registered/vbm11 Apr 04 2020-XYZres051_0001_warped_seg.npy\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(images[::-1]):\n",
    "    #if not os.path.exists(re.sub('_warped_seg.npy','_seg_warped_single.mat',re.sub('_0001','',image))):\n",
    "    if (time.time() - os.path.getmtime(re.sub('_warped_seg.npy','_seg_warped_single.mat',re.sub('_0001','',image))))/3600>6:\n",
    "        print(image)\n",
    "        img_0001 = np.load(image)\n",
    "        img = np.load(re.sub('_0001','',image))\n",
    "        seg = img*img_0001\n",
    "        seg = (seg==1)*1\n",
    "        seg = seg.astype('int8')\n",
    "        seg = fill_holes(seg)\n",
    "        savemat(re.sub('_warped_seg.npy','_seg_warped_single.mat',re.sub('_0001','',image)),{'FinalImage':fill_holes(binary_dilation(seg))})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88724b6",
   "metadata": {},
   "source": [
    "# Generate Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d2f9bc-ddab-451e-b194-f4d6a7398a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path('matt_preds_registered')\n",
    "files_seg_0001 = directory.glob('*_0001_warped_seg.npy')\n",
    "files_seg_0001 = sorted([x.as_posix() for x in files_seg_0001])\n",
    "len(files_seg_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e754c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 82/380 [00:11<00:00, 815.58it/s]/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres151_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 34%|███▍      | 131/380 [00:29<01:09,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres152_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 35%|███▍      | 132/380 [00:59<02:44,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres153_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 35%|███▌      | 133/380 [01:28<04:54,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres154_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 35%|███▌      | 134/380 [01:57<07:50,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres155_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 36%|███▌      | 135/380 [02:26<11:46,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres156_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 36%|███▌      | 136/380 [02:55<16:52,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres157_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 36%|███▌      | 137/380 [03:24<23:19,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200227_23-XYZres158_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 36%|███▋      | 138/380 [03:53<31:10,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres171_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 37%|███▋      | 139/380 [04:22<40:16, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres172_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 37%|███▋      | 140/380 [04:51<50:18, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres173_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 37%|███▋      | 141/380 [05:20<1:00:34, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres175_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 38%|███▊      | 143/380 [05:49<59:13, 14.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres177_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 38%|███▊      | 145/380 [06:18<58:07, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres179_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 39%|███▊      | 147/380 [06:48<57:35, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres180_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 39%|███▉      | 148/380 [07:17<1:07:12, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_26-XYZres181_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      " 39%|███▉      | 149/380 [07:46<1:16:03, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569328/2490744040.py:8: UserWarning: matt_preds_registered/20200411_28-XYZres183_single_skel.tif is a low contrast image\n",
      "  io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
      "100%|██████████| 380/380 [08:15<00:00,  1.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for file_0001 in tqdm(files_seg_0001[:]):\n",
    "    #if not os.path.exists(re.sub('_0001_warped_seg.npy','_warped.pickle',file_0001)):\n",
    "    if (time.time() - os.path.getmtime(re.sub('_0001_warped_seg.npy','_warped.pickle',file_0001)))/3600>10:\n",
    "        file = file_0001\n",
    "        skel_file = re.sub('_0001_warped_seg.npy','_skel_warped_single.mat',file)\n",
    "        skel = loadmat(skel_file)['FilteredImage']\n",
    "        if np.sum(skel) != 0:\n",
    "            io.imsave(re.sub('_0001_warped_seg.npy','_single_skel.tif',file),skel)\n",
    "            graph = sknw.build_sknw(skel, multi=False)\n",
    "            print(len(graph.edges))            \n",
    "            nx.write_gpickle(graph,re.sub('_0001_warped_seg.npy','_warped.pickle',file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fb8a9",
   "metadata": {},
   "source": [
    "# write vessel measurments to graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9471d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "directory = Path('matt_preds_registered')\n",
    "files = directory.glob('*_warped.pickle')\n",
    "files = sorted([x.as_posix() for x in files])\n",
    "files = [x for x in files if '-' in x]\n",
    "#files = [x for x in files if not os.path.exists(re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',x)))]\n",
    "print(len(files))\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "97c0c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                | 0/379 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "xls = pd.ExcelFile('TBI_STIM_metalog_local.xlsx')\n",
    "xls2 = pd.ExcelFile('../TBI_monai_UNET/p3_metalog.xlsx')\n",
    "df = {}\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df[sheet_name] = xls.parse(sheet_name)\n",
    "for sheet_name in xls2.sheet_names:\n",
    "    df[sheet_name] = xls2.parse(sheet_name)\n",
    "\n",
    "for file in tqdm(files[0:]):\n",
    "    #if not os.path.exists(re.sub('preds','preds_graphs',re.sub('.pickle','_radii.pickle',file))):\n",
    "        graph = nx.read_gpickle(file)\n",
    "        if len(graph.edges) < 1500:\n",
    "            for sheet_name in xls.sheet_names + xls2.sheet_names:\n",
    "                if re.sub('matt_preds_registered/','',re.sub('_warped.pickle','',re.sub('xyz','XYZ',file))).split('-')[1] in df[sheet_name].values:\n",
    "                    subj = sheet_name\n",
    "                    if (re.sub('matt_preds_registered/','',re.sub('_warped.pickle','',file)).split('-')[0].split('_') + [''])[1] in sheet_name or re.sub('matt_preds/','',re.sub('_warped.pickle','',file)).split('-')[0].split(' ')[0] in sheet_name:\n",
    "                        if subj in [\"TBI07_3D\",\n",
    "                                    \"TBI11_3D\",\n",
    "                                    \"TBI22_3D\",\n",
    "                                    \"TBI31_3D\",\n",
    "                                    \"TBI38_3D\",\n",
    "                                    \"SHAM09_3D\",\n",
    "                                    \"SHAM12_3D\",\n",
    "                                    \"SHAM23_3D\",\n",
    "                                    \"SHAM32_3D\",\n",
    "                                    'TBI38_3D',\n",
    "                                    'TBI6_3D',\n",
    "                                    'SHAM7_3D',\n",
    "                                    'TBI43_3D',\n",
    "                                    'TBI45_3D',\n",
    "                                    'SHAM53_3D',\n",
    "                                    'SHAM56_3D',\n",
    "                                    'SHAM55_3D']:\n",
    "                            gender = 'male'\n",
    "                        else:\n",
    "                            gender = 'female'\n",
    "                        treatment = re.sub('SHA','SHAM',subj[0:3])\n",
    "                        _tmp = df[subj].loc[df[subj]['CHECK WATER'] == re.sub('matt_preds/','',re.sub('_warped.pickle','',re.sub('xyz','XYZ',file))).split('-')[1]]\n",
    "                        if _tmp['Unnamed: 12'].iloc[0] == 'raster':\n",
    "                            seg_file = re.sub('_warped.pickle','_warped_seg.npy',file)\n",
    "                            seg_0001_file = re.sub('_warped.pickle','_0001_warped_seg.npy',file)\n",
    "                            img_file = re.sub('_warped.pickle','_warped_mean.npy',file)\n",
    "                            img_0001_file = re.sub('_warped.pickle','_0001_warped_mean.npy',file)\n",
    "                            seg = np.load(seg_file)\n",
    "                            seg_0001 = np.load(seg_0001_file)\n",
    "                            img = np.load(img_file)\n",
    "                            img_0001 = np.load(img_0001_file)\n",
    "                            break\n",
    "                            seg_dst = distance_transform_edt(seg)\n",
    "                            seg_0001_dst = distance_transform_edt(seg_0001)\n",
    "                            nrn_dst = np.load(re.sub('_warped.pickle','_seg_nrn_dst.npy',file))\n",
    "                            nrn_dst = np.swapaxes(nrn_dst,0,2)\n",
    "                            wavelength = _tmp['Unnamed: 11'].iloc[0]\n",
    "                            power_per = _tmp['Unnamed: 10'].iloc[0]\n",
    "                            start_depth = _tmp['Unnamed: 2'].iloc[0]\n",
    "                            if treatment != 'vbm':\n",
    "                                age = _tmp['Unnamed: 14'].iloc[0]\n",
    "                                days_post_injury = _tmp['Unnamed: 15'].iloc[0]\n",
    "                            else:\n",
    "                                age = 'unknown'\n",
    "                                days_post_injury = 'unknown'\n",
    "                            \n",
    "                            a, b, c = np.mgrid[-20:21:1, -20:21:1, -20:21:1]\n",
    "                            abc = np.dstack([a.flat,b.flat, c.flat])\n",
    "                            mu = np.array([0,0,0])\n",
    "                            sigma = np.array([0.636,0.127,0.127])\n",
    "                            covariance = np.diag(sigma**2)\n",
    "                            d = multivariate_normal.pdf(abc, mean=mu, cov=covariance)\n",
    "                            d = d.reshape((len(a),len(b),len(c)))\n",
    "                            deconv_img = np.copy(img)\n",
    "                            deconv_img[0] =  1023 * restoration.richardson_lucy((img[0]+1e-2)/1023.0, d, iterations=5)\n",
    "                            deconv_img[1] =  1023 * restoration.richardson_lucy((img[1]+1e-2)/1023.0, d, iterations=5)\n",
    "                            deconv_img = np.int16(deconv_img)\n",
    "                            deconv_img_0001 = np.copy(img_0001)\n",
    "                            deconv_img_0001[0] =  1023 * restoration.richardson_lucy((img_0001[0]+1e-2)/1023.0, d, iterations=5)\n",
    "                            deconv_img_0001[1] =  1023 * restoration.richardson_lucy((img_0001[1]+1e-2)/1023.0, d, iterations=5)\n",
    "                            deconv_img_0001 = np.int16(deconv_img_0001)\n",
    "                            \n",
    "                            for i in tqdm(range(len(graph.edges))):\n",
    "                                path = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['pts']\n",
    "                                _pred_radii = np.mean(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max = np.max(seg_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii == 0:\n",
    "                                    _pred_radii =1\n",
    "                                    _pred_radii_max = 5\n",
    "                                _pred_radii_0001 = np.mean(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                _pred_radii_max_0001 = np.max(seg_0001_dst[path[::-1,0],path[::-1,1],path[::-1,2]])\n",
    "                                if _pred_radii_0001 == 0:\n",
    "                                    _pred_radii_0001 =1\n",
    "                                    _pred_radii_max_0001 = 5\n",
    "                                \n",
    "                                _box_fit = max([np.int16(_pred_radii_max)+5, np.int16(_pred_radii_max_0001)+5, 10])\n",
    "                                #path_grad = np.gradient(path,edge_order=2)[0]\n",
    "                                path_smooth = np.float32(np.copy(path))\n",
    "                                for k in range(len(path[0])):\n",
    "                                    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "                                path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "                                res_fwhm = []\n",
    "                                res_fwhm_0001 = []\n",
    "                                X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "                                x,y = np.meshgrid(X,Y)\n",
    "                                x = x.flatten()\n",
    "                                y = y.flatten()\n",
    "                                z = np.zeros(len(x))\n",
    "                                xy = np.vstack([x,y,z])\n",
    "                                break\n",
    "                                def calc_fwhm_path(I):\n",
    "                                    point_grad = path_grad[I]\n",
    "                                    point = path[I]\n",
    "                                    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "                                        rotated = xy.T + point\n",
    "                                    else:\n",
    "                                        rotated = _rotmat(point_grad,xy.T) + point\n",
    "                                    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                                                        rotated.T, \n",
    "                                                                        order=1,\n",
    "                                                                        cval=-10000)\n",
    "                                    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                                                             rotated.T, \n",
    "                                                                             order=1,\n",
    "                                                                             cval=-10000)\n",
    "                                    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                      xy[0:2, points!=-10000], \n",
    "                                                                      points[points!=-10000], \n",
    "                                                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                           0,\n",
    "                                                                           0,\n",
    "                                                                           np.mean(points[points!=-10000])]),\n",
    "                                                                      bounds = ((-1023, 1e-4, -1*_pred_radii/2, -1*_pred_radii/2, -1023), \n",
    "                                                                                (1023, max([_pred_radii_max_0001, _pred_radii_max])*5/(2*np.sqrt(2*np.log(2))), _pred_radii/2, _pred_radii/2, 1023)),\n",
    "                                                                      maxfev=10000\n",
    "                                                                     )\n",
    "                                    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                                                xy[0:2, points_0001!=-10000], \n",
    "                                                                                points_0001[points_0001!=-10000], \n",
    "                                                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                                                     0,\n",
    "                                                                                     0,\n",
    "                                                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/2, -1*_pred_radii_0001/2, -1023), \n",
    "                                                                                          (1023, max([_pred_radii_max_0001, _pred_radii_max])*5/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/2, _pred_radii_0001/2, 1023)),\n",
    "                                                                                maxfev=10000\n",
    "                                                                               )\n",
    "                                    sigma = popt[1]\n",
    "                                    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "                                    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    sigma_0001= popt_0001[1]\n",
    "                                    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "                                    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "                                    return fwhm, fwhm_0001, fwhm_sigma, fwhm_sigma_0001\n",
    "                                \n",
    "                                pool = multiprocessing.Pool(16)\n",
    "                                _vals, _vals_0001, _vals_sigma, _vals_sigma_0001 = zip(*pool.map(calc_fwhm_path, range(len(path))))\n",
    "                                _nrn_dst_vals = nrn_dst[path[::-1,0],path[::-1,1],path[::-1,2]]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii'] = np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_std'] = np.std(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001'] = np.mean(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['radii_0001_std'] = np.std(_vals_0001)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_neuron_distance'] = np.mean(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_std'] = np.std(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['neuron_distance_min'] = np.min(_nrn_dst_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['delta'] = np.mean(_vals_0001) - np.mean(_vals)\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['gender'] = gender\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights'] = _vals\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty'] = _vals_sigma\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_0001'] = _vals_0001\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['path_weights_uncertanty_0001'] = _vals_sigma_0001\n",
    "                                #graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight'] = graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['weight']\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0z'] = path[0][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0y'] = path[0][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-0x'] = path[0][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1z'] = path[-1][0]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1y'] = path[-1][1]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['end-1x'] = path[-1][2]\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['img_start_depth'] = start_depth\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['mean_depth'] = np.mean(path[:,0])\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['euclidean-dst'] = np.sqrt(np.sum(np.square(path[-1]-path[0])))\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['subject'] = subj\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['treatment'] = treatment\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['wavelength'] = wavelength\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['power'] = power_per\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['age'] = age\n",
    "                                graph[list(graph.edges)[i][0]][list(graph.edges)[i][1]]['days_post_injury'] = days_post_injury\n",
    "                            #nx.write_gpickle(graph, re.sub('preds','preds_graphs_fwhm',re.sub('.pickle','_radii.pickle',file)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f2c71b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512, 512, 254)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_0001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "957654ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 254)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d81e75df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matt_preds_registered/06162021_45-XYZres288_warped_mean.npy'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('_warped.pickle','_warped_mean.npy',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f356c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_smooth = np.float32(np.copy(path))\n",
    "for k in range(len(path[0])):\n",
    "    path_smooth[:,k] = sp.ndimage.gaussian_filter1d(np.float64(path[:,k]),2,mode='nearest')\n",
    "path_grad = np.gradient(path_smooth,edge_order=2)[0]\n",
    "res_fwhm = []\n",
    "res_fwhm_0001 = []\n",
    "X = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "Y = np.arange(-1*_box_fit,_box_fit+1,1)\n",
    "x,y = np.meshgrid(X,Y)\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "z = np.zeros(len(x))\n",
    "xy = np.vstack([x,y,z])\n",
    "\n",
    "res_fwhm = []\n",
    "res_fwhm_0001 = []\n",
    "\n",
    "res_fwhm_sigma = []\n",
    "res_fwhm_sigma_0001 = []\n",
    "\n",
    "for I in tqdm(range(len(path))):\n",
    "    if I==40:\n",
    "        break\n",
    "    point_grad = path_grad[I]\n",
    "    point = path[I]\n",
    "    if all(point_grad[0:2] == [0,0]) and abs(point_grad[2]/point_grad[2]) == 1:\n",
    "        rotated = xy.T + point\n",
    "    else:\n",
    "        rotated = _rotmat(point_grad,xy.T) + point\n",
    "    points = sp.ndimage.map_coordinates(deconv_img[0]-deconv_img[1],\n",
    "                                        rotated.T, \n",
    "                                        order=1,\n",
    "                                        cval=-10000)\n",
    "    points_0001 = sp.ndimage.map_coordinates(deconv_img_0001[0]-deconv_img_0001[1],\n",
    "                                             rotated.T, \n",
    "                                             order=1,\n",
    "                                             cval=-10000)\n",
    "    popt,pcov = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                      xy[0:2, points!=-10000], \n",
    "                                      points[points!=-10000], \n",
    "                                      p0=([np.max(points[points!=-10000])-np.mean(points[points!=-10000]),\n",
    "                                           max([_pred_radii, _pred_radii_0001]),\n",
    "                                           0,\n",
    "                                           0,\n",
    "                                           np.mean(points[points!=-10000])]),\n",
    "                                      bounds = ((-1023, 1e-4, -1*_pred_radii/3, -1*_pred_radii/3, -1023), \n",
    "                                                (1023, _pred_radii_max*8/(2*np.sqrt(2*np.log(2))), _pred_radii/3, _pred_radii/3, 1023)),\n",
    "                                      maxfev=10000\n",
    "                                     )\n",
    "    popt_0001,pcov_0001 = sp.optimize.curve_fit(twoD_Gaussian, \n",
    "                                                xy[0:2, points_0001!=-10000], \n",
    "                                                points_0001[points_0001!=-10000], \n",
    "                                                p0=([np.max(points_0001[points_0001!=-10000])-np.mean(points_0001[points_0001!=-10000]),\n",
    "                                                     max([_pred_radii, _pred_radii_0001]),\n",
    "                                                     0,\n",
    "                                                     0,\n",
    "                                                     np.mean(points_0001[points_0001!=-10000])]),\n",
    "                                                bounds = ((-1023, 1e-4, -1*_pred_radii_0001/3, -1*_pred_radii_0001/3, -1023), \n",
    "                                                          (1023, _pred_radii_max_0001*8/(2*np.sqrt(2*np.log(2))), _pred_radii_0001/3, _pred_radii_0001/3, 1023)),\n",
    "                                                maxfev=10000\n",
    "                                               )\n",
    "    sigma = popt[1]\n",
    "    fwhm = 2*np.sqrt(2*np.log(2))*sigma\n",
    "    fwhm_sigma = pcov[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    sigma_0001= popt_0001[1]\n",
    "    fwhm_0001 = 2*np.sqrt(2*np.log(2))*sigma_0001\n",
    "    fwhm_sigma_0001 = pcov_0001[1,1] * 2*np.sqrt(2*np.log(2))\n",
    "    #print(fwhm)\n",
    "    #print(I)\n",
    "    res_fwhm.append(fwhm)\n",
    "    res_fwhm_0001.append(fwhm_0001)\n",
    "    res_fwhm_sigma.append(fwhm_sigma)\n",
    "    res_fwhm_sigma_0001.append(fwhm_sigma_0001)\n",
    "    if I ==5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.8",
   "language": "python",
   "name": "monai3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
